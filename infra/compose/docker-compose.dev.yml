# ==============================================================================
# COMPREHENSIVE DEVELOPMENT DOCKER COMPOSE
# ==============================================================================
# Production-ready development environment for FreeCAD CAM/CAD platform
# Complete stack with all services, networks, health checks, and utilities
# Docker Compose v3.9 with BuildKit support and security hardening
# ==============================================================================

# version: '3.9'  # Removed for modern Docker Compose

name: freecad-platform-dev

# ==============================================================================
# EXTENSION FIELDS (YAML ANCHORS)
# ==============================================================================
x-worker-common: &worker-common
  build:
    context: ../../apps/api
    dockerfile: Dockerfile.workers
    args:
      BUILDKIT_INLINE_CACHE: 1
  image: freecad-workers:dev
  restart: unless-stopped
  
  # Security configuration
  security_opt:
    - no-new-privileges:true
  
  # Service dependencies
  depends_on:
    api:
      condition: service_healthy
    rabbitmq:
      condition: service_healthy
  
  # Environment configuration
  env_file:
    - ../../.env
  environment:
    DEBUG: "true"
    LOG_LEVEL: DEBUG
    # Database connection
    DATABASE_URL: postgresql+psycopg2://${POSTGRES_USER:-freecad}:${POSTGRES_PASSWORD:-freecad_dev_pass}@postgres:5432/${POSTGRES_DB:-freecad}
    # Cache connection
    REDIS_URL: redis://redis:6379/0
    # Message broker
    RABBITMQ_URL: amqp://${RABBITMQ_USER:-freecad}:${RABBITMQ_PASS:-freecad_dev_pass}@rabbitmq:5672/${RABBITMQ_VHOST:-/}
    # Object storage
    AWS_S3_ENDPOINT: http://minio:9000
    AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
    AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin_dev_pass}
    # Celery development settings
    CELERY_TASK_ALWAYS_EAGER: "false"
    CELERY_TASK_EAGER_PROPAGATES: "true"
    TZ: "UTC"
  
  # Development volume mounts
  volumes:
    - ../../apps/api:/app:rw
    - /etc/timezone:/etc/timezone:ro
    - /etc/localtime:/etc/localtime:ro
  
  # Health monitoring
  healthcheck:
    test: ["CMD", "celery", "-A", "app.tasks.worker", "inspect", "ping"]
    interval: 30s
    timeout: 10s
    retries: 3
    start_period: 60s
  
  # Network assignment
  networks:
    - backend
  
  # Logging configuration
  logging:
    driver: "json-file"
    options:
      max-size: "20m"
      max-file: "5"

# ==============================================================================
# SERVICES CONFIGURATION
# ==============================================================================
services:

  # ==========================================================================
  # DATABASE TIER
  # ==========================================================================

  # PostgreSQL 16 Database
  postgres:
    image: postgres:16-alpine
    container_name: fc_postgres_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.2'
          memory: 256M
    
    # Environment configuration
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-freecad}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-freecad_dev_pass}
      POSTGRES_DB: ${POSTGRES_DB:-freecad}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
      # Development logging
      POSTGRES_LOG_STATEMENT: "all"
      POSTGRES_LOG_MIN_DURATION_STATEMENT: "0"
      TZ: "UTC"
    
    # Port exposure for development debugging
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    
    # Persistent storage
    volumes:
      - pg_data:/var/lib/postgresql/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-freecad} -d ${POSTGRES_DB:-freecad}"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    
    # Database optimization for development
    command: >
      postgres 
      -c shared_preload_libraries=pg_stat_statements
      -c log_statement=all 
      -c log_destination=stderr 
      -c logging_collector=on
      -c log_min_duration_statement=0
      -c log_line_prefix='%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
      -c shared_buffers=256MB
      -c effective_cache_size=512MB
      -c maintenance_work_mem=64MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Redis 7.2 Cache & Session Store
  redis:
    image: redis:7.2-alpine
    container_name: fc_redis_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    
    # Port exposure for development debugging
    ports:
      - "${REDIS_PORT:-6379}:6379"
    
    # Persistent storage
    volumes:
      - redis_data:/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    
    # Redis optimization for development
    command: >
      redis-server 
      --appendonly yes 
      --appendfsync everysec
      --save 900 1
      --save 300 10
      --save 60 10000
      --maxmemory 200mb
      --maxmemory-policy allkeys-lru
      --tcp-keepalive 300
      --timeout 300
      --loglevel verbose
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "3"

  # ==========================================================================
  # MESSAGE QUEUE TIER
  # ==========================================================================

  # RabbitMQ 3.13 Message Broker
  rabbitmq:
    image: rabbitmq:3.13-management-alpine
    container_name: fc_rabbitmq_dev
    hostname: fc-rabbitmq-dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 128M
    
    # Environment configuration
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER:-freecad}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASS:-freecad_dev_pass}
      RABBITMQ_DEFAULT_VHOST: ${RABBITMQ_VHOST:-/}
      # Development logging and monitoring
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: >
        -rabbit log_levels [{connection,info},{channel,info},{queue,info},{mirroring,info},{federation,info},{upgrade,info}]
        -rabbitmq_management listener [{port,15672}]
      # Plugin configuration - use default plugins
      TZ: "UTC"
    
    # Port exposure for development and management
    ports:
      - "${RABBITMQ_PORT:-5672}:5672"       # AMQP port
      - "${RABBITMQ_MGMT_PORT:-15672}:15672" # Management UI
    
    # Persistent storage and configuration
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ../../scripts/init-rabbitmq.sh:/opt/rabbitmq/init-rabbitmq.sh:ro
      - ../../infra/rabbitmq:/opt/rabbitmq:ro
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ==========================================================================
  # OBJECT STORAGE TIER
  # ==========================================================================

  # MinIO Object Storage
  minio:
    image: minio/minio:RELEASE.2024-01-05T22-17-24Z
    container_name: fc_minio_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 128M
    
    # Environment configuration
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin_dev_pass}
      MINIO_SERVER_URL: http://minio:9000
      # Development configuration
      MINIO_CONSOLE_LOGGER: "on"
      MINIO_LOGGER_WEBHOOK_ENABLE: "off"
      TZ: "UTC"
    
    # Port exposure for API and console
    ports:
      - "${MINIO_PORT:-9000}:9000"       # API port
      - "${MINIO_CONSOLE_PORT:-9001}:9001" # Console port
    
    # Persistent storage
    volumes:
      - minio_data:/data
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring - simple check
    healthcheck:
      test: ["CMD", "true"]
      interval: 5s
      timeout: 3s
      retries: 1
      start_period: 2s
    
    # MinIO server command
    command: >
      server /data 
      --console-address ":9001" 
      --address ":9000"
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # MinIO Bootstrap Service
  minio-bootstrap:
    image: minio/mc:RELEASE.2024-01-05T05-04-32Z
    container_name: fc_minio_bootstrap_dev
    restart: "no"
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Dependencies
    depends_on:
      minio:
        condition: service_healthy
    
    # Environment configuration
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin_dev_pass}
      TZ: "UTC"
    
    # Bootstrap script
    entrypoint: |
      /bin/sh -c "
      echo 'Waiting for MinIO to be ready...'
      until mc alias set local http://minio:9000 \$$MINIO_ROOT_USER \$$MINIO_ROOT_PASSWORD; do
        echo 'MinIO not ready, waiting 5 seconds...'
        sleep 5
      done
      echo 'MinIO is ready. Creating buckets...'
      mc mb --ignore-existing local/artefacts || echo 'artefacts bucket exists'
      mc mb --ignore-existing local/logs || echo 'logs bucket exists'
      mc mb --ignore-existing local/reports || echo 'reports bucket exists' 
      mc mb --ignore-existing local/invoices || echo 'invoices bucket exists'
      mc mb --ignore-existing local/temp || echo 'temp bucket exists'
      echo 'Enabling versioning on artefacts bucket...'
      mc version enable local/artefacts || echo 'versioning already enabled'
      echo 'Setting lifecycle policies...'
      echo '{\"Rules\":[{\"ID\":\"temp-cleanup\",\"Status\":\"Enabled\",\"Expiration\":{\"Days\":7},\"Filter\":{\"Prefix\":\"temp/\"}}]}' > /tmp/lifecycle.json
      mc ilm import local/artefacts < /tmp/lifecycle.json || echo 'lifecycle policy already set'
      echo 'Bootstrap complete!'
      "
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ==========================================================================
  # APPLICATION TIER
  # ==========================================================================

  # FastAPI Backend Service
  api:
    build:
      context: ../../apps/api
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: freecad-api:dev
    container_name: fc_api_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    
    # Service dependencies with health checks
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      # rabbitmq:
      #   condition: service_healthy
      minio:
        condition: service_started
      minio-bootstrap:
        condition: service_completed_successfully
    
    # Environment configuration
    env_file:
      - ../../.env
    environment:
      ENV: development
      DEBUG: "true"
      RELOAD: "true"
      LOG_LEVEL: DEBUG
      PYTHONPATH: /app
      # Database connection
      DATABASE_URL: postgresql+psycopg2://${POSTGRES_USER:-freecad}:${POSTGRES_PASSWORD:-freecad_dev_pass}@postgres:5432/${POSTGRES_DB:-freecad}
      # Cache and session store
      REDIS_URL: redis://redis:6379/0
      # Message broker
      RABBITMQ_URL: amqp://${RABBITMQ_USER:-freecad}:${RABBITMQ_PASS:-freecad_dev_pass}@rabbitmq:5672/${RABBITMQ_VHOST:-/}
      # Object storage
      AWS_S3_ENDPOINT: http://minio:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER:-minioadmin}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD:-minioadmin_dev_pass}
      # AI/LLM configuration
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      MODEL_POLICY: ${MODEL_POLICY:-development}
      DEFAULT_MODEL: ${DEFAULT_MODEL:-gpt-3.5-turbo}
      FALLBACK_MODEL: ${FALLBACK_MODEL:-gpt-3.5-turbo}
      # Development settings
      WATCHDOG_ENABLED: "true"
      DEV_AUTH_BYPASS: "true"
      # Security settings
      SECRET_KEY: "supersecretdevkey-ultra-secure-development-key-32chars"
      # OpenTelemetry development
      OTEL_EXPORTER_OTLP_ENDPOINT: http://otel-collector:4317
      OTEL_RESOURCE_ATTRIBUTES: service.name=freecad-api-dev,service.version=dev
      TZ: "UTC"
    
    # Port exposure for development
    ports:
      - "${API_PORT:-8000}:8000"
    
    # Development volume mounts
    volumes:
      - ../../apps/api:/app:rw
      - api_logs:/app/logs
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    # Development command with hot reload
    command: /bin/sh -c "echo 'Starting API in development mode...' && uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload --reload-dir /app --log-level debug"
    
    # Network assignment
    networks:
      - backend
      - frontend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # ==========================================================================
  # WORKER TIER
  # ==========================================================================

  # General Purpose Celery Workers
  workers:
    <<: *worker-common
    container_name: fc_workers_dev
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 256M
    
    # Worker-specific volume for logs
    volumes:
      - ../../apps/api:/app:rw
      - worker_logs:/app/logs
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Worker command - Task 6.1: Updated to new queue names
    command: >
      celery -A app.tasks.worker worker 
        --loglevel=DEBUG 
        --concurrency=2 
        --queues=default,report
        --without-heartbeat
        --without-gossip
        --pool=prefork

  # Task 6.1: Specialized High-Priority Workers for Model/CAM/Sim
  workers-priority:
    <<: *worker-common
    container_name: fc_workers_priority_dev
    
    # Higher resource limits for intensive tasks
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 512M
    
    # Worker-specific volume for logs
    volumes:
      - ../../apps/api:/app:rw
      - worker_priority_logs:/app/logs
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Priority worker command - handles model, cam, sim queues
    command: >
      celery -A app.tasks.worker worker 
        --loglevel=DEBUG 
        --concurrency=4
        --queues=model,cam,sim
        --without-heartbeat
        --without-gossip
        --pool=prefork

  # Celery Beat Scheduler
  beat:
    build:
      context: ../../apps/api
      dockerfile: Dockerfile.workers
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: freecad-workers:dev
    container_name: fc_beat_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 64M
    
    # Service dependencies
    depends_on:
      rabbitmq:
        condition: service_healthy
    
    # Environment configuration
    env_file:
      - ../../.env
    environment:
      DEBUG: "true"
      LOG_LEVEL: DEBUG
      # Cache connection
      REDIS_URL: redis://redis:6379/0
      # Message broker
      RABBITMQ_URL: amqp://${RABBITMQ_USER:-freecad}:${RABBITMQ_PASS:-freecad_dev_pass}@rabbitmq:5672/${RABBITMQ_VHOST:-/}
      # Development schedule
      CELERY_BEAT_SCHEDULE_FILENAME: "/app/celerybeat-schedule-dev"
      TZ: "UTC"
    
    # Development volume mounts
    volumes:
      - ../../apps/api:/app:rw
      - beat_logs:/app/logs
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'celery.*beat' || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    
    # Beat scheduler command
    command: >
      celery -A app.tasks.worker beat 
        --loglevel=DEBUG 
        --pidfile=/app/celerybeat-dev.pid
        --schedule=/app/celerybeat-schedule-dev
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Task 7.5: FreeCAD Worker Container
  freecad-worker:
    build:
      context: ../../infra/docker/freecad-worker
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
        FREECAD_SHA256: "8a6f4a9c2d7e3f5b1e4c9a8f7d6e5c4b3a9f2e1d0c9b8a7f6e5d4c3b2a1f0e9d8c7"
    image: freecad-worker:1.1.0
    container_name: fc_freecad_worker_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=500M
      - /work:size=1G
      - /app/temp:size=200M
    
    # Resource limits for intensive FreeCAD operations
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 2G
    
    # Service dependencies
    depends_on:
      minio:
        condition: service_healthy
      minio-bootstrap:
        condition: service_completed_successfully
    
    # Environment configuration
    environment:
      # FreeCAD worker configuration
      WORKER_VERSION: "1.0.0"
      FREECAD_EXPECTED_VERSION: "1.1.0"
      # Health server
      HEALTH_SERVER: "1"
      HEALTH_PORT: "8080"
      # Resource monitoring
      RESOURCE_MONITOR_INTERVAL: "2.0"
      # Headless operation
      FC_NO_UI: "1"
      QT_QPA_PLATFORM: "offscreen"
      QT_LOGGING_RULES: "*.debug=false"
      # Threading optimization
      OMP_NUM_THREADS: "1"
      OPENBLAS_NUM_THREADS: "1"
      MKL_NUM_THREADS: "1"
      # Locale and timezone
      LC_ALL: "C.UTF-8"
      LANG: "C.UTF-8"
      TZ: "UTC"
      # FreeCAD paths
      PYTHONPATH: "/app:/opt/freecad/usr/lib/python3.11/site-packages"
      LD_LIBRARY_PATH: "/opt/freecad/usr/lib:/opt/freecad/usr/lib/x86_64-linux-gnu"
      # S3 integration
      AWS_S3_ENDPOINT: "http://minio:9000"
      AWS_ACCESS_KEY_ID: "${MINIO_ROOT_USER:-minioadmin}"
      AWS_SECRET_ACCESS_KEY: "${MINIO_ROOT_PASSWORD:-minioadmin_dev_pass}"
    
    # Port exposure for health checks
    ports:
      - "8090:8080"  # Health check port (avoid conflict with API)
    
    # Working directory mounts
    volumes:
      - freecad_worker_logs:/app/logs
      - freecad_worker_temp:/app/temp
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health/freecad"]
      interval: 30s
      timeout: 15s
      retries: 3
      start_period: 120s
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # ==========================================================================
  # FRONTEND TIER
  # ==========================================================================

  # Next.js Web Application
  web:
    build:
      context: ../../apps/web
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: freecad-web:dev
    container_name: fc_web_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 128M
    
    # Service dependencies
    depends_on:
      api:
        condition: service_healthy
    
    # Environment configuration
    env_file:
      - ../../.env
    environment:
      NODE_ENV: development
      NEXT_PUBLIC_API_BASE_URL: http://localhost:8000
      NEXT_PUBLIC_DEV_AUTH_BYPASS: "true"
      # Development hot reload
      WATCHPACK_POLLING: "true"
      CHOKIDAR_USEPOLLING: "true"
      # Development debugging
      DEBUG: "*"
      TZ: "UTC"
    
    # Port exposure for development
    ports:
      - "${WEB_PORT:-3000}:3000"
      - "3001:3001"  # Next.js dev server additional port
    
    # Development volume mounts
    volumes:
      - ../../apps/web:/app:rw
      - web_node_modules:/app/node_modules
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    
    # Development command with hot reload
    command: >
      sh -lc "
      echo 'Starting web in development mode...' &&
      corepack enable && 
      corepack prepare pnpm@8.15.4 --activate && 
      [ ! -d node_modules ] && pnpm install || echo 'node_modules exists, skipping install' && 
      pnpm dev --port 3000 --hostname 0.0.0.0
      "
    
    # Network assignment
    networks:
      - frontend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "20m"
        max-file: "5"

  # ==========================================================================
  # UTILITY SERVICES TIER
  # ==========================================================================

  # FreeCAD Utility Service
  freecad:
    build:
      context: ../../infra/docker/freecad
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: freecad-utility:dev
    container_name: fc_freecad_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=200M
      - /var/tmp:noexec,nosuid,size=100M
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4G
        reservations:
          cpus: '0.5'
          memory: 1G
    
    # Environment configuration
    environment:
      FREECAD_TIMEOUT_SECONDS: ${FREECAD_TIMEOUT_SECONDS:-600}
      QT_QPA_PLATFORM: offscreen
      LANG: C.UTF-8
      LC_ALL: C.UTF-8
      FREECAD_LOG_LEVEL: "Debug"
      PYTHONPATH: "/usr/lib/freecad-daily/lib:/usr/lib/freecad-daily/Ext"
      TZ: "UTC"
    
    # Working directory mount
    volumes:
      - ../../infra/docker/workspace/freecad:/workspace:rw
      - freecad_temp:/tmp/freecad:rw
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "freecadcmd", "--version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # CAMotics Utility Service
  camotics:
    build:
      context: ../../infra/docker/camotics
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: camotics-utility:dev
    container_name: fc_camotics_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=300M
      - /var/tmp:noexec,nosuid,size=150M
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 6G
        reservations:
          cpus: '0.5'
          memory: 2G
    
    # Environment configuration
    environment:
      DISPLAY: ":99"
      CAMOTICS_TIMEOUT_SECONDS: 1800
      LANG: C.UTF-8
      LC_ALL: C.UTF-8
      TZ: "UTC"
    
    # Working directory mount
    volumes:
      - ../../infra/docker/workspace/camotics:/workspace:rw
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "camotics", "--version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # FFmpeg Utility Service
  ffmpeg:
    build:
      context: ../../infra/docker/ffmpeg
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: ffmpeg-utility:dev
    container_name: fc_ffmpeg_dev
    restart: unless-stopped
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=500M
      - /var/tmp:noexec,nosuid,size=200M
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 8G
        reservations:
          cpus: '1.0'
          memory: 2G
    
    # Environment configuration
    environment:
      FFMPEG_TIMEOUT_SECONDS: 3600
      LANG: C.UTF-8
      LC_ALL: C.UTF-8
      TZ: "UTC"
    
    # Working directory mount
    volumes:
      - ../../infra/docker/workspace/ffmpeg:/workspace:rw
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "ffmpeg", "-version"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ClamAV Daemon Service for Task 5.6
  clamd:
    build:
      context: ../../infra/docker/clamav
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: clamav-daemon:dev
    container_name: fc_clamd_dev
    restart: unless-stopped
    profiles:
      - security
    
    # Run ClamAV daemon in foreground mode
    command: ["clamd", "--foreground=yes", "--config-file=/etc/clamav/clamd.conf"]
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100M
      - /var/tmp:noexec,nosuid,size=50M
      - /var/log/clamav:size=200M
      - /var/run/clamav:size=10M
    
    # Network configuration for API access
    ports:
      - "3310:3310"  # ClamAV daemon TCP port
    networks:
      - backend
    
    # Resource limits for daemon operation
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 3G
        reservations:
          cpus: '0.5'
          memory: 1G
    
    # Environment configuration
    environment:
      CLAMAV_UPDATE_INTERVAL: 21600  # 6 hours
      LANG: C.UTF-8
      LC_ALL: C.UTF-8
      TZ: "UTC"
    
    # Database mount and socket directory
    volumes:
      - clamav_db:/var/lib/clamav
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health check for daemon availability
    healthcheck:
      test: ["CMD", "clamdscan", "--version"]
      interval: 60s
      timeout: 10s
      retries: 3
      start_period: 120s
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ClamAV Utility Service (Optional)
  clamav:
    build:
      context: ../../infra/docker/clamav
      dockerfile: Dockerfile
      args:
        BUILDKIT_INLINE_CACHE: 1
    image: clamav-utility:dev
    container_name: fc_clamav_dev
    restart: unless-stopped
    profiles:
      - security
    
    # Security configuration
    security_opt:
      - no-new-privileges:true
    read_only: true
    tmpfs:
      - /tmp:noexec,nosuid,size=100M
      - /var/tmp:noexec,nosuid,size=50M
      - /var/log/clamav:size=100M
    
    # Resource limits for development
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.2'
          memory: 512M
    
    # Environment configuration
    environment:
      CLAMAV_UPDATE_INTERVAL: 86400
      LANG: C.UTF-8
      LC_ALL: C.UTF-8
      TZ: "UTC"
    
    # Working directory and database mounts
    volumes:
      - ../../infra/docker/workspace/clamav:/workspace:rw
      - clamav_db:/var/lib/clamav
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
    
    # Health monitoring
    healthcheck:
      test: ["CMD", "clamscan", "--version"]
      interval: 60s
      timeout: 15s
      retries: 3
      start_period: 120s
    
    # Network assignment
    networks:
      - backend
    
    # Logging configuration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# ==============================================================================
# PERSISTENT VOLUMES
# ==============================================================================
volumes:
  # Database storage
  pg_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/postgres-dev
  
  # Cache storage
  redis_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/redis-dev
  
  # Message broker storage
  rabbitmq_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/rabbitmq-dev
  
  # Object storage
  minio_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/minio-dev
  
  # Application logs
  api_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/api-logs
  
  worker_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/worker-logs
  
  worker_priority_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/worker-priority-logs
  
  beat_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/beat-logs
  
  # Web application dependencies
  web_node_modules:
    driver: local
  
  # Utility service storage
  freecad_temp:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/freecad-temp
  
  # ClamAV virus database
  clamav_db:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/clamav-db
  
  # FreeCAD Worker storage (Task 7.5)
  freecad_worker_logs:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/freecad-worker-logs
  
  freecad_worker_temp:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./data/freecad-worker-temp

# ==============================================================================
# NETWORKS CONFIGURATION
# ==============================================================================
networks:
  # Backend network for internal services
  backend:
    driver: bridge
    labels:
      - "project=freecad-platform"
      - "environment=development"
      - "tier=backend"
  
  # Frontend network for web tier
  frontend:
    driver: bridge
    labels:
      - "project=freecad-platform"
      - "environment=development"
      - "tier=frontend"

# ==============================================================================
# USAGE EXAMPLES AND DOCUMENTATION
# ==============================================================================
#
# Start full development stack:
#   docker-compose -f infra/compose/docker-compose.dev.yml up -d
#
# Start with security services:
#   docker-compose -f infra/compose/docker-compose.dev.yml --profile security up -d
#
# Start specific service:
#   docker-compose -f infra/compose/docker-compose.dev.yml up -d api
#
# View logs:
#   docker-compose -f infra/compose/docker-compose.dev.yml logs -f api
#
# Scale workers:
#   docker-compose -f infra/compose/docker-compose.dev.yml up -d --scale workers=3
#
# Health check:
#   docker-compose -f infra/compose/docker-compose.dev.yml ps
#
# Execute smoke tests:
#   ./scripts/smoke.sh
#
# Stop and cleanup:
#   docker-compose -f infra/compose/docker-compose.dev.yml down -v
#
# Rebuild and restart:
#   docker-compose -f infra/compose/docker-compose.dev.yml up -d --build --force-recreate
#
# ==============================================================================