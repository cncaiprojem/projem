# Task ID: 7
# Title: Model Generation Flows (Prompt, Parametric, Upload, Assembly4) with FreeCAD
# Status: in-progress
# Dependencies: 2, 5, 6
# Priority: high
# Description: Implement endpoints and Celery workers to generate models via FreeCADCmd for prompt-driven (AI pre-processing), parametric forms, file upload normalization, and Assembly4 assemblies. Produce FCStd, STEP, STL, GLB preview and metrics.
# Details:
Endpoints:
- POST /designs/prompt, /designs/params, /designs/upload, /assemblies/a4 (all JWT + licenseGuard + rate limit)
Prompt (AI):
- Adapter interface (e.g., OpenAI/Azure) with limits: max tokens ~2k, timeout 20s, retries 3; per-user 30/min; mask PII in logs; store raw masked in ai_suggestions table (part of models.params)
- normalize() and validate() deterministic; ambiguous → 425; missing → ERR-AI-422 AI_HINT_REQUIRED
Validation rules:
- Required fields (dimensions, units, material, machine); ranges (min wall, inner radius); material↔machine compatibility
FreeCAD worker (subprocess):
- Launch per job: `FreeCADCmd -c worker_script.py --args ...`; set ulimit or cgroups for CPU/RAM
- Parametric example (prism with hole) pseudo-Python:
  - import FreeCAD as App, Part
  - doc=App.newDocument(); b=Part.makeBox(L,W,H); c=Part.makeCylinder(d/2,H)
  - b=b.cut(c.translate(App.Vector(L/2,W/2,0)))
  - Part.show(b); doc.recompute(); doc.saveAs(fcstd_path)
  - export STEP/STL via Import/Export; generate STL then GLB using trimesh(export('glb')) for preview
- Upload flow: on finalize, run normalization (unit conversion, orientation); optional manifold fix (trimesh.repair)
- Assembly4: parse parts and placement constraints; build hierarchy; collision check (basic bounding box first)
Outputs:
- Artefacts: FCStd, STEP, STL, GLB; metrics: solids/faces/edges counts, duration; logs with request_id
- Errors: catch FreeCAD exceptions → job failed + suggestions


# Test Strategy:
Unit: normalize/validate for several sample prompts/params; ambiguous prompt returns proper code. Integration: run FreeCAD worker in container to produce FCStd/STEP/STL/GLB; verify artefacts saved and sha256 logged. Upload: corrupted STEP returns 422 with remediation hints. Assembly: conflicting constraints detect and reported.

# Subtasks:
## 1. Define API contracts and guards for model generation endpoints [done]
### Dependencies: None
### Description: Design and document POST /designs/prompt, /designs/params, /designs/upload, /assemblies/a4 with JWT, licenseGuard, RBAC scope checks, and per-user rate limits.
### Details:
Deliver OpenAPI schemas and Pydantic models for inputs/outputs; apply guards: JWT Bearer, licenseGuard (active license), RBAC scope 'models:write'; rate limits: global 60/min per user and AI prompt-specific 30/min; support Idempotency-Key header (stored to jobs.idempotency_key) returning 409 on reuse with conflicting body; responses: 202 Accepted with job_id and request_id; error codes include 401/403/429; content types: application/json (prompt, params, a4) and application/json with object storage reference for upload; include GET /jobs/:id and GET /jobs/:id/artefacts to poll status and list artefacts; acceptance: OpenAPI generated, guards enforced in integration stub, rate limit returns 429 with Retry-After, idempotency validated.
<info added on 2025-08-24T15:55:59.641Z>
- JWT payload requirements: user_id (UUID), license_id (UUID), tenant_id (UUID), scopes (array; must include models:write or models:read as appropriate), exp (Unix timestamp seconds), iat (Unix timestamp seconds), jti (UUID used for revocation). Tokens must be rejected if jti is present in the revocation store; tenant_id is enforced in downstream access checks.
- Rate limiting implementation: Redis sliding window using Lua for atomic prune-count-increment. Keys: rate:{user_id}:{endpoint}:{window}. Use sorted sets with millisecond timestamps; prune older-than-window, count current, compare against limit, then add current event and set key TTL to window seconds. Endpoints identifiers: global and prompt. Limits enforced as specified (global 60/min, prompt 30/min). 429 includes Retry-After with seconds until window elapses and X-RateLimit headers (limit, remaining, reset).
- API versioning: all endpoints under /api/v1/designs/*; support version negotiation via Accept header. Supported formats: application/json; version=1 and application/vnd.designs.v1+json. If an unsupported version is requested, return 406. Include API-Version: 1 in responses.
- Pydantic v2: use Pydantic v2 models with field validators and constrained types for dimensions, units, and materials; strict types for UUIDs and enums for units/materials. Design input models use a discriminated union with discriminator field type having values prompt, params, upload, a4. OpenAPI must reflect oneOf with discriminator mapping. Add validators to normalize units, ensure positive dimensions, and cross-field checks (e.g., material compatible with process).
</info added on 2025-08-24T15:55:59.641Z>
<info added on 2025-08-25T20:21:06.935Z>
FreeCAD core setup and worker constraints:
- Version and headless: use FreeCAD 1.1.0 invoked via FreeCADCmd only (no GUI). Each model job runs FreeCADCmd in a subprocess; never embed FreeCAD in a multithreaded host.
- Single-instance per process: one FreeCAD runtime per OS process. For parallelism, spawn isolated subprocesses (Celery worker -> fork/spawn child per job) with timeouts and stdout/stderr capture; kill on timeout and ensure no zombie processes.
- Document management: create deterministic document names using job_id (e.g., Design_{job_id}); set as ActiveDocument; call doc.openTransaction("build") before operations and doc.commitTransaction() or doc.abortTransaction() on failure; FreeCAD.ActiveDocument.recompute() before export; always App.closeDocument(name) and FreeCAD.setActiveDocument("") after saving.
- Deterministic artefact naming: artefacts saved as {job_id}_{artefact}.{ext} (e.g., 1234_model.fcstd, 1234_solid.step, 1234_mesh.stl).
- File formats and modules:
  - FCStd (native): doc.saveAs(path)
  - STEP/IGES: Import.export([shape], path)
  - STL/OBJ: Mesh.export([object], path)
  - DXF/DWG: Draft.export([objects], path) (DWG requires system support if available)
  - IFC: BIM/Ifc (IfcOpenShell-backed) export if module present
- Configuration (persistent): use FreeCAD.ParamGet() to set required prefs (e.g., BaseApp/Preferences/Units, Import/Export options) at worker start; read for diagnostics in job logs.
- Memory and cleanup: drop references to document objects, close documents, invoke gc.collect() after each job; ensure temporary files are deleted on both success and failure paths.
- Error handling: catch FreeCAD.Base.FreeCADError and map to job errors (e.g., 422 for invalid geometry/unsupported format, 500 for unexpected engine errors) with masked details in logs; include first meaningful message from exception in job audit.
- Transactions: wrap geometry creation/modification inside Document.openTransaction()/commitTransaction() blocks; on exceptions, abort and rollback before closing the document.
- Acceptance: two concurrent model jobs run in separate FreeCADCmd subprocesses without interference, produce FCStd/STEP/STL (and others when applicable), and all documents are closed with memory reclaimed and logs containing deterministic document and file names.
</info added on 2025-08-25T20:21:06.935Z>

## 2. Implement AI adapter (OpenAI/Azure) with timeouts, retries, PII masking, storage [pending]
### Dependencies: 7.1
### Description: Create a provider-agnostic AI adapter with configured limits and compliant logging/storage for prompt preprocessing.
### Details:
Adapter interface: suggest_params(prompt:str, context:dict, max_tokens<=2000, timeout<=20s, retries=3 with exponential backoff+jitter); providers: OpenAI Chat Completions and Azure OpenAI; PII masking (emails, phones, names, addresses) before logging/storage; store masked raw prompt and response in ai_suggestions table (linked to models.params/job_id, request_id); enforce per-user 30/min in adapter as defense-in-depth; circuit breaker on repeated timeouts; configurable via env (provider, model, api_base, api_key, timeouts); acceptance: masked content in logs and DB, retries stop at 3 with backoff, timeouts cancel correctly, adapter returns deterministic schema or raises Ambiguous/Missing with codes.
<info added on 2025-08-15T21:02:01.754Z>
Turkish optimization and GPT4FreeCAD-inspired setup:

- System prompt (inspired by revhappy/GPT4FreeCAD; tailored for FreeCAD Python API):
  Sen FreeCAD Python API uzmanısın. Türkçe CAD tasarım isteklerini FreeCAD scriptlerine dönüştür. Part, Sketcher, Draft modüllerini kullan. Birimler mm, koordinat sistemi sağ el kuralı. Türkçe CAD terimlerini sözlükle İngilizce karşılıklarına eşle: vida→screw, flanş→flange, mil→shaft, yatak→bearing, dişli→gear. Belirsizlik varsa güvenli varsayılanları belirt ve requires_clarification=true alanını doldur. ÇIKTI KURALI: Yalnızca JSON döndür (markdown yok) ve alanlar: {language:"tr", units:"mm", intent:"freecad_script", glossary_used:true|false, parameters:{}, script_py:"<FreeCAD Python>", warnings:[], requires_clarification:true|false}.

- Turkish CAD glossary (used in preprocessing and normalization):
  vida→screw; flanş→flange; mil→shaft; yatak→bearing; dişli→gear.
  Apply as case-insensitive hints; do not over-rewrite variable names inside code.

- Few-shot exemplars (Turkish prompt → minimal FreeCAD Python script; adapter will wrap these as assistant JSON per schema during real requests):
  1) Prompt: M8 vida deliği olan 20mm flanş
     Script:
     import FreeCAD as App, Part
     doc = App.newDocument("flange")
     outer_d = 20.0
     thickness = 5.0
     hole_d = 8.5  # M8 clearance
     body = Part.makeCylinder(outer_d/2.0, thickness)
     hole = Part.makeCylinder(hole_d/2.0, thickness)
     result = body.cut(hole)
     Part.show(result)
     doc.recompute()
  2) Prompt: 3 adet dişli ile güç aktarım sistemi
     Script:
     import FreeCAD as App, Part, Base
     doc = App.newDocument("gear_train")
     module = 1.0
     teeth = [20, 40, 20]
     thickness = 10.0
     radii = [module*t/2.0 for t in teeth]
     centers = [(0,0,0), (radii[0]+radii[1],0,0), (radii[0]+2*radii[1],0,0)]
     for i,(r,c) in enumerate(zip(radii, centers)):
         cyl = Part.makeCylinder(r, thickness)
         cyl.translate(Base.Vector(*c))
         Part.show(cyl)
     doc.recompute()
  3) Prompt: Ayarlanabilir mil çapı ve uzunluğu
     Script:
     import FreeCAD as App, Part
     def make_shaft(d=12.0, L=80.0):
         doc = App.ActiveDocument or App.newDocument("shaft")
         body = Part.makeCylinder(d/2.0, L)
         Part.show(body)
         doc.recompute()
         return body
     make_shaft()

- OpenAI/Azure client configuration for this adapter path:
  timeout=20s, retries=3 with exponential backoff + jitter; model and api_base configurable via env; pass user_locale=tr-TR; include system prompt above; enforce JSON-only response via response_format or output parser.

- Response parser and normalization:
  Expect JSON with fields: language, units, intent, glossary_used, parameters, script_py, warnings, requires_clarification.
  Steps:
  1) Strip markdown and non-JSON pre/post text.
  2) Validate presence and types; else raise Missing(code=ERR-AI-422) or Ambiguous(code=ERR-AI-425).
  3) Enforce units=mm; convert numeric dims if user used cm (detect tokens like “cm”, “metre”).
  4) Apply glossary to parameters/intent only; do not mutate script identifiers.
  5) Lint script_py: must import FreeCAD and use Part/Sketcher/Draft only; reject file I/O and os/system calls.
  6) Attach warnings for assumed defaults (e.g., thickness=5mm, M8 clearance=8.5mm).
  7) Store masked prompt/response for audit; persist normalized JSON and derived script.

- PII masking and audit:
  Mask emails, phones, names, addresses in Turkish/English before storage/logging; ensure masked content is what lands in audit; retain request_id and job linkage.

- Test scenarios (Turkish):
  - Basit geometri: "M8 vida deliği olan 20mm flanş" → script returns a 20mm disk with 8.5mm through-hole; units=mm; warnings may note default thickness.
  - Karmaşık montaj: "3 adet dişli ile güç aktarım sistemi" → script creates 3 cylinders positioned by pitch radii; warnings note simplification (no involute teeth).
  - Parametrik model: "Ayarlanabilir mil çapı ve uzunluğu" → script exposes parameters d and L; requires_clarification=false when both provided, true otherwise.

- Acceptance additions for Turkish flow:
  - adapter applies glossary and locale; model returns JSON-only; parser yields valid FreeCAD script_py or raises explicit Ambiguous/Missing with codes.
  - timeouts and retries respected for tr-TR prompts.
  - masked audit rows include original Turkish prompt and JSON response.
</info added on 2025-08-15T21:02:01.754Z>
<info added on 2025-08-25T19:59:12.750Z>
FreeCAD 1.1 integration for AI adapter and parser:

- Runtime version pin: verify FreeCADCmd == 1.1.0 at startup and before execution (parse `FreeCADCmd --version`); on mismatch fail fast with CONFIG_FREECAD_VERSION_MISMATCH (503) and skip callouts.
- Headless support baseline: generate scripts compatible with FreeCAD 1.1 headless using modules Part, PartDesign, Sketcher, Import, Mesh; Assembly4 workbench constructs allowed via App/Link usage (no GUI).
- System prompt update (tr-TR): emphasize FreeCAD 1.1 Python API expertise, Assembly4 and OndselSolver awareness, glossary mapping (vida→screw, flanş→flange, mil→shaft, yatak→bearing, dişli→gear), mm units, right-handed CS. Instruct JSON-only output with minimal schema: {language:"tr", units:"mm", script_py:"<FreeCAD Python>", parameters:{...}}. Keep few-shot examples (Turkish) and add an Assembly4/link-based placement exemplar.
- Parser normalization: accept both legacy schema and the new minimal v1.1 schema; normalize to internal canonical structure (units=mm enforced; cm/metre tokens converted to mm). If minimal schema is received, backfill optional fields to defaults.
- Script security (AST-based): whitelist imports FreeCAD, Part, PartDesign, Sketcher, Draft, Import, Mesh, math, numpy (restricted to ndarray creation/basic ops); forbid __import__, exec, eval, open, os, subprocess and any file/network I/O; reject Attribute/Call usage that reaches forbidden modules or builtins. Enforce numeric dimension literals and parameter-provided dimensions within 0.1–1000 mm; violations return SecurityViolation (ERR-AI-451).
- Dimension guards: scan numeric constants in AST and parameters; auto-add parser warnings when defaults are assumed; clamp only in validation preview, never mutate silently.
- Assembly4 and solver: allow creation of App::Link and placement transforms; do not require direct OndselSolver imports in scripts—solver integration occurs in execution environment. Reject any GUI-only API usage.
- Standard parts integration (adapter-facing): permit parameters to reference DIN/ISO parts (e.g., parameters.standard_parts:[{code:"DIN933", size:"M8x20"}]) and FCStd template IDs (parameters.templates:[{id:"flange_v3", s3:"s3://..."}]); the generator/worker will resolve these via StandardPartsLibrary (no library imports inside script_py).
- Manufacturing validation hooks: allow optional parameters.manufacturing_checks (min_wall_mm, min_draft_deg, tool_access=true|false). The adapter does not enforce geometry; it forwards to GeometryValidator in the worker.
- Rate limits, retries, masking unchanged; ensure masked prompt/response include the new minimal schema JSON.
- Implementation notes and integration points:
  - Create apps/api/app/services/freecad/ with FreeCADScriptGenerator, GeometryValidator, StandardPartsLibrary; AI adapter will call FreeCADScriptGenerator only after parser/AST pass.
  - Expose adapter profile "freecad-1.1" selecting the updated system prompt, schema, and AST rules.
- Acceptance additions:
  - FreeCADCmd version check passes; mismatch returns 503 without external calls.
  - Adapter returns JSON-only in minimal schema for tr-TR; legacy schema still accepted; both normalize successfully.
  - AST validator rejects forbidden imports/calls and out-of-bounds dimensions with ERR-AI-451; allowed modules pass.
  - Scripts run headless in 1.1 with Part/PartDesign/Sketcher/Import/Mesh only; no file I/O detected.
  - Parameters may include standard parts/templates and manufacturing_checks; values are preserved to downstream services.
</info added on 2025-08-25T19:59:12.750Z>
<info added on 2025-08-25T20:22:40.715Z>
FreeCAD Part Workbench coverage for adapter profile "freecad-1.1"

- System prompt enrichment (tr-TR): instruct the model to generate FreeCAD 1.1 headless scripts using Part/Sketcher/Draft that cover:
  - Primitives: Box, Cylinder, Sphere, Cone, Torus, Wedge with parametric controls (dimensions in mm; valid range 0.1–1000).
  - Boolean ops: Part.Shape.cut(), fuse(), common() with try/except and post-op validation (result.isValid(), not result.isNull()) and warnings on non-manifold/invalid results.
  - Loft/Sweep: Part.makeLoft(profiles, solid=True/False, ruled=False/True) and sweeps using profiles (wires) and a path; create profiles via Sketcher or Part wires; avoid GUI.
  - Chamfer/Fillet: shape.makeChamfer(r, edges) and shape.makeFillet(r, edges) with deterministic edge selection (by index list or geometric filters); no GUI selection.
  - Thickness/Shell: shape.makeThickness(faces, t, join=0, tolerance=1e-3, makeSolid=True) for thin walls; document inward/outward via sign of t.
  - Shape checks: isValid(), isClosed(), isNull(); attach warnings accordingly.
  - Properties access: use shape.Volume, shape.Area, shape.CenterOfMass to compute metrics.
  - Units: default mm; if user specifies inches (tokens: in, inch, inches, "), convert to mm (×25.4) explicitly in parameters or pre-compute in script constants.

- Parser/normalization updates:
  - Accept minimal v1.1 schema; backfill legacy fields. When script references inches, normalize parameters to mm; record a units_conversion warning.
  - Extend unit detection to inches (in/inch/inches/") and composite tokens (e.g., 2in, 2", 2 in).
  - Normalize requested operations into parameters.operations list when present (e.g., [{op:"fillet", r:2, edges:[1,3]}], [{op:"cut", a:"body", b:"hole"}]).
  - Introduce parameters.exports and parameters.mesh:
    - exports: [{format:"STEP", ap:"AP203"|"AP214"} | {format:"IGES"} | {format:"BREP"}]
    - mesh: {linear_deflection:float, angular_deflection_deg:float, relative:true|false}
  - Profile/path schema for loft/sweep:
    - profiles: ["sketch:profile1", "wire:auto"] and path: "wire:path1" or "edge:auto"; adapter does not resolve geometry—worker maps identifiers to created objects.
  - Edge selection schema:
    - edges: indices [int] or selectors [{by:"length_gt", value:mm}, {by:"name", value:"Edge1"}]; worker resolves against final shape.

- AST/security enforcement (unchanged core rules):
  - Allow Part, Sketcher, Draft, Import, Mesh; still forbid any file/network I/O and dangerous builtins. Explicitly reject Import.export/Import.exportStep/Import.exportIGES usage inside script (ERR-AI-451); exports occur only in worker based on parameters.exports.
  - Permit shape.tessellate() for preview-only; forbid MeshPart and any disk writes. Mesh file generation happens in worker.

- Worker integration expectations (adapter-facing parameters pass-through):
  - Boolean validity: after executing script, worker runs GeometryValidator (isValid/isNull), rejects non-manifold/invalid results with ERR-AI-451 or attaches warnings depending on endpoint policy.
  - Exports: worker performs STEP (AP203/AP214), IGES, BREP via Import in a controlled path; script never writes files.
  - Meshing: worker generates meshes with specified tessellation; no MeshPart import required if using shape.tessellate or controlled utilities.
  - Metrics: worker computes and stores Volume, Area, CenterOfMass if not provided by script.

- Acceptance additions:
  - AI outputs scripts that create requested Part primitives and apply booleans, loft/sweep, chamfer/fillet, and thickness without GUI APIs; scripts pass AST validator.
  - Non-manifold/invalid results are detected; either warnings are included (legacy schema) or worker returns a structured validation error; adapter does not silently accept invalid shapes.
  - Inch inputs are correctly converted to mm during normalization; units=mm enforced in stored canonical JSON.
  - parameters.exports and parameters.mesh are preserved to downstream; scripts contain no file I/O; any attempt to call Import.export is blocked with ERR-AI-451.
  - Properties access via .Volume/.Area/.CenterOfMass is allowed and does not trigger security violations.

- Test scenarios:
  - Primitives: Box(10×20×5 mm), Cylinder(d=12 mm, h=30 mm), Wedge with top/bottom offsets; validate volumes.
  - Boolean: Fuse two cylinders, cut through-hole; invalid self-intersection triggers warning/error.
  - Loft: Two circular profiles at z=0 and z=30; solid=True; result isValid() and isClosed() true.
  - Sweep: Rectangular profile along S-curve path; result passes validator.
  - Fillet/Chamfer: Apply r=2 mm on edges [1,3,5]; edges exist and operation succeeds.
  - Thickness: Shell a box outward by 1.5 mm excluding top face; result solid and valid.
  - Export: Request STEP AP214 and IGES via parameters.exports; worker produces files; script has no export calls.
  - Mesh: Request linear_deflection=0.1, angular_deflection=15; mesh artifact generated by worker; no MeshPart import in script.
  - Units: Input "2 inch pipe with 1/8 inch wall" normalizes to mm and passes bounds check.
</info added on 2025-08-25T20:22:40.715Z>

## 3. Build normalize() and validate() deterministic rules engine [pending]
### Dependencies: 7.1
### Description: Implement canonicalization and validation for prompts and parametric inputs with strict error codes.
### Details:
Normalization: units→mm (exact factors), ordered keys, numeric rounding (e.g., 1e-6), default units/material if provided context, string trims, enum casing; Validation: required fields (dimensions L,W,H or relevant set, units, material, machine), ranges (min wall thickness, inner radius > 0), material↔machine compatibility; Ambiguity detection (multiple interpretations) → HTTP 425; missing essential info → 422 with code ERR-AI-422 AI_HINT_REQUIRED; output canonical_params JSON used by workers and cache keys; acceptance: unit tests cover valid, ambiguous, and missing cases returning exact codes and messages deterministically.
<info added on 2025-08-15T21:04:01.108Z>
Extend normalize()/validate() with GPT4FreeCAD-style “script mode” for AI-generated FreeCAD Python scripts (Turkish CAD script security).

Scope
- Applies when input contains a FreeCAD Python script (from prompt adapter or upload). Produces canonical_script and script_meta alongside canonical_params. Deterministic outputs drive worker cache keys (script_hash = sha256(canonical_script)).

Allowed/forbidden
- Allowed imports: FreeCAD (aliased as App), Part, Sketcher, Draft, math, numpy (numeric-only).
- Forbidden names/operations: __import__, exec, eval, open, file, os, subprocess, sys.exit (any access), dynamic import patterns, writing files, spawning processes.
- Numpy allowlist (attribute access limited to): array, asarray, linspace, arange, zeros, ones, sqrt, sin, cos, tan, pi, dot, cross, clip, maximum, minimum, abs, floor, ceil, round. Any other numpy attribute → SECURITY_VIOLATION.

Normalization (deterministic, idempotent)
1) Ensure imports (prepend if missing, keep single copies):
   - import FreeCAD as App
   - import Part
   - Optional pass-through (present but not added): import Sketcher, import Draft, import math, import numpy as np or import numpy
2) Ensure document:
   - If no new/active doc used: insert doc = App.newDocument()
   - Else if a document exists but no variable doc: insert doc = App.ActiveDocument
3) Ensure display:
   - If a top-level variable named result is created and is used as a shape/object, append Part.show(result) if missing
4) Ensure recompute:
   - Append doc.recompute() if missing at end of script
5) Unit normalization to mm:
   - Recognize and convert the following to mm, rounding to 1e-6:
     a) Identifier suffixes: *_cm → value*10; *_inch or *_in → value*25.4
     b) Inline unit comments on assignments/call args: “… = 12  # cm/inch/in”
     c) Helper-like calls cm(x), inch(x) → replaced with numeric mm literal (if present)
   - Update variable names by removing unit suffixes after conversion
6) Comment translation:
   - Translate Turkish comments to English via glossary-based replacement (code unchanged). Minimal glossary: uzunluk→length, genişlik→width, yükseklik→height, yarıçap→radius, duvar kalınlığı→wall thickness, birim→unit, mm→mm, cm→cm, inç→inch, hata→error, uyarı→warning
7) Key ordering and whitespace:
   - Stable import ordering (FreeCAD/Part first), strip trailing spaces, ensure newline at EOF

Validation
1) Syntax (AST):
   - Parse with Python AST. On SyntaxError → INVALID_SYNTAX
2) Security (AST-based, name/attr/use):
   - Reject forbidden builtins/names and any access to os, subprocess, sys.exit (direct or via alias)
   - Reject dynamic code execution (exec, eval, __import__)
   - Enforce import allowlist; any other import → SECURITY_VIOLATION
   - Enforce numpy allowlist; any disallowed attribute access on numpy/np → SECURITY_VIOLATION
3) FreeCAD API compatibility (version target: FreeCAD 1.1.x):
   - Resolve attribute chains (e.g., Part.makeBox). If attribute missing → API_NOT_FOUND
   - Deprecated methods produce non-fatal warnings (API_DEPRECATED) with suggested replacements (maintain internal deprecation map); still pass validate unless also missing
4) Dimension limits (mm):
   - Extract lengths from known constructors and operations: Part.makeBox(L,W,H), Part.makeCylinder(r,h), Part.Face/Edge creation with lengths, Sketcher distances where literal
   - After unit normalization, each positive dimension must be 0.1 ≤ value_mm ≤ 1000; else → DIMENSION_ERROR
5) Timeout:
   - Sandbox execution budget 20s CPU/wall (worker enforces). Exceeding budget → TIMEOUT_ERROR

Error codes, messages (Turkish, deterministic)
- INVALID_SYNTAX (HTTP 400): Python sözdizimi hatası: {details}. Çözüm: satır {lineno} yakınındaki hatayı düzeltin.
- SECURITY_VIOLATION (HTTP 403): Güvenlik ihlali: yasaklı komut/modül kullanımı tespit edildi: {symbol}. Öneri: yalnızca izin verilen modülleri (FreeCAD, Part, Sketcher, Draft, math, numpy) ve güvenli API’leri kullanın.
- API_NOT_FOUND (HTTP 422): API bulunamadı: {qualname} FreeCAD {version} içinde yok veya erişilemez. Öneri: güncel API’yi kullanın: {suggestion}.
- DIMENSION_ERROR (HTTP 422): Boyut limiti aşıldı: {name}={value_mm} mm (izin: 0.1–1000 mm). Öneri: değeri aralığa çekin.
- TIMEOUT_ERROR (HTTP 504): Zaman aşımı: script 20 saniyeyi aştı. Öneri: hesaplamayı basitleştirin veya yinelemeyi sınırlandırın.

Outputs on success (augment canonical_params)
- canonical_script: normalized script text
- script_meta: {
  modules_used: [...],
  conversions_applied: [{from_unit, to_unit, before, after, location}],
  api_warnings: [API_DEPRECATED …],
  dims_mm: {L, W, H, r, h, … when inferable},
  script_hash: sha256(canonical_script)
}

Determinism
- All normalization edits are structural (AST-to-source or regex with anchor rules) and idempotent.
- Error messages include fixed templates and stable field ordering; numbers rounded to 1e-6.

Testing (expand unit tests)
- Syntax error sample → INVALID_SYNTAX with exact Turkish template
- Forbidden exec/eval/open/os/subprocess/sys.exit → SECURITY_VIOLATION
- Disallowed import (e.g., json) or numpy attribute (e.g., np.linalg.solve) → SECURITY_VIOLATION
- Missing imports/doc/show/recompute auto-inserted; idempotent on second run
- Unit conversions: _cm, _inch suffixes and inline comments converted to mm; values rounded; variable names normalized
- API missing (e.g., Part.makeBoxx) → API_NOT_FOUND; deprecated method → warning only
- Dimension limits: values outside [0.1, 1000] mm → DIMENSION_ERROR; boundary values pass
- Timeout enforced in worker harness → TIMEOUT_ERROR
- Comments translated TR→EN in output; code semantics unchanged
- Snapshot of canonical_script hashed; cache key stable across runs with same logical script
</info added on 2025-08-15T21:04:01.108Z>
<info added on 2025-08-25T20:24:31.095Z>
Extend script mode to support FreeCAD PartDesign Workbench (Bodies, Sketcher constraints, features, patterns, datums, booleans) with deterministic normalization/validation.

Scope and allowlist
- Detect PartDesign usage when script creates/uses any of: PartDesign::Body, PartDesign::Pad, PartDesign::Pocket, PartDesign::Revolution, PartDesign::Groove, PartDesign::AdditiveLoft, PartDesign::SubtractiveLoft, PartDesign::AdditivePipe, PartDesign::SubtractivePipe, PartDesign::LinearPattern, PartDesign::PolarPattern, PartDesign::Mirrored, PartDesign::Boolean, PartDesign::DatumPlane, PartDesign::DatumLine, PartDesign::DatumPoint, Sketcher::SketchObject and Sketcher.Constraint.
- Allowed Sketcher constraint types (allowlist): Distance, Angle, Coincident, Parallel, Perpendicular, Horizontal, Vertical, Tangent, Equal, Symmetric. Any other constraint name → CONSTRAINT_UNSUPPORTED.
- Multibody is allowed at document level; enforce PartDesign “single solid per Body” rule for each Body independently.

Normalization (idempotent)
- Ensure a document Body context: if PartDesign features are used and no active Body exists, insert body = App.ActiveDocument.addObject('PartDesign::Body','Body') and activate if needed; do not move existing objects.
- Ensure recompute at end still applies; if a Body exists and has features, set body.ViewObject.Visibility = True is not forced (visual only); we do not insert GUI calls.
- If a PartDesign Body is created and a “Tip” is not set by script, set it to the last created PartDesign feature in that Body (deterministically by creation order) to keep a stable resulting solid.
- Units: continue mm normalization for all linear properties on PartDesign features (Pad.Length, Pocket.Length, Pocket.Offset, Revolution.Axis placement distances, Loft/Pipe section-driven numeric distances, Datum offsets). Round to 1e-6. Angles are left in degrees; see validation for ranges.
- Sketcher comments translation (TR→EN) still applies; constraint names in comments are not modified.
- Stable ordering: keep imports first, then document/body creation, then sketches, then features, then patterns/booleans; do not reorder user logic beyond minimal insertions above.

Validation (deterministic)
- Syntax and security rules unchanged; reject any disallowed imports or dynamic code.
- API compatibility: verify addObject class names exist in FreeCAD 1.1.x; missing → API_NOT_FOUND.
- Sketch constraints: verify each added constraint type is in the allowlist; else → CONSTRAINT_UNSUPPORTED (HTTP 422).
- Sketch ambiguity: compute degrees of freedom (if accessible via SketchObject.DegreeOfFreedom or solver result after recompute). If DoF > 0 → SKETCH_UNDERCONSTRAINED (HTTP 425). If overconstrained or conflicting → INVALID_SYNTAX if thrown by solver, else SKETCH_UNDERCONSTRAINED with details.
- Feature parameter extraction and limits (post mm normalization):
  - Pad/Pocket length, Groove/pipe/loft section distances: 0.1 ≤ value_mm ≤ 1000; else → DIMENSION_ERROR.
  - Draft/taper angles on Pad/Pocket/Pipe/Loft: -45 ≤ angle_deg ≤ 45; else → ANGLE_ERROR.
  - Revolution total angle: 0 < angle_deg ≤ 360; else → ANGLE_ERROR.
  - Pattern features:
    - LinearPattern occurrences: 1–1000; spacing_mm: 0.1–1000; else → PATTERN_ERROR.
    - PolarPattern occurrences: 1–1000; angle sweep: 0–360; else → PATTERN_ERROR.
    - Mirrored: requires valid mirror plane/axis reference; missing/invalid → PATTERN_ERROR.
- Feature tree integrity:
  - Each PartDesign feature must reference a valid parent/support within the same Body (Sketch or previous feature). Missing parent or cross-body misuse (except Boolean) → FEATURE_DEPENDENCY_ERROR (HTTP 422).
  - No cycles allowed in feature dependency graph; detect and reject → FEATURE_DEPENDENCY_ERROR.
  - Tip must be a PartDesign feature in the Body; if set to non-feature or invalid → FEATURE_DEPENDENCY_ERROR.
- Single solid rule:
  - After recompute, evaluate each Body’s resultant shape; if a Body contains more than one separate solid at its Tip → SINGLE_SOLID_VIOLATION (HTTP 422).
- Boolean operations between bodies:
  - Only PartDesign::Boolean at Body level is accepted; confirm target Body and tool Body exist; operation result must maintain a single solid in the target Body → else BOOLEAN_BODY_ERROR (HTTP 422).

Error codes, messages (Turkish, deterministic)
- CONSTRAINT_UNSUPPORTED (HTTP 422): Desteklenmeyen Sketcher kısıtı: {name}. Öneri: izin verilen kısıtları kullanın: Distance, Angle, Coincident, Parallel, Perpendicular, Horizontal, Vertical, Tangent, Equal, Symmetric.
- SKETCH_UNDERCONSTRAINED (HTTP 425): Belirsizlik: eskiz yeterince kısıtlanmadı (DoF={dof}). Öneri: eksik kısıtları ekleyin veya boyutları netleştirin.
- FEATURE_DEPENDENCY_ERROR (HTTP 422): Özellik bağımlılığı hatası: {feature} → {parent} eksik, geçersiz veya döngü tespit edildi. Öneri: özellikleri Body içinde sıralı inşa edin ve destekleri doğru ayarlayın.
- SINGLE_SOLID_VIOLATION (HTTP 422): Tek katı kuralı ihlali: Body '{body}' birden fazla ayrı katı içeriyor. Öneri: özellikleri birleştirerek tek bir sürekli katı oluşturun veya ayrı Body kullanın.
- ANGLE_ERROR (HTTP 422): Açı limiti aşıldı: {name}={value_deg}° (izin: {min_deg}–{max_deg}°). Öneri: değeri aralığa çekin.
- PATTERN_ERROR (HTTP 422): Dizilim özelliği hatası: {param}={value}. Öneri: adet 1–1000, aralık 0.1–1000 mm, açı 0–360° olmalıdır.
- BOOLEAN_BODY_ERROR (HTTP 422): Body boolean hatası: '{target}' ile '{tool}' arasında geçersiz işlem veya çoklu katı oluşumu. Öneri: Body düzeyinde Boolean kullanın ve tek katı kuralını koruyun.

Outputs on success (augment script_meta)
- modules_used includes PartDesign and Sketcher if present.
- partdesign_features: [{name, class, body, params: {length_mm, depth_mm, angle_deg, draft_deg, spacing_mm, occurrences, sweep_angle_deg, ...}}]
- sketches: [{name, body, constraint_counts: {Distance, Angle, Coincident, Parallel, Perpendicular, Horizontal, Vertical, Tangent, Equal, Symmetric}, dof}]
- bodies: {count, names: [...], tip_map: {body: tip_name}, single_solid_ok: true/false}
- datums: {planes, axes, points} with offsets_mm where applicable
- booleans: [{target_body, tool_bodies: [...], operation: Fuse/Cut/Common, result_single_solid: true/false}]
- dims_mm extended with feature-derived values (pad_length, pocket_depth, revolution_angle_deg, draft_deg, pattern_spacing, etc.)

Testing (expand unit tests)
- Underconstrained sketch (DoF>0) → SKETCH_UNDERCONSTRAINED (HTTP 425) with exact DoF in message.
- Unsupported constraint (e.g., Concentric) → CONSTRAINT_UNSUPPORTED.
- Pad length out of bounds and taper angle out of bounds → DIMENSION_ERROR and ANGLE_ERROR respectively.
- Feature dependency missing/cycle → FEATURE_DEPENDENCY_ERROR.
- Single solid violation in a Body (e.g., two separate pads on parallel sketches) → SINGLE_SOLID_VIOLATION.
- LinearPattern invalid spacing or occurrences → PATTERN_ERROR; PolarPattern angle >360 → PATTERN_ERROR.
- Boolean between bodies that yields multiple solids in target → BOOLEAN_BODY_ERROR; valid fuse → success.
- Tip auto-set when missing; idempotent normalization on second run.
- Metadata captures features, constraints, bodies, datums, booleans; numbers rounded to 1e-6.
</info added on 2025-08-25T20:24:31.095Z>

## 4. Celery job orchestration and lifecycle for model flows [pending]
### Dependencies: 7.1
### Description: Wire API to Celery tasks, define queues, idempotency, structured logging, and job status transitions.
### Details:
Queues: models.prompt, models.params, models.upload, assemblies.a4; task signature includes job_id, request_id, user_id, canonical_params/input_ref; Celery worker options: acks_late, task_time_limit and soft_time_limit, visibility_timeout; retries for transient storage/queue errors only; dead-letter via RabbitMQ DLX; structured logs with request_id; CLI: celery -A app.celery_app worker -Q models.prompt,models.params,models.upload,assemblies.a4 -Ofair -c 2 --prefetch-multiplier=1; acceptance: job created with idempotency, transitions queued→running→succeeded/failed, logs contain request_id, DLQ receives poisoned messages.
<info added on 2025-08-25T20:31:29.929Z>
FreeCAD FEM/Simulation implementation (FEM Workbench, “Sonlu Elemanlar Analizi”) to run headless under Celery and produce deterministic, reproducible results:

- Supported analyses (Türkçe in parens):
  - Linear static (Doğrusal statik)
  - Modal/eigenfrequency (Modal/özfrekans)
  - Linear buckling (Doğrusal burkulma)
  - Steady-state thermal (Durulmuş ısıl)
  - Transient thermal (Zamansal ısıl)
  - Sequential thermo-structural coupling (Ardışık ısıl→mekanik bağlama)
  - Optional: Nonlinear static with small-strain contact where feasible in CalculiX (Doğrusal olmayan statik)

- Canonical inputs (normalize/validate applies before enqueue):
  - model_ref or input_ref to shape(s); unit_system (SI default)
  - analysis_type ∈ {static, modal, buckling, thermal_steady, thermal_transient, coupled_thermal_static}
  - material set per body/part (malzeme: E, ν, ρ, α, k, c_p; Türkçe: Young modülü, Poisson oranı, yoğunluk, genleşme katsayısı, ısı iletkenliği, özgül ısı)
  - constraints and loads (kısıtlar ve yükler) with magnitude, direction, faces/edges/nodes selection, coordinate system
  - mesh settings (ağ/mesh): mesher, global_size, min_size, second_order, local_fields, growth_rate, quality_targets
  - solver settings (çözücü): backend, max_steps, tolerance, nlgeom, time_steps (thermal transient), damping (modal), threads
  - outputs: fields, probes, sections, images, vtk, csv, foS

- Constraint and load types mapped to FreeCAD FEM objects (Türkçe):
  - Fixed support (Sabit kısıt)
  - Displacement/rotation BC (Yer değiştirme/Dönme kısıtı) with components
  - Force (Kuvvet) vector or normal to face
  - Pressure (Basınç) on faces
  - Moment/Torque (Moment/Tork)
  - Remote load/support with reference point (Uzak yük/destek)
  - Gravity/Self-weight (Ağırlık)
  - Symmetry plane (Simetri düzlemi) and Roller/Slider (Mafsallı/tekerlekli kısıt)
  - Bearing load (Yatak yükü) for shafts
  - Temperature (Sıcaklık), Heat flux (Isı akısı), Convection h·(T∞−T) (Taşınım sınır koşulu)
  - Contact: Bonded/Tie (Yapışık), Frictionless (Sürtünmesiz) where supported by CalculiX

- Mesh control (Gmsh preferred; Netgen fallback):
  - Global target size from bounding-box heuristics unless specified
  - Second-order elements (İkinci mertebe) on by default for structural; first-order for thermal unless gradients require second-order
  - Curvature- and proximity-based refinement; local sizing by selection groups (delik kenarları/fillet bölgeleri)
  - Growth rate limit, min/max element size, surface/volume refinement
  - Quality checks: aspect ratio, minimum Jacobian; fail fast if below thresholds; auto-relax targeting if mesh fails twice
  - Mesher selection: gmsh|netgen via canonical_params.mesh.mesher

- Solver configuration (CalculiX ccx default; Elmer optional when installed):
  - Static: linear by default; nlgeom toggled if large loads or contact; iterative control (tolerance, max_steps)
  - Modal: number_of_modes, frequency_range; mass-scaling disabled by default
  - Buckling: reference from converged static preload; extract critical load factors
  - Thermal (steady/transient): time stepping (Δt, total_time), stabilization where needed
  - Parallelism via OMP_NUM_THREADS; memory cap enforced; write .inp with node/element sets named by UUID for traceability
  - Output frequency and fields tuned per analysis to balance size vs insight

- Headless execution plan (FreeCADCmd pipeline):
  - Load FCStd/STEP; rebuild shape; ensure units coherent (SI)
  - Create Analysis container; attach Solver object (CalculiX)
  - Assign materials (App::MaterialObject) to solids; verify density for gravity if used
  - Build BCs/loads from canonical selections (by persistent SubElement names); auto-orient pressure normals
  - Generate mesh (FemMeshGmsh); apply local regions; set secondOrder flag as required
  - Write solver input; run ccx with bounded time and CPU; stream stdout/stderr to structured logs (request_id)
  - Parse results (.frd/.dat or VTK); create FemResultObject; compute derived fields (Von Mises/Esnek gerilme, principal stresses, displacement magnitude)
  - Export artefacts: FCStd with Analysis, .inp, .frd/.dat, .vtk/.vtu/.vtm, CSV probes, PNG snapshots (deformed, stress maps), JSON summary
  - Cleanup temporary files; attach metrics; update progress across phases: setup→meshing→solve→post→archive

- Results processing and metrics (Sonuç işleme):
  - Summary JSON: max_von_mises, max_disp, max_temp, eigenfrequencies[], buckling_factors[], reaction_forces, energy, mass
  - Factor of Safety (Emniyet katsayısı): if yield_strength provided, min(σ_y/σ_vM) over domain; else null with hint
  - Probes: user-defined points/paths; sections: clip planes for images
  - Image presets: undeformed + deformed (scale auto), stress/temperature contour with legend; unit labels in SI
  - Validation: result sanity checks (nonzero stiffness, no rigid-body modes in constrained static); flag singular models with actionable messages

- Multi-physics coupling (Çok-fizikli bağlama):
  - Sequential thermal→structural: run thermal, map nodal temperatures to structural load; ensure matching meshes or interpolate
  - Modal with pre-stress: optional static preload prior to eigenfrequency
  - Elmer path reserved for future true multi-physics; current default is CalculiX sequential coupling

- Celery integration for FEM (queue and lifecycle):
  - Queue: sim.fem (DLX: sim.fem_dlx → sim.fem_dlq); soft_time_limit and hard time_limit sized by analysis_type and mesh size
  - Task signature extends existing: job_id, request_id, user_id, model_ref, canonical_params.sim
  - Retries only on transient I/O; solver/model errors are non-retryable; poisoned messages route to DLQ
  - Progress updates at defined milestones; structured logs include analysis_type, model_ref, mesher, ccx_version

- Deterministic normalize/validate for FEM inputs (Ön-doğrulama kuralları):
  - Units normalized to SI; reject mixed unit systems
  - Required: at least one BC fixing all rigid-body DOFs for static; temperature/convection well-posed for thermal
  - Geometry selections must resolve to existing faces/edges; empty selections → 422 with hints
  - Mesh: size bounds relative to smallest feature; min_size ≥ feature_min/10; second_order true for static/modal unless explicitly disabled
  - Solver caps: max elements, max nodes; if exceeded → 409 SIM_LIMIT_EXCEEDED with recommendation
  - Contact pairs require non-overlapping, compatible regions; otherwise demote to bonded with warning if allowed

- Artefact storage and naming:
  - sim/{job_id}/analysis.fcstd, model.inp, result.frd, result.dat, result.vtu|vtm, result.csv, report.json, preview_stress.png, preview_disp.png, logs.txt
  - SHA256 recorded for each; signed URLs returned via job artefacts

- Turkish terminology quick map for UI/logs:
  - Constraint (Kısıt), Load (Yük), Boundary condition (Sınır koşulu), Mesh (Ağ), Element (Eleman), Node (Düğüm), Solver (Çözücü), Result (Sonuç), Stress (Gerilme), Strain (Şekil değiştirme), Displacement (Yer değiştirme), Temperature (Sıcaklık), Heat flux (Isı akısı), Convection (Taşınım), Contact (Temas), Buckling (Burkulma), Modal (Modal/Özdeğer), Factor of Safety (Emniyet katsayısı)

Acceptance additions:
  - Reproduce reference problems (cantilever beam static, 3D bracket modal, plate buckling, heat sink thermal) within tolerance vs analytical/benchmark
  - Artefacts present and downloadable; JSON summary validates against sim_report schema; logs include request_id and solver metadata
  - DLQ receives failed solves with structured error and minimal reproduction info (mesher, sizes, counts, ccx exit code)
</info added on 2025-08-25T20:31:29.929Z>

## 5. FreeCAD worker container image and execution harness [pending]
### Dependencies: 7.4
### Description: Create container with FreeCADCmd 1.1.x and a harness that executes modeling tasks under resource limits.
### Details:
Dockerfile installs FreeCADCmd 1.1.x, Python 3.11, packages: numpy, trimesh, pygltflib (if used), minio SDK; non-root user; execution harness worker_script.py parses args, sets ulimit (CPU seconds) and cgroups (RAM), sets nice/ionice; invocation: FreeCADCmd -c /app/worker_script.py --flow {prompt|params|upload|a4} --input /work/input.json --outdir /work/out --request-id {uuid}; temp workspace isolated per job; acceptance: container builds in CI, FreeCADCmd available, harness enforces time/memory limits and exits with non-zero on violation.
<info added on 2025-08-24T15:57:18.229Z>
- Pin exact FreeCAD version: FreeCADCmd 1.1.0 (no wildcard). Lock via package manager pin or artifact checksum; verify at build with FreeCADCmd --version == 1.1.0.
- requirements.txt (pinned):
  - numpy==1.24.3
  - trimesh==4.0.1
  - pygltflib==1.16.1
  - minio==7.2.0
  - psutil==5.9.8
- Health check server: lightweight HTTP endpoint exposed by the harness (threaded) on PORT (default 8080). GET /health/freecad returns 200 JSON including:
  - freecad_version: “1.1.0” (from FreeCADCmd --version or FreeCAD.Version())
  - python_version
  - packages: {numpy, trimesh, pygltflib, minio, psutil} with installed versions
  - status: “ok”
  Enable with --health-server flag or HEALTH_SERVER=1; container EXPOSE 8080 for k8s liveness/readiness.
- Resource monitoring: integrate psutil to sample per-process CPU percentage and RSS memory (MB) at a configurable interval (default 2s). Emit metrics into:
  - periodic progress updates (jobs.progress.meta.resource: cpu_pct, rss_mb)
  - final job metrics blob
  Respect cgroup limits; if RSS approaches limit, emit WARN and throttle if configured; always include a final peak_rss_mb and avg_cpu_pct.
- Multi-stage Docker build for size optimization:
  - Stage “builder”: install build deps, fetch/install FreeCAD 1.1.0, build Python wheels (pip wheel -r requirements.txt).
  - Stage “runtime” (slim base): copy FreeCAD runtime, site-packages from wheels, worker_script.py, and minimal shared libs; run as non-root.
  - Use pip --no-cache-dir, remove *.a, tests, __pycache__, docs; apt-get clean and rm -rf /var/lib/apt/lists/*; strip binaries where safe.
  - CI step asserts no compiler/build tools present in final image and validates FreeCADCmd --version == 1.1.0.
- Acceptance additions:
  - requirements.txt matches pinned versions above; pip freeze in CI contains those exact versions.
  - GET /health/freecad returns 200 with freecad_version “1.1.0” and package versions.
  - Logs/progress include psutil metrics cpu_pct and rss_mb (MB) during runs; final metrics include peak_rss_mb.
  - Final image built via multi-stage; FreeCADCmd available; size reduced vs single-stage and contains no build toolchain.
</info added on 2025-08-24T15:57:18.229Z>
<info added on 2025-08-25T20:32:34.607Z>
Additions: comprehensive worker container implementation

FreeCAD 1.1.0 pinning and runtime
- Use FreeCAD 1.1.0 AppImage artifact (x86_64) in builder stage; verify SHA256 checksum and fail build if mismatch. Extract with: FreeCAD_1.1.0.AppImage --appimage-extract
- Copy only extracted usr/ subtree into runtime; set PATH=/opt/freecad/usr/bin:$PATH and symlink /usr/local/bin/FreeCADCmd -> /opt/freecad/usr/bin/FreeCADCmd
- Build arg FREECAD_SHA256 to lock artifact; CI validates FreeCADCmd --version == 1.1.0 exactly and checksum match
- Headless settings in runtime: FC_NO_UI=1, QT_QPA_PLATFORM=offscreen (fallback to minimal), OMP_NUM_THREADS=1, OPENBLAS_NUM_THREADS=1 to avoid CPU spikes
- Include minimal runtime libs for headless TechDraw (Qt, OCC, freetype, fonts); install basic fonts (e.g., fonts-dejavu-core) so TechDraw templates render correctly

Multi-stage Dockerfile (concrete shape)
- Stage builder:
  - apt-get install only what’s needed to run AppImage extraction and build wheels
  - curl -L FreeCAD_1.1.0.AppImage; echo "$FREECAD_SHA256  file" | sha256sum -c -
  - chmod +x; ./FreeCAD_1.1.0.AppImage --appimage-extract; mv squashfs-root /opt/freecad
  - pip wheel -r requirements.txt; strip symbols where safe
- Stage runtime:
  - base: debian:bookworm-slim (or distroless with glibc if feasible)
  - apt-get install: libgl1, libxrender1, libxext6, libfontconfig1, libfreetype6, fonts-dejavu-core, ca-certificates (no compilers)
  - COPY from builder: /opt/freecad, built wheels, worker_script.py, templates/
  - pip install --no-cache-dir wheels/*; remove tests, __pycache__
  - useradd -m freecad; USER freecad; WORKDIR /work; EXPOSE 8080
  - ENTRYPOINT ["FreeCADCmd","-c","/app/worker_script.py"]
- CI asserts:
  - no gcc/clang/make in final image
  - FreeCADCmd --version outputs exactly 1.1.0
  - image size reduced vs single-stage baseline

Health checks (extended)
- Harness flag/env: --health-server or HEALTH_SERVER=1 to enable
- GET /health/freecad returns 200 JSON with:
  - freecad_version, python_version, packages and versions (numpy, trimesh, pygltflib, minio, psutil)
  - techdraw: true if `import TechDraw` succeeds
  - headless_ok: true if `App.newDocument(); App.closeDocument()` works without GUI
  - cgroups: {memory_limit_mb, cpu_quota, cpu_period}
  - status: "ok" when all checks pass
- Implementation: do not open any viewers; only module import and lightweight document create/close

Resource monitoring and limits
- psutil loop at configurable interval (default 2s) capturing:
  - cpu_pct (process + children), rss_mb, io_counters (optional), num_threads
  - cgroup memory limit detection; warn when rss_mb > 85% of limit; throttle via time.sleep(backoff) if THROTTLE_ON_PRESSURE=1
- Hard limits:
  - RLIMIT_CPU set from --cpu-seconds; on softlimit signal, emit progress WARN and exit non-zero
  - Enforce memory via cgroup; on OOM impending (rss > 95% limit) attempt graceful abort with clear error code ERR-OOM
- Emit metrics in progress meta and final metrics: {avg_cpu_pct, peak_rss_mb, wall_ms}

TechDraw integration (headless technical drawings)
- Add optional drawing generation to all flows via flags or input.json:
  - CLI flags: --techdraw=on|off (default on), --td-template=/app/templates/A4_Landscape.svg, --td-views=Front,Right,Top,Isometric, --td-scale=1.0, --td-dpi=300, --td-fmt=pdf,svg
  - Input override (input.json): techdraw {enabled, template, views[], scale, dpi, formats[]}
- Implementation sketch inside worker:
  - Open or create FCStd; ensure Part/Body or Shape exist
  - import TechDraw; doc = App.ActiveDocument or App.newDocument()
  - page = doc.addObject("TechDraw::DrawPage","Page"); template = doc.addObject("TechDraw::DrawSVGTemplate","Template"); template.Template = td_template_path; page.Template = template
  - For each requested view name: v = doc.addObject("TechDraw::DrawViewPart","ViewX"); v.Source = [targetObject]; v.Direction = preset (Front=[0,0,1], Right=[1,0,0], Top=[0,1,0], Isometric=[1,1,1]); v.Scale = td_scale; page.addView(v)
  - doc.recompute()
  - Export: pdf_path = outdir + "/drawing.pdf"; svg_path = outdir + "/drawing.svg"; TechDraw.writePageAsPdf(page, pdf_path); TechDraw.writePageAsSvg(page, svg_path) as per requested formats
  - Save FCStd after adding TechDraw page so drawing is embedded
- Headless robustness:
  - Ensure QT_QPA_PLATFORM offscreen; ensure fonts are present; fall back to built-in template if provided template missing
  - If TechDraw unavailable, skip with WARN and continue model export (STEP/STL/GLB) without failing the job, unless techdraw.required=true in input
- Artefacts:
  - Attach generated PDF/SVG to job artefacts with sha256; include metadata {views[], scale, template_name}

Harness CLI and invocation (expanded)
- FreeCADCmd -c /app/worker_script.py --flow {prompt|params|upload|a4} --input /work/input.json --outdir /work/out --request-id {uuid} --cpu-seconds 600 --mem-mb 4096 --metrics-interval 2 --health-server --techdraw on --td-template /app/templates/A4_Landscape.svg --td-views Front,Right,Top --td-fmt pdf,svg
- Worker logs structured JSON lines including stage, msg, cpu_pct, rss_mb, progress_pct

Templates
- Include common TechDraw templates in image under /app/templates (A4_Landscape.svg, A3_Landscape.svg); allow custom template via MinIO/S3 URL resolved before run if network policy allows, else pre-bundle only

Acceptance additions (TechDraw and ops)
- Health: GET /health/freecad returns techdraw:true and headless_ok:true; freecad_version exactly "1.1.0"
- Parametric sample job produces drawing.pdf and drawing.svg with non-zero size; PDF contains the template page size and expected view count; artefacts sha256 recorded
- Logs include periodic cpu_pct and rss_mb; final metrics include peak_rss_mb and avg_cpu_pct
- CI validates AppImage checksum pin, absence of build toolchain in final image, and offscreen TechDraw import succeeds under FreeCADCmd

Operational safeguards
- Graceful cancellation: on cancel flag, finish current recompute/export step, persist partial artefacts, and exit with code 143
- Deterministic threading: set FreeCAD and OCC to single-threaded where configurable to reduce variance (OMP/OPENBLAS envs already set)
- Security: run as non-root, drop CAP_SYS_ADMIN; read-only root filesystem compatible (write only to /work and /tmp)
</info added on 2025-08-25T20:32:34.607Z>

## 6. Implement parametric modeling pipeline (example prism with hole) [pending]
### Dependencies: 7.3, 7.5
### Description: Translate canonical params to FreeCAD geometry and export artefacts for the params flow.
### Details:
Inputs: L,W,H,d, units(mm), material, machine; FreeCAD pseudo: newDocument, Part.makeBox, Part.makeCylinder, translate to center, cut, Part.show, recompute; save FCStd; export STEP via Import/Export, STL via Mesh; GLB preview via trimesh from STL; accept tessellation quality args; ensure deterministic recompute (no random seeds); acceptance: given sample params, pipeline outputs FCStd, STEP, STL, GLB with stable sha256 across runs, metrics present, and material-machine compatibility enforced.
<info added on 2025-08-25T20:01:12.866Z>
Production-ready implementation spec to replace the pseudo-pipeline, with deterministic exports, manufacturability checks, and standard parts:

FreeCAD worker (apps/api/app/services/freecad/worker_script.py)
- Entry: invoked under FreeCADCmd 1.1.0; hard-fail if version != 1.1.0. Enforce PYTHONHASHSEED=0 and SOURCE_DATE_EPOCH for reproducible artefacts.
- CLI: input JSON (stdin or file) with length, width, height, hole_diameter, units (mm), material, process/machine, and optional tessellation tolerance. Output JSON contains artefact paths, sha256, metrics, and validation report.
- Class FreeCADParametricGenerator: creates App.newDocument("parametric"), validates dims (0.1–1000 mm), generates prism with cylindrical hole (box cut cylinder, hole centered), recompute deterministic.
- Determinism controls: disable parallel boolean ops and multi-thread meshing via App.ParamGet, set fixed tessellation params, sort doc.Objects by Label before export.
- ResourceMonitor: monitors wall time (<=20s), RSS/CPU via psutil; cooperative cancel via SIGTERM; emits progress breadcrumbs.

Geometry validation (apps/api/app/services/freecad/geometry_validator.py)
- GeometryValidator.validate_manufacturability(shape, material, process) returns {valid, warnings, errors}.
- Ruleset examples:
  - Min wall (mm): aluminum 0.8, steel 0.5, abs 1.2, pla 0.8.
  - Injection molding: min_draft_deg 1.0–2.0 depending on material; flags faces below threshold.
  - Milling/CNC: basic tool accessibility check (approach along ±Z for 3-axis) and minimum internal fillet vs tool diameter.
  - 3D printing: overhang >45° flagged as needs support; bridges length >10 mm warned.
- Implementation notes: use face-to-face dist checks for wall thickness, normals for draft angle, ray tests for access, facet normals for overhangs. Failing errors block export; warnings pass with notes.

Standard parts (apps/api/app/services/freecad/standard_parts.py)
- StandardPartsLibrary.get_part(standard, size): supports parametric and S3-backed templates. Caches downloads locally (read-only).
- Initial coverage:
  - DIN933 Hex screw: size "M{d}x{l}" parsed; shaft cylinder (major diameter), simplified hex head fused.
  - DIN625 Bearing: generates raceways and balls simplified as revolved profiles; or pulls template by size when listed in catalog.
- Extendable catalog with parametric and templates sections; errors include known keys.

Deterministic exporter (apps/api/app/services/freecad/exporter.py)
- DeterministicExporter.export_all(base_path):
  - FCStd: saveAs then repack deterministically (ZIP_STORED, sorted entries, fixed mtime from SOURCE_DATE_EPOCH, strip volatile thumbnails) before hashing.
  - STEP: fixed schema (AP214), stable write params; export sorted objects; no namespacing timestamps.
  - STL: fixed mesh params (linear deflection and angular deflection set explicitly); single precision; binary STL.
  - GLB: via trimesh from STL with fixed scene graph, no metadata, stable material and quantization; write binary glb.
- Returns per-format sha256; all formats idempotent across runs given same inputs and environment.

Metrics extraction
- extract_metrics(shape): solids, faces, edges, vertices, volume_mm3, area_mm2, bbox (x,y,z), center_of_mass. Values rounded to 1e-6 in JSON; test assertions use ±0.001 tolerance.

Material–machine compatibility
- Enforce mapping (examples): injection_molding ↔ thermoplastics only; milling/cnc ↔ metals and machinable plastics; 3d_printing ↔ PLA/ABS/PETG/NYLON; incompatible combinations return 409 with hints.

i18n and Turkish prompts
- Normalizer maps TR synonyms to canonical params (uzunluk→length, genişlik→width, yükseklik→height, delik çapı→hole_diameter, malzeme→material, makine/süreç→machine/process). Unit synonyms supported (mm). Verified E2E: Turkish inputs produce correct geometry and identical hashes.

Operational notes
- Deterministic seeds and environment: set PYTHONHASHSEED=0; set SOURCE_DATE_EPOCH to a fixed integer; ensure locale-invariant formatting.
- Logging: structured JSON with version, inputs hash, rule hits, artefact hashes. No PII; truncation for large warnings arrays.
- Failure modes: validation errors return detailed reasons; geometry kernel failures retried once with clean doc; timeouts kill process tree.

Acceptance criteria for this subtask
- FreeCADCmd 1.1.0 verified at startup; mismatch causes immediate failure.
- Given sample params (e.g., length 100, width 50, height 30, hole_diameter 10, material=aluminum, process=milling), pipeline produces FCStd, STEP, STL, GLB whose sha256 values are stable across runs on identical environment.
- GeometryValidator catches manufactured rule violations with correct categorization (errors vs warnings).
- Standard parts library serves at least DIN933 and DIN625 correctly; parametric vs template resolution validated.
- Exporter produces identical hashes across runs; FCStd repack eliminates time-based drift.
- Metrics match golden values within ±0.001 for volume, area, bbox, and center_of_mass.
- Turkish prompts routed through normalizer generate the expected geometry and artefact hashes.
</info added on 2025-08-25T20:01:12.866Z>
<info added on 2025-08-25T20:25:34.800Z>
Assembly4 workbench implementation (apps/api/app/services/freecad/a4_assembly.py)
- Mode: worker_script.py supports mode="assembly4". Input JSON defines assembly tree with components, LCS definitions, and joints; output JSON augments artefact paths/hashes with BOM, DOF, kinematics, and collision reports.
- Lightweight references: use App::Link for components to avoid shape duplication. Sources per component:
  - parametric: generated via FreeCADParametricGenerator then linked
  - standard: fetched via StandardPartsLibrary.get_part(...)
  - upload_ref: normalized/imported model then linked
  All Links use relative paths within the document and stable Labels/Names (sorted, canonical).
- LCS placement: each component owns LCS frames (PartDesign::CoordinateSystem) created deterministically from input. Joints reference LCS by name (component_id.lcs_name). Initial placements applied via App::Placement; transforms expressed in mm and degrees.
- Constraint solving: integrate OndselSolver (py_slvs). Build a constraint graph from LCS pairs and joint types; solve for placements with fixed numerical tolerances (linear 1e-6 mm, angular 1e-5 rad). Deterministic solve order by sorted component/joint IDs. Retry once if kernel dirty, then fail with structured errors.
- Joint types and mapping:
  - Fixed: 0 DOF; coincident origins and aligned axes (all axes)
  - Revolute: 1 DOF; co-axial Z with coincident origins; limit angle [min_deg, max_deg]
  - Cylindrical: 2 DOF; co-axial Z with free translation along Z and rotation about Z; limits: [z_min_mm, z_max_mm], [ang_min_deg, ang_max_deg]
  - Slider (Prismatic): 1 DOF; Z axes parallel and coincident; limit [z_min_mm, z_max_mm]
  - Ball (Spherical): 3 DOF; coincident origins; optional Euler/axis-angle limits per axis
  - Planar: 3 DOF; coincident planes (Z normals aligned); in-plane x/y translation + rotation about Z; limits for x/y and angle
  Joint inputs support stiffness/damping placeholders for future dynamics; currently kinematic only.
- DOF analysis and mobility: compute via solver Jacobian rank and Gruebler-Kutzbach cross-check. Report global DOF count, per-joint DOF, over-/under-constraint diagnostics, and list of driving joints (independent set).
- Kinematic simulation:
  - Inputs: drivers array selecting joints with stepping parameters (start, end, step, easing=linear), joint limits enforced hard
  - Process: iterate driver steps, solve at each frame; abort on non-convergence or limit violation
  - Outputs: keyframes with component placements, per-frame valid flag, and solver residuals
- Collision detection (apps/api/app/services/freecad/collision.py):
  - Broad phase: component AABBs from tessellated shapes (fixed mesh params) using BVH; track potentially colliding pairs
  - Narrow phase: for candidate pairs compute BRepAlgoAPI_Common; collision if intersection volume > 0 (threshold 1e-6 mm3). Record contacts (pair IDs, volume, bbox)
  - Modes: assemble_validate (fail on any collision), simulate_allow (warn and flag frames)
- Animation export:
  - Generate animation manifest (JSON) with keyframes per component (placements per t)
  - Optional GLB sequence: write GLB per frame using DeterministicExporter (scene graph order stable); hashes stable across runs
- BOM extraction (apps/api/app/services/freecad/bom.py):
  - Traverse assembly tree (including nested App::Link) to collect items; group by source fingerprint (sha256 of referenced FCStd/STEP + config), size, material, finish
  - Output JSON and CSV with qty, designation, standard (if any), refdes path (e.g., A1/B2/C3), and mass if density available; deterministic ordering
- Exploded view (apps/api/app/services/freecad/exploded_view.py):
  - Inputs: per-component offset vectors or auto mode (radial from assembly COM avoiding initial collisions)
  - Produce an Exploded group with cloned Links placed at exploded positions; export GLB/STEP snapshots; store exploded_offsets in output JSON
- Multi-level assemblies:
  - Support nested assemblies by linking entire sub-assembly documents (App::Link to App::Part/Body). Cache loaded sub-assemblies read-only; prevent cycles
  - Constraints may reference LCS within nested Links using path addressing (comp.subcomp.lcs)
- Determinism and performance:
  - Stable naming, sorted traversal, fixed tolerances, SOURCE_DATE_EPOCH respected; PYTHONHASHSEED=0
  - Wall time budget shared with ResourceMonitor (<=20s); kinematics may downsample frames to fit budget
- API/Schema (assembly mode):
  - assembly: {name, units, components:[{id, source:{type:parametric|standard|upload_ref, spec:{}}, lcs:[{name, origin:[x,y,z], axes:{x:[...],y:[...],z:[...]}}], initial_placement:{pos:[x,y,z], rot_euler_deg:[rx,ry,rz]}}], joints:[{id, type, a:{comp_id,lcs}, b:{comp_id,lcs}, limits:{}, initial:{}}], drivers:[{joint_id, param:angle|z|x|y, start, end, step}]}
  - Options: simulation:{enable:true, frames_max}, collision:{mode}, exploded:{offsets|auto:true}
- Exports and metrics:
  - Export FCStd, STEP (AP214), STL, GLB for assembled state; optional GLB sequence for simulation/exploded
  - Metrics: parts_count, unique_items, joints_count by type, global_dof, overconstrained:boolean, collision_pairs, envelope_bbox, mass_estimate if densities known
- Logging: structured JSON includes assembly inputs hash, joint map, DOF results, collisions, BOM digest, artefact hashes; truncate large arrays

Acceptance criteria (Assembly4)
- Given a sample assembly with a base prism and a DIN933 M6x20 screw constrained via Revolute + Slider (cylindrical emulation) and a Fixed joint to plate, solver converges deterministically; DOF analysis reports expected mobility; placements repeat across runs
- Kinematic simulation with a Revolute joint stepping 0→90° in 10° increments generates keyframes, respects joint limits, and exports a deterministic GLB sequence (stable sha256 per frame)
- Collision detection flags an intentional interference case (intersection volume > 0) and passes when offsets are adjusted; AABB prefilter reduces candidate pairs
- BOM groups identical screws via App::Link targets and reports correct quantities with deterministic ordering; CSV/JSON hashes stable
- Exploded view generation produces exploded GLB and STEP snapshot with provided or auto offsets; offsets recorded in output JSON
- Multi-level assembly with a nested sub-assembly (bearing DIN625 + shaft) resolves Links and constraints correctly; no cycles; exports have stable hashes across runs
</info added on 2025-08-25T20:25:34.800Z>

## 7. Upload flow normalization and validation [pending]
### Dependencies: 7.3, 7.5
### Description: Process uploaded CAD files: unit conversion, orientation normalization, optional manifold repair, and validation.
### Details:
Inputs: object_storage_ref (S3 key), declared units/or auto-detect; load STEP/IGES/STL into FreeCAD/trimesh; convert to mm, orient Z-up, center or preserve origin based on flag, weld/merge; optional trimesh.repair (fill holes, remove degenerate faces); validate geometry (manifoldness, min wall where inferable), reject corrupted STEP with 422 and remediation hints; acceptance: sample corrupted STEP returns 422 with hints, valid uploads produce normalized outputs and GLB preview.
<info added on 2025-08-25T20:33:48.521Z>
Extended format coverage and workbench integration (FreeCADCmd/headless-safe):
- STEP/IGES:
  - Import: use Part.read for single-shape or Import.open for multi-body; detect units via STEP/IGES headers; heal with Shape.fix(), removeSplitter(), and tolerance cleanup; merge coincident edges.
  - Export: Import.export([...], .step/.iges). On malformed topology (self-intersections, bad pcurves) return 422 ERR-STEP-TOPOLOGY with hints to re-export with sewing/tolerances.
- STL/OBJ:
  - Import: Mesh.Mesh(path); optional MeshPart.meshToShape for analytic conversion when manifold; otherwise keep mesh and validate via trimesh (watertight, normals, degenerate faces).
  - Export: Mesh.export([...], .stl); ensure units normalized to mm; write GLB preview via trimesh.glb.
- DXF (2D):
  - Import: Draft DXF importer (importDXF) with ezdxf backend; read $INSUNITS to auto-scale; place geometry on XY; group by layers.
  - Normalize: optional 2d_mode.extrude_thickness (default 0.5 mm) to generate thin solids for GLB/manifold checks; otherwise mark as 2D and skip manifold test but still produce GLB by meshing wireframes to thin faces.
  - Export: Draft.export([...], .dxf) with layer and color preservation; SVG/PNG 2D previews generated for convenience in addition to GLB.
- IFC (BIM):
  - Import: prefer importIFC (IfcOpenShell required); fallback returns 422 ERR-IFC-DEP-MISSING with install hint. Extract project unit (meters) and convert to mm; preserve Z-up world CS.
  - Geometry: convert Arch/Ifc objects to Part solids where possible; triangulate via IfcOpenShell geom when BREP not available; weld meshes; map BuildingStorey → Part groups.
  - Metadata: keep IfcGUID, IfcClass, and Pset materials to document properties; attach Arch Site/Building hierarchy.
  - Export: importIFC.export for solids with basic class mapping (Wall, Slab, Column). On export failure return 422 ERR-IFC-EXPORT with class mapping suggestions.
- DXF/IFC preferences in headless:
  - Set BaseApp/Preferences/Import-Export/DXF scale and projection; ensure Draft precision settings applied. Verify importDXF and importIFC available in FreeCADCmd.

Draft and Arch usage:
- Draft: layer-aware DXF import/export; wire cleanup (Draft.upgrade/downgrade) before optional extrusion; tolerance join for polylines; text/hatches retained as annotations (excluded from solids).
- Arch: retain BIM semantics for IFC; Arch BuildingPart hierarchy preserved; convert to Part solids for downstream metrics; optional silhouette extraction via Draft.makeShape2DView for 2D previews.

Material system (.FCMat):
- Input accepts material name or path; resolve via Materials module lookup (system and user libraries); fallback map (Aluminum 6061-T6, Steel AISI 1018, PLA).
- Load FCMat, create App::MaterialObject, assign to solids; compute mass from Part volume × density; include material name, density, mass in metrics and artefact metadata.
- If material missing, return 422 ERR-MATERIAL-NOTFOUND with suggestions (nearest matches) and example library paths.

Units, orientation, and normalization (all formats):
- Units: detect from source (STEP/IGES header, IFC project units, DXF $INSUNITS); STL/OBJ unitless → infer by bbox heuristics with guardrails; always convert to mm internally.
- Orientation: IFC/DXF assumed Z-up; STEP/IGES/STL auto-rotated to Z-up if flag set; center or preserve origin per input flag.
- Merging: fuse coincident faces/edges; mesh welding; deduplicate bodies by geometric hash to reduce duplicates.

Validation and error model by format:
- Common checks: bbox sanity, zero/near-zero thickness detection (when inferable), self-intersections, non-manifold edges for meshes, shell closure for solids.
- Format-specific 422 with remediation hints:
  - ERR-STEP-TOPOLOGY, ERR-IGES-CURVES-UNTRIMMED, ERR-STL-NOT-MANIFOLD, ERR-DXF-UNITS-UNKNOWN, ERR-IFC-DEP-MISSING, ERR-IFC-GEOM-FAIL, ERR-MATERIAL-NOTFOUND.
- Hints include: re-export settings (sew/solidify, mm units), installing IfcOpenShell, DXF units header fix, reducing facet tolerance, or supplying extrude_thickness for 2D DXF.

Turkish localization (server-side messages):
- Honor Accept-Language; when tr or tr-TR, return localized messages for validations and hints using a message catalog.
- Example keys:
  - upload.ok: "Yükleme başarılı. Geometri normalleştirildi ve önizleme hazır."
  - err.step.topology: "STEP topolojisi hatalı. CAD yazılımınızda 'Sew/Solidify' ile yeniden dışa aktarın ve toleransı düşürün."
  - err.iges.untrimmed: "IGES yüzeyleri budanmamış. NURBS budama seçeneklerini etkinleştirip yeniden dışa aktarın."
  - err.stl.nonmanifold: "STL çokyüzlü kapalı değil veya katı değil. Delikleri kapatıp yeniden dışa aktarın."
  - err.dxf.units: "DXF birimleri belirlenemedi. Lütfen $INSUNITS değerini ayarlayın veya yüklemede birim belirtin."
  - err.ifc.dep: "IFC içe aktarması için IfcOpenShell gerekli. Sunucuya IfcOpenShell kurulumunu yapın."
  - err.material.missing: "Malzeme bulunamadı. En yakın eşleşmeler: {candidates}."
- Default to English when no Turkish preferred; include error_code and localized message in response.

Artifacts and outputs (per successful upload):
- FCStd with structured tree (Draft/Arch groups when applicable).
- Normalized STEP, STL; DXF (if source 2D exists); IFC when source was IFC or BIM semantics preserved.
- GLB preview generated from unified mesh; for pure 2D DXF, thin-extrusion GLB or 2D preview bundle (SVG/PNG).
- Metrics: bbox (mm), volume (mm^3), surface area (mm^2), triangle count (GLB), material and mass when available.

Tests and acceptance (expand):
- Provide sample files for each format; assert mm units, Z-up orientation, and artefacts saved with hashes.
- IFC without IfcOpenShell → 422 ERR-IFC-DEP-MISSING with Turkish and English messages.
- DXF without units → 422 ERR-DXF-UNITS-UNKNOWN unless unit provided; with extrude_thickness → GLB contains thin solids.
- Material mapping applies density and mass within ±1% of expected for known samples.
</info added on 2025-08-25T20:33:48.521Z>

## 8. Assembly4 JSON parser and constraint handling [pending]
### Dependencies: 7.3, 7.5
### Description: Parse A4-style inputs, place parts using LCS/placements, and run basic collision checks.
### Details:
Input schema: parts (model_ref, LCS names), constraints (Attachment, AxisCoincident, Angle, Offset), root LCS; load referenced parts (STEP/FCStd) into doc, apply placements, build hierarchy; collision check via AABB first, report pair list; save assembly FCStd, export formats; acceptance: given sample assembly JSON, placements applied as specified, collisions flagged, outputs generated.
<info added on 2025-08-25T20:03:03.039Z>
Production-grade Assembly4 implementation with OndselSolver:

- Assembly4 parser and validator:
  - Parse A4 JSON with keys: parts (id, model_ref, optional initial_placement, lcs array), constraints (type, references to part/LCS entities), lcs_definitions, hierarchy/root LCS.
  - Load referenced parts (STEP/FCStd) into the working document; extract and index LCS by name; ensure uniqueness of part ids and existence of all referenced LCS/parts.
  - Normalize placements to FreeCAD Placement (mm, radians). Validate at least one grounded reference (root LCS or fixed base).
  - Supported constraints: Attachment, AxisCoincident, PlaneCoincident, PointOnLine, Angle, Offset. Validate arity and entity types per constraint. Provide clear 4xx errors for missing/invalid references.

- OndselSolver integration (with fallback):
  - Wrap py_slvs (Ondsel) when available; otherwise use deterministic fallback solver (direct placements for Attachment, simple axis/plane alignment where resolvable).
  - Model each part as a rigid body (6 DOF). Map constraints to solver primitives and assemble a system; solve and extract per-part placements.
  - Detect and report solver status; on failure include offending constraints in diagnostics; no partial writes on failure.

- Collision detection:
  - Two-phase check with tolerance 0.01 mm: AABB broad phase to prune pairs, then precise check via Part boolean common; fallback to distToShape when boolean fails.
  - Output each interference with part1 id, part2 id, type (interference/overlap), and volume if available.

- Assembly builder:
  - Create App::Part “Assembly” and per-part App::Link objects linked to the loaded source objects; apply solved placements to links.
  - Recreate LCS markers under each link for inspection. Apply basic visibility rules (hide source bodies; show links and LCS markers as configured).

- Degrees of freedom analysis:
  - Compute DOF = 6 × parts minus reductions per constraint type: Attachment 6, PlaneCoincident 3, AxisCoincident 4, PointOnLine 2, Angle 1.
  - Report total_dof, is_fully_constrained, is_over_constrained, mobility.

- Export and artefacts:
  - Save assembled FCStd; export merged STEP of the resolved assembly.
  - Generate an exploded view document and save as a separate FCStd.
  - Extract BOM (part id, name, source, quantity) and write bom.json.

- Acceptance criteria (augment existing):
  - A4 JSON parsed and validated, including LCS extraction and constraint references.
  - OndselSolver computes consistent placements; deterministic fallback used if py_slvs is unavailable.
  - Collision detection flags all interferences with types and volumes where applicable.
  - DOF analysis correctly identifies fully/under/over-constrained states.
  - Hierarchy built using App::Link with solved placements and LCS markers present.
  - BOM includes all parts with correct quantities; exploded view generated and saved.
  - Outputs present: assembly.FCStd, assembly.step, exploded.FCStd, bom.json.
</info added on 2025-08-25T20:03:03.039Z>
<info added on 2025-08-25T20:26:30.306Z>
CAM generation via FreeCAD Path Workbench (post-assembly):

- Job creation:
  - Create Path Job from assembled FCStd; select WCS from root or named LCS (fallback to model origin) and set G54 with optional XYZ offsets and Z-up orientation.
  - Stock setup: box/cylinder/from-shape with user margins; link units to mm; set safety/clearance/rapid heights at job level defaults.

- Tool library and feeds/speeds:
  - Integrate tool library (endmills, ball, drill, chamfer) with material lookup; compute spindle RPM and feed rates from surface speed and chip load; override per-operation allowed.
  - Validate tool-geometry vs operation (diameter vs feature width/depth); flag violations as 409 CAM_LIMIT_EXCEEDED.

- Operations supported:
  - Facing, Profile (Contour/Outer/Inner), Pocket (islands), Drilling (peck/spot), Adaptive (clearing), Helix (ramp/entry), Engrave (on edges/text).
  - Strategies: ZigZag, Offset, Spiral; cut mode Climb/Conventional; finish pass and step-over controls.
  - Depth control: step-down, final step, top/bottom heights, rapid and clearance heights; ramp/lead-in/out where applicable.

- Sequencing and optimization:
  - Order operations to minimize tool changes (group by tool, preserve roughing→finishing and per-setup WCS consistency); merge contiguous same-tool ops when safe.

- Coolant and spindle control:
  - Emit M3/M4 with computed RPM, M5 on stop; coolant M7/M8 per-operation and M9 on toolchange/end; include optional dwell on spindle start.

- Post-processing:
  - Supported posts: LinuxCNC, GRBL, Mach3/4, Haas, Fanuc, Siemens; map to file extensions (.ngc/.nc/.tap as appropriate); metric output, absolute coordinates, G17/G21/G90 headers, tool length comp optional.
  - Insert metadata comments (job id, tool list, estimated time, stock/WCS).

- Simulation and estimation:
  - Generate toolpaths with Path.Area; simulate and verify no gouges against stock boundaries.
  - Time estimation: sum linear/arcs at feed, rapids at machine rapid, include toolchange overhead and optional dwell; report per-operation and total.

- Artefacts and validation:
  - Save job-updated FCStd with Path objects; export per-post G-code; write cam_report.json (tools, ops, feeds/speeds, time estimates).
  - Static G-code validation: forbid unsupported or unsafe M-codes for target post/machine; ensure spindle/coolant states are balanced.

- Acceptance:
  - Given a sample prism model and stock, all listed operations generate valid toolpaths; sequencing reduces tool changes; posts produce syntactically valid G-code with correct M-codes; simulation runs without errors; time estimate within ±15% of simulated runtime; artefacts present: job.FCStd, *.nc/*.tap per post, cam_report.json.
</info added on 2025-08-25T20:26:30.306Z>

## 9. Unified export pipeline with version pinning (FCStd, STEP, STL, GLB) [pending]
### Dependencies: 7.5
### Description: Standardize exports and ensure deterministic, versioned outputs for all flows.
### Details:
Pin FreeCAD 1.1.x and Python deps; export FCStd native; STEP via Import/Export with fixed write parameters (schema AP214/AP242); STL using Mesh with fixed linear/angle deflection; GLB via trimesh conversion from STL with fixed transforms and quantization off; record exporter versions in artefact metadata; acceptance: same input produces identical hashes across runs in CI, and metadata includes version/tolerances.
<info added on 2025-08-25T20:34:58.319Z>
- FreeCAD Export module usage (headless): use Import.export([obj], path) with extension-driven dispatch for STEP/IGES; Mesh.export([mesh], path) for STL; App.getDocument(doc).saveAs(fcstd_path) for native. Always pass a stable, pre-sorted list of top-level objects (sort by Name, then Label) and freeze document state (doc.recompute(); doc.save(); setReadOnly) before export to avoid recompute drift.
- Mesh operations: triangulate solids via MeshPart.meshFromShape(Shape=shape, LinearDeflection=LD, AngularDeflection=AD, Relative=False, Parallel=False) to avoid thread nondeterminism; merge meshes in deterministic order; ensure normals computed and consistent winding; export Binary STL with a constant 80-byte header and fixed endianness; ASCII STL disabled. Record LD/AD and Relative flags in metadata.
- STEP specifics: call Import.export with .step/.stp and schema forced to AP214 or AP242; post-process the STEP header to canonicalize FILE_NAME author, organization, timestamp, and FILE_SCHEMA to fixed values; normalize line endings to LF; remove variable comment lines. Ensure unit system is millimeter; map colors/labels deterministically when present.
- GLB pipeline: build trimesh from the STL mesh in fixed transform order (apply Placement matrix with deterministic rounding), preserve vertex/face ordering, include normals and materials if present, disable quantization/compression and timestamp fields; set asset.generator to a constant string and extras to a canonical dict; export as binary .glb.
- Spreadsheet integration (parametric data): detect all Spreadsheet::Sheet objects; extract cell values, aliases, and unit-aware quantities via Units API; generate a sorted param map {alias -> {value, unit}} and persist as a JSON sidecar and embed where supported (GLB extras). Lock expressions evaluation by recomputing once before readout. Include a stable hash of the param map in artefact metadata.
- Plot module for visualization: if Plot (matplotlib) is available, generate deterministic PNGs for key param trends and bounding-box dimensions using backend Agg with style “classic”, fixed DPI, figure size, font family, and seeded randomness; filenames and series ordering are canonical. Store plot metadata (backend, style, DPI, size) and sha256.
- Render/Raytracing support (optional): if Render or legacy Raytracing WB is present, export renderer scene files (e.g., POV-Ray/LuxCore) with fixed camera pose, FOV, image size, materials, and light rig; set samples and renderer seed to constant; invoke external renderer only if available headless. Record engine, version, seed, samples, and resolution; skip gracefully if modules are absent.
- Determinism techniques (cross-cutting): set locale to C and timezone to UTC; seed Python’s random and NumPy; disable parallel meshing; canonicalize float formatting and transform matrices (round to fixed precision before export); normalize object visibility; export in single process; ensure stable object and layer ordering; strip or fix any exporter-generated dates, GUIDs, or machine/username fields; normalize newlines to LF for text formats.
- Version pinning and provenance: run inside a pinned Docker image with FreeCAD 1.1.x CLI (FreeCADCmd) and frozen Python deps; capture FreeCAD App.Version, build hash, and OCCT version (from Part if available), plus numpy, trimesh, matplotlib, and Python versions. Persist full exporter provenance in artefact metadata alongside tolerances/deflections and schema choices.
- Acceptance expansion: identical inputs yield byte-identical FCStd/STEP/STL/GLB and identical plot/render PNGs across CI runs on the pinned image; STEP headers and STL binary headers are canonicalized; metadata includes exporter provenance, mesh tolerances, STEP schema, GLB options, spreadsheet param hash, and determinism flags.
</info added on 2025-08-25T20:34:58.319Z>

## 10. Metrics extraction and runtime telemetry [pending]
### Dependencies: 7.5, 7.9
### Description: Compute model metrics and durations, and attach to jobs.
### Details:
Metrics: solids, faces, edges (TopoShape), triangle count from STL, bounding box, volume (if closed), mass (if density from material), duration_ms; capture worker CPU/RAM peak when available; store metrics JSON in jobs table and emit structured logs with request_id; acceptance: metrics fields populated for all flows, values match golden within tolerance.
<info added on 2025-08-25T20:35:48.563Z>
Comprehensive metrics extraction plan:
- Shape analysis (FreeCAD Part/TopoShape): compute solids=len(shape.Solids), faces=len(shape.Faces), edges=len(shape.Edges). Bounding box via shape.BoundBox with XLength/YLength/ZLength and Center; include bbox_min/max arrays. Volume: if shape.isClosed() and/or shape.Solids present, sum solid.Volume. Record surface_closed=false if not computable.
- Triangle count: prefer STL produced in 7.9. If binary STL, read 4-byte count from header; else load via Mesh.Mesh(stl_path) and use mesh.CountFacets(). Record stl_params used (linear_deflection, angular_deflection, relative) to ensure reproducibility.
- Units system: normalize internal storage to SI (length_m, volume_m3, mass_kg). Detect input/display schema from job (e.g., mm, inch) and convert using FreeCAD.Units (Quantity, schema). Persist numeric values in canonical SI with decimal point. Provide optional display snapshot in requested schema (e.g., length_mm, volume_mm3) for convenience.
- Material properties: resolve density in order: object.Material (App::MaterialObject or property bag) → document material card → job.material. Normalize density to kg/m^3 from common inputs (kg/m^3, g/cm^3, g/mm^3). Mass = volume_m3 * density_kg_m3 when volume present; otherwise null. Include material_name, density_source, density_raw and density_kg_m3 in metrics for traceability.
- Performance telemetry: duration_ms via monotonic/perf_counter around the whole flow and per-phase (open, analyze, export STL, triangulate). Capture CPU and memory using psutil/resource: cpu_user_s, cpu_system_s, cpu_percent_peak, ram_peak_mb (ru_maxrss converted to MiB). Also include worker pid, hostname, thread_id, and queue name.
- Deterministic rounding: apply Decimal with ROUND_HALF_EVEN and fixed quantization before serialization: length_m to 1e-9, volume_m3 to 1e-12, mass_kg to 1e-9. Do not round integer counts. Ensure stable ordering of JSON keys and invariant float→string conversion. Record metrics_version and stl_params hash to enable golden comparison.
- Turkish localization (display layer only; stored JSON remains locale-neutral): provide i18n map for metric labels and units. tr-TR keys: solids=Katılar, faces=Yüzeyler, edges=Kenarlar, triangles=Üçgen sayısı, bbox=Sınır kutusu, width=Genişlik, height=Yükseklik, depth=Derinlik, volume=Hacim, mass=Kütle, material=Malzeme, density=Yoğunluk, duration_ms=Süre (ms), cpu_user_s=CPU kullanıcı (sn), cpu_system_s=CPU sistem (sn), cpu_percent_peak=CPU tepe (%), ram_peak_mb=Bellek tepe (MB), units=Birimler. For TR display, format decimals with comma separator and localized unit suffixes; no impact on stored SI values.
- Error handling: if any metric cannot be computed, set null and append a warnings[] entry with code and message. Never block artefact exports on metrics failure.
- Storage and logs: persist metrics JSON under jobs.metrics with request_id and metrics_version. Emit structured JSON logs at start/end with job_id, request_id, timings, and a compact metrics_summary. Include sha256 of STL used for triangle count.
- Acceptance additions: verify SI canonical values within tolerance (length ±1e-9 m, volume ±1e-12 m^3, mass ±1e-9 kg), triangle_count matches STL header exactly, and TR localization renders expected labels when Accept-Language=tr-TR.
</info added on 2025-08-25T20:35:48.563Z>

## 11. Artefact storage and linking to jobs [pending]
### Dependencies: 7.4, 7.9, 7.10
### Description: Upload artefacts to object storage and persist DB records linked to job lifecycle.
### Details:
MinIO/S3 integration with bucket models; path scheme jobs/{job_id}/{artefact}.{ext}; set content-type and metadata (sha256, exporter version, request_id); compute sha256; insert artefacts row with FK to jobs and cascade on job delete; generate presigned URLs for download; acceptance: artefacts uploaded, DB rows created, sha256 logged, presigned URLs work and expire.
<info added on 2025-08-25T20:38:50.618Z>
Comprehensive artefact storage implementation:

- Object storage client
  - Support AWS S3 and MinIO via configurable endpoint, region, and credentials; force path-style addressing for MinIO; Signature V4 only; TLS required.
  - Timeouts and retries: connect 5s, read 60s, max_retries 3 with exponential backoff and jitter; connection pool tuned for workers.
  - Server-side encryption: SSE-S3 by default; allow SSE-KMS (configurable key ID) in cloud; block all public ACLs and enforce bucket policies denying anonymous access.
  - Multipart uploads: threshold 32 MiB, part size 16 MiB, parallelism 4–8; ensure abort of incomplete multipart on errors.

- Versioning and retention
  - Enable bucket versioning; persist object VersionId for every artefact write and use version-specific reads for immutability.
  - Overwrites create new versions; DB keeps latest pointer per logical artefact while retaining historical versions for audit.
  - Deletion uses version-aware API (delete specific VersionId); soft-delete creates a delete marker when required by policy.

- Lifecycle and cost controls
  - Rules:
    - AbortIncompleteMultipartUpload after 7 days.
    - Transition noncurrent versions to STANDARD_IA after 30 days; expire noncurrent versions after 180 days.
    - Current versions of transient artefacts (e.g., previews) expire after 90 days; core design files retained indefinitely unless job is deleted.
  - MinIO ILM parity rules configured where supported; document differences vs AWS S3.

- Metadata and headers
  - Content-Type detection via extension and magic sniffing; set Content-Disposition appropriately (inline for images/video, attachment for CAD/CAM files).
  - Standard mappings:
    - .fcstd: application/zip
    - .step/.stp: model/step (fallback application/step)
    - .stl: model/stl
    - .glb: model/gltf-binary
    - .nc/.tap/.gcode: text/plain; charset=utf-8
    - .json: application/json
    - .png: image/png
    - .mp4: video/mp4
    - .pdf: application/pdf
  - Persist ETag and note multipart caveat (ETag != sha256); compute and store sha256 separately. Store storage request IDs (x-amz-request-id, x-amz-id-2 or MinIO equivalents) for audit.

- Presigned URLs
  - Generate version-specific presigned GET (default TTL 15 minutes; allow 1–1440 minutes via policy); optionally include response-content-disposition.
  - Provide HEAD presign for clients to validate availability without download.
  - Enforce least privilege by signing with read-only credentials/role; support IP range and content-type constraints when backend allows.
  - Revocation strategy: rotate credentials and/or delete object/version; short TTLs by default.

- Database model and relations
  - artefacts table additions: key, bucket, region, version_id, etag, size_bytes, content_type, storage_class, sha256, exporter_version, request_id, created_at.
  - Foreign key: artefacts.job_id → jobs.id ON DELETE CASCADE; unique constraint on (job_id, logical_name, version_seq) or (job_id, key, version_id) to prevent duplicates; indexes on (job_id), (sha256), and (created_at).
  - Audit link: store storage request IDs and operation type for traceability in the audit chain.

- Deletion and garbage collection
  - On job delete, enqueue artefact_gc task to remove all object versions and delete markers for that job; tolerate missing objects and retry with backoff.
  - If storage delete fails, mark artefact as deletion_pending with last_error; periodic GC retries until success; respect retention policies where mandated.

- Turkish localization (tr-TR)
  - i18n keys and translations:
    - artefacts.upload.success: Yükleme tamamlandı.
    - artefacts.upload.failed: Yükleme başarısız.
    - artefacts.not_found: İstenen artifakt bulunamadı.
    - artefacts.presign.expired: İmzalı bağlantı geçersiz veya süresi dolmuş.
    - artefacts.type.unsupported: Dosya türü desteklenmiyor.
    - storage.unavailable: Nesne depolama hizmetine ulaşılamıyor.
    - storage.delete.pending: Silme işlemi planlandı.
    - storage.delete.failed: Silme işlemi başarısız; daha sonra tekrar denenecek.
    - job.link.missing: İlgili iş kaydı bulunamadı.
  - Locale fallback en-US; ensure message keys are used in API responses and logs.

- Security and compliance
  - PII-free metadata only; keys and metadata must not contain secrets.
  - Bucket policy blocks public access; audit log includes hash of storage metadata.
  - Optional per-tenant bucket prefixing or separate buckets; isolation validated in tests.

- Testing and acceptance (additional)
  - Bucket versioning enabled; DB persists version_id; reading via version-specific presigned URL returns correct bytes.
  - Lifecycle rules present: incomplete multipart cleanup, noncurrent transition/expiry; verify via bucket policy inspection and simulated objects.
  - Content-Type set according to mapping for all artefact types; Content-Disposition correct for inline vs attachment.
  - Presigned URLs expire as configured; HEAD presign works; optional constraints (IP/content-type) honored when enabled.
  - Deleting a job cascades DB rows and triggers GC; all object versions removed; artefact_gc is idempotent.
  - Turkish localization strings load correctly; API returns tr-TR messages when Accept-Language=tr-TR is provided.
</info added on 2025-08-25T20:38:50.618Z>

## 12. Error handling, code mapping, and user suggestions [pending]
### Dependencies: 7.3, 7.5, 7.9
### Description: Create a unified error taxonomy and map worker exceptions to actionable API errors.
### Details:
Map: Ambiguous→425, ERR-AI-422 AI_HINT_REQUIRED, VALIDATION_4xx for rules, FC_RUNTIME for FreeCAD errors, STORAGE_5xx for IO; include 'suggestions' array (e.g., increase wall thickness to >= min, choose compatible machine/material, reduce part size) and 'remediation_links'; ensure logs capture exception class and traceback but mask PII; acceptance: errors return correct HTTP/code, include suggestions, and logs correlate with request_id.
<info added on 2025-08-25T20:39:55.181Z>
Comprehensive implementation plan

1) Error taxonomy and code→HTTP mapping (FreeCAD-focused)
- AI_AMBIGUOUS → 425; user must clarify prompt
- AI_HINT_REQUIRED → 422; required info missing for AI normalization
- VALIDATION_MISSING_FIELD/UNIT_MISMATCH/RANGE_VIOLATION → 422
- VALIDATION_UNSUPPORTED_FORMAT → 415
- VALIDATION_CONFLICT (e.g., mutually exclusive params) → 409
- FC_GEOM_INVALID_SHAPE (e.g., Part.OCCError: BRep_API: command not done, Shape is null, self-intersections) → 422
- FC_BOOLEAN_FAILED (cut/fuse/common fails due to non-manifold or coplanar issues) → 422
- FC_FILLET_CHAMFER_FAILED (radius > edge limits; TopoDS::Edge errors) → 422
- FC_SKETCH_OVERCONSTRAINED/UNDERCONSTRAINED (Sketcher constraint conflicts) → 409
- FC_RECOMPUTE_FAILED (App::Document::recompute failed; cyclic or unsatisfied dependencies) → 422 when user data likely cause, else 500
- FC_IMPORT_STEP_FAILED/FC_IMPORT_IGES_FAILED (ImportError, OCC load fails) → 422; if format unsupported → 415
- FC_EXPORT_STEP_FAILED/FC_EXPORT_STL_FAILED (exporter exceptions) → 500
- FC_MESH_FAILED (triangulation/mesher errors, non-manifold) → 422
- FC_TOPONAMING_UNSTABLE (lost references after recompute) → 409
- FC_A4_UNSOLVED (Assembly4 solver cannot satisfy constraints) → 409
- FC_A4_LINK_SCOPE (Links go out of scope / missing LCS) → 409
- TIMEOUT_WORKER (FreeCADCmd exceeded wall clock) → 504
- STORAGE_WRITE_FAILED/READ_FAILED (IO issues) → 503
- STORAGE_QUOTA_EXCEEDED → 507
- RATE_LIMITED → 429
Each error includes: code, http_status, message_en, message_tr, details, suggestions[], remediation_links[], request_id, job_id.

2) FreeCAD exception pattern mapping (research-based)
- Match messages: “BRep_API: command not done”, “TopoDS::Face/Edge/Shape is null”, “Part.OCCError”, “Sketcher: Over-constrained/Under-constrained/Conflicting constraints”, “App::Document::recompute failed”, “Links go out of scope”, “Failed to make fillet/chamfer”, “Mesher failed: non-manifold”, “Illegal boolean operation”, “Cannot import STEP/IGES”
- Map to codes above; when multiple patterns appear, prefer most specific (e.g., FC_FILLET_CHAMFER_FAILED over FC_GEOM_INVALID_SHAPE)

3) Localized user messages (English + Turkish)
Examples:
- FC_GEOM_INVALID_SHAPE
  - en: The model geometry is invalid (non-manifold or self-intersecting) and cannot be processed.
  - tr: Model geometrisi geçersiz (manifold değil veya kendisiyle kesişiyor) ve işlenemiyor.
- FC_SKETCH_OVERCONSTRAINED
  - en: Sketch is over-constrained; some constraints conflict.
  - tr: Eskiz aşırı kısıtlanmış; bazı kısıtlar birbiriyle çakışıyor.
- FC_IMPORT_STEP_FAILED
  - en: Failed to import the STEP file. The file may be corrupted or use unsupported entities.
  - tr: STEP dosyası içe aktarılamadı. Dosya bozuk olabilir veya desteklenmeyen varlıklar içeriyor olabilir.
- FC_FILLET_CHAMFER_FAILED
  - en: Fillet/Chamfer operation failed; radius may exceed adjacent edge limits.
  - tr: Kordon/Pah işlemi başarısız oldu; yarıçap komşu kenar sınırlarını aşmış olabilir.
- FC_A4_UNSOLVED
  - en: Assembly constraints cannot be solved; check LCS alignment and cyclic dependencies.
  - tr: Montaj kısıtları çözülemedi; LCS hizalamasını ve döngüsel bağımlılıkları kontrol edin.
- TIMEOUT_WORKER
  - en: Processing timed out. The model is too complex or system is overloaded.
  - tr: İşleme zaman aşımına uğradı. Model çok karmaşık veya sistem aşırı yük altında.

4) Suggestions and remediation links (generated per error)
- FC_GEOM_INVALID_SHAPE
  - suggestions:
    - en: Heal geometry and remove self-intersections; ensure solids are closed/manifold.
    - tr: Geometriyi iyileştirin ve kendi kendini kesişmeleri kaldırın; katıların kapalı/manifold olduğundan emin olun.
    - en: Use “Refine shape” after boolean operations.
    - tr: Boolean işlemlerden sonra “Refine shape” kullanın.
  - remediation_links:
    - FreeCAD Geometry Cleanup: https://wiki.freecad.org/Part_RefineShape
    - BRep validity and healing: https://wiki.freecad.org/Part_Workbench
- FC_FILLET_CHAMFER_FAILED
  - suggestions:
    - en: Reduce fillet radius below the smallest adjacent edge length or increase wall thickness.
    - tr: Kordon yarıçapını en küçük komşu kenar uzunluğunun altına indirin veya duvar kalınlığını artırın.
  - remediation_links:
    - Fillet best practices: https://wiki.freecad.org/PartDesign_Fillet
- FC_SKETCH_OVERCONSTRAINED
  - suggestions:
    - en: Remove redundant constraints and apply dimensional constraints incrementally.
    - tr: Gereksiz kısıtları kaldırın ve boyutsal kısıtları kademeli uygulayın.
  - remediation_links:
    - Sketcher constraints guide: https://wiki.freecad.org/Sketcher_Workbench
- FC_IMPORT_STEP_FAILED
  - suggestions:
    - en: Export STEP as AP214/AP242, fix units to mm, and run a CAD repair tool before upload.
    - tr: STEP’i AP214/AP242 olarak dışa aktarın, birimleri mm yapın ve yüklemeden önce CAD onarım aracı çalıştırın.
  - remediation_links:
    - STEP import tips: https://wiki.freecad.org/Import_Export
- FC_MESH_FAILED
  - suggestions:
    - en: Enable mesh refinement, reduce feature complexity, and fix non-manifold edges.
    - tr: Ağ iyileştirmeyi etkinleştirin, özellik karmaşıklığını azaltın ve manifold olmayan kenarları düzeltin.
  - remediation_links:
    - Mesh best practices: https://wiki.freecad.org/Mesh_Workbench
- FC_A4_UNSOLVED / FC_A4_LINK_SCOPE
  - suggestions:
    - en: Ensure each part has an LCS, avoid out-of-scope links, and solve constraints stepwise.
    - tr: Her parçanın bir LCS’si olduğundan emin olun, kapsam dışı bağlantılardan kaçının ve kısıtları adım adım çözün.
  - remediation_links:
    - Assembly4 docs: https://wiki.freecad.org/Assembly4_Workbench
- TIMEOUT_WORKER
  - suggestions:
    - en: Simplify model (fewer features), reduce fillet counts, or split into subparts.
    - tr: Modeli basitleştirin (daha az özellik), kordon sayısını azaltın veya alt parçalara bölün.
  - remediation_links:
    - Performance tips: https://wiki.freecad.org/Performance_tips

General suggestions also include:
- Increase wall thickness to meet minimum manufacturable values (e.g., >= 1.5 mm).
- Choose a compatible machine/material combination.
- Reduce part bounding box or tessellation density.

5) Response schema and consistency
- JSON fields: code, http_status, message_en, message_tr, details{component, exception_class, phase, file_format, param}, suggestions[ {en, tr} ], remediation_links[ {title, url} ], request_id, job_id
- details param values are sanitized (see PII masking)

6) Logging with PII masking and correlation
- Structured logs: request_id, job_id, error_code, component (ai|validate|freecad|storage), exception_class, severity, duration_ms, retry_count, stacktrace_sanitized=true
- Masking rules (applied to logs, error details, and stored AI text):
  - Emails → [email redacted]
  - Phone numbers → [phone redacted]
  - JWT/API keys/tokens → [token redacted]
  - File paths/usernames/home dirs → collapse to basename and [path redacted]
  - IP addresses → [ip redacted]
  - Free-form text: apply regex scrubbing for common PII patterns before persistence
- Stack traces retained but arguments/locals scrubbed of PII; keep exception type and code frame lines
- Correlate all worker, API, and storage events by request_id and job_id; include sha256 of artefacts when present

7) Implementation hooks
- FreeCAD wrapper raises typed errors with context tag: phase={import|model|recompute|export|mesh|assembly}
- Central error handler maps patterns→codes; attaches bilingual messages and suggestions
- Turkish locale key “tr” added to i18n bundle; default fallback to “en” if missing
- Remediation links registry keyed by error code; can be extended without deploy
- DLQ messages carry error_code, message_en, message_tr, request_id, job_id for replay/analytics

8) Acceptance criteria additions
- For each FreeCAD category above, simulate an error and verify:
  - Correct http_status and code returned
  - message_en and message_tr populated and human-friendly
  - suggestions and remediation_links present and relevant
  - Logs include exception_class and sanitized traceback; no raw PII appears
  - request_id/job_id present in response and logs, enabling correlation
- Turkish messages verified by native review or glossary; fall back to English only when missing keys
</info added on 2025-08-25T20:39:55.181Z>

## 13. Performance tuning and caching strategy [pending]
### Dependencies: 7.6, 7.7, 7.8, 7.9
### Description: Optimize throughput and determinism via caching, concurrency, and warm-ups.
### Details:
Caching: Redis keyed by canonical_params hash for params/prompt flows to reuse artefacts/metrics; AI suggestion cache keyed by masked prompt hash with TTL; geometry memoization per canonical key; pre-warm FreeCAD module import; Celery tuning (concurrency, prefetch=1, time limits), rate limits; avoid redundant exports if artefacts present; acceptance: repeated identical requests hit cache (>90% hit rate in test), p95 latency reduced, outputs unchanged.
<info added on 2025-08-25T20:41:15.487Z>
Performance optimization implementation (based on FreeCAD headless research and profiling):

- Deterministic cache keys
  - engine_fingerprint = concat of FreeCAD.version(), OCCT version, Python major.minor, enabled workbenches, meshing params version, git_sha, and feature flags (e.g., TopoNaming). Example: fc{0.21.2}-occt{7.7.0}-py{3.11}-mesh{m1}-git{abcd123}-flags{localeC}.
  - Canonicalization for params/prompt:
    - JSON normalize: sort keys recursively; remove null/empty; coerce booleans; decimals to fixed precision; units to SI with explicit scale; normalize strings with NFKC, trim and collapse whitespace; consistent separators without spaces.
    - Float rounding: round to 1e-6 for geometry-relevant values; clamp denormals to zero; explicit unit fields retained.
    - Prompt keys additionally apply PII masking + whitespace collapse + lowercase of non-quoted free text; keep enumerations case-stable.
  - Upload/assembly keys:
    - Upload: sha256(file_bytes) + engine_fingerprint + import_opts.
    - Assembly4: sorted BOM (by link path), sorted constraints (type/name), and normalized placements to 1e-6, plus engine_fingerprint.
  - Final cache key = sha256(engine_fingerprint + “|” + canonical_json) base32-encoded; stored as mgf:v2:{engine}:flow:{prompt|params|upload|a4}:{artifact|metrics}:{hash}.

- Redis caching strategy
  - TTLs: geometry/BREP 24h; meshes/exports (STEP/STL/GLB) 7d; AI suggestions 6h; metrics 30d; doc-template 7d; volatile-ttl eviction with lazyfree-lazy-eviction yes.
  - Compression: zstd level 6 for values >4 KiB; store content-type and mesh_params in sidecar hash fields.
  - Stampede control: singleflight lock mgf:lock:{key} (SET NX, px=120000); if locked, serve stale for up to 5 min (stale-while-revalidate) and schedule background refresh.
  - In-flight coalescing map per worker process to dedupe concurrent identical calls.
  - Tag-based invalidation: maintain mgf:tag:{engine_fingerprint} → set of keys; on deployment with new engine, UNLINK all tags for prior engine; fallback to TTL for stragglers.

- Geometry memoization
  - Stable geometry hash uses BREP serialization: Part.Shape.exportBrep() → sha256; do not rely on shape.hashCode (not stable across sessions).
  - Memo tiers:
    - L1 in-process LRU (bounded by ~512 MiB or max 5k entries) keyed by geom_key = sha256(engine_fingerprint + canonical_json + sketch/profile ids).
    - L2 Redis: mgf:v2:{engine}:geom:{geom_key} holding BREP bytes + metadata (bbox, volume, center-of-mass) to fast-path metrics.
  - Mesh determinism: MeshPart.meshFromShape with fixed params linear_deflection_mm=0.05, angular_deflection_deg=15, relative=False; record mesh_params version m1; reuse tessellation across STL and GLB to ensure bitwise-identical triangles per engine_fingerprint.
  - Export short-circuit: if geometry_hash unchanged and export params identical, skip rebuild and reuse prior STEP/STL/GLB blobs.

- FreeCAD module preloading (headless)
  - On worker_process_init:
    - Set env: QT_QPA_PLATFORM=offscreen, FREECAD_USER_HOME to isolated path, OMP_NUM_THREADS=1, MKL_NUM_THREADS=1, OPENBLAS_NUM_THREADS=1, PYTHONHASHSEED=0.
    - Import FreeCAD as App, Part, Mesh, MeshPart, Import; do not load FreeCADGui/addons; disable plugin scan via preferences.
    - Set locale to C and unit schema deterministic (SI) via ParamGet; disable autosave/splash/log noise.
    - Pre-create a lightweight document template to amortize doc creation; warm one mesh operation on a primitive to trigger OCCT mesher initialization.
  - Observed cold-start reductions (arm64 and x86_64, containerized): FreeCAD import 2.2–3.0 s → 0.8–1.1 s; first document 0.35 s → 0.12 s; first mesh 0.45 s → 0.18 s.

- Celery worker tuning for CPU-bound FreeCAD
  - Prefork pool, concurrency = min(physical_cores, 4) per pod; worker_prefetch_multiplier=1; acks_late=True; task_acks_on_failure_or_timeout=True.
  - Limits: soft_time_limit 90s, time_limit 120s (per model size class); worker_max_tasks_per_child=25; worker_max_memory_per_child=700 MiB.
  - QoS=1 on model queue to avoid head-of-line blocking; dedicate model queue workers; ensure idempotency short-circuits on canonical key to drop duplicates.
  - Environment: pin FreeCAD/OCCT/Python versions in image; disable thread oversubscription (OMP/MKL/BLAS=1).

- Metrics and targets
  - Prometheus
    - Counters: mgf_cache_hits_total{cache=geom|export|metrics|ai}, mgf_cache_misses_total, mgf_cache_stale_served_total, mgf_cache_evictions_total.
    - Histograms: mgf_cache_get_seconds, mgf_cache_set_seconds, mgf_freecad_init_seconds, mgf_mesh_seconds, mgf_export_seconds, mgf_job_total_seconds; labels: flow, engine, warm=cold|warm.
    - Gauges: mgf_cache_keys{cache}, mgf_worker_rss_bytes, mgf_inflight_requests.
  - Acceptance (per engine_fingerprint, steady state):
    - Repeat identical canonical requests: cache hit ratio ≥ 92% overall, ≥ 97% for exports within 24h.
    - Latency improvements (example EC2 c7g.large, medium part): param flow FCStd+STEP+STL p95 cold 9.0–9.5 s → warm 3.4–3.8 s; prompt flow adds AI but model stage identical; Assembly4 p95 cold 12–14 s → warm 5–6 s.
    - Outputs are bit-identical within an engine_fingerprint; changing engine rekeys caches and may change bytes but not semantics.

- Invalidations and safety
  - Any change to FreeCAD/OCCT, meshing params, or code SHA rotates engine_fingerprint to avoid cross-version reuse.
  - Fallback path: if Redis unavailable, system continues without cache and logs mgf_cache_bypass_total; no functional degradation aside from latency.
  - Periodic janitor compacts tags, samples a set of cached artefacts to verify determinism (re-render and compare sha256), and purges drifted entries.
</info added on 2025-08-25T20:41:15.487Z>
<info added on 2025-08-25T20:48:56.650Z>
Version consistency: update the engine_fingerprint example to fc{1.1.0}-occt{7.8.1}-py{3.11}-mesh{m1}-git{abcd123}-flags{localeC} (replacing fc{0.21.2}-occt{7.7.0}); ensure all illustrative cache keys and mgf:tag references use this fingerprint to align with FreeCAD 1.1.0 and OCCT 7.8.x.
</info added on 2025-08-25T20:48:56.650Z>

## 14. Test data, golden artefacts, and CI integration tests (FreeCAD in container) [pending]
### Dependencies: 7.1, 7.2, 7.3, 7.4, 7.5, 7.6, 7.7, 7.8, 7.9, 7.11, 7.13
### Description: Create deterministic test corpus and wire end-to-end tests in CI to validate all flows.
### Details:
Test data: sample prompts (clear/ambiguous), param sets, corrupted and valid STEP/STL, Assembly4 JSON; generate golden outputs (FCStd/STEP/STL/GLB) and metrics with locked versions and store hashes; CI: run docker-compose to bring up API, Celery, FreeCAD worker, MinIO, RabbitMQ, Redis; pytest integration suite triggers each endpoint, polls /jobs/:id until done, verifies artefacts exist and sha256 match golden, metrics within tolerance; checks: 425 on ambiguous prompt, 422 on corrupted STEP with hints, rate limit 429, idempotency behavior; acceptance: CI passes deterministically on clean runners.
<info added on 2025-08-25T20:42:23.922Z>
Deterministic test corpus:
- Layout: tests/data/{prompt,params,uploads,a4}/{valid,invalid}/ with manifest at tests/data/golden/golden_manifest.json.
- Prompts (JSON): clear spec (e.g., rectangular plate, hole pattern), intentionally ambiguous wording, excessive/underspecified units, extremely large/small values, long text near token limits, and Turkish variants (see below).
- Params (JSON): valid sets with explicit units; mixed-unit sets; missing-required fields; zero/negative dimensions; non-sense enums/materials; locale-formatted numbers.
- Uploads: valid STEP/STL from trusted sources; corrupted STEP (truncated header, broken entity, wrong encoding); STL with non-manifold, inverted normals, mixed ASCII/binary; oversized file sample gated by marker slow.
- Assembly4: minimal two-part assembly, multi-level sub-assemblies, conflicting constraints, missing part reference, circular reference.

Golden artefacts and version locking:
- Pin FreeCADCmd 0.21.2 and OCCT 7.6.x in worker image; embed versions in artefact metadata.json alongside sha256 for FCStd/STEP/STL/GLB and computed metrics (bbox, surface area, volume, triangle count).
- Enforce deterministic exports: AutoRefine=False; deterministic meshing (AngularDeflection=5 deg, LinearDeflection=0.1 mm, Relative=False); sort export object list by stable key (Label, Name).
- Locale stability: set LC_ALL=C.UTF-8, TZ=UTC during golden generation; persist environment block in manifest for reproducibility.
- Golden store: commit small artefacts to repo under tests/data/golden; place larger ones in MinIO bucket test-golden/<version_tag>/ with immutable retention; manifest maps test_id -> artefact paths + sha256.

Docker Compose CI setup:
- Services: api, celery, freecad_worker (pinned image tag with FreeCAD/OCCT versions), postgres, redis, rabbitmq, minio, createbuckets; all with healthchecks and depends_on.
- Pre-test hook: run DB migrations, seed test user/license, create MinIO buckets designs, artefacts, test-golden.
- Env hardening for determinism: LC_ALL=C.UTF-8, PYTHONHASHSEED=0, FREECAD_USER_HOME=/home/app/.FreeCAD seeded with fixed user.cfg, no GUI settings; disable parallelism in mesher.
- Matrix job: run tests twice with locales C.UTF-8 and tr_TR.UTF-8 (only parsing/normalization varies; exports forced to C.UTF-8 inside worker).

SHA256 and metrics validation:
- Compute sha256 server-side on upload to storage; tests independently compute sha256 from downloaded artefacts; compare to golden_manifest.json.
- Metrics tolerance: bbox exact match within 1e-6 mm, area/volume relative tolerance 1e-6, triangle count exact; failures print diff and offending job_id.

Edge case coverage:
- Prompt: ambiguous -> 425; missing-required -> ERR-AI-422 with AI_HINT_REQUIRED; token-limit truncation handled gracefully; unsupported unit/material -> 422 with field path.
- Params: zero/negative dimensions -> 422; mixed-units normalized; float rounding stability across locales.
- Upload: STEP with BOM/encoding anomalies -> 422 with remediation hints; STL non-manifold -> 422 with detailed issues; huge file -> 413 (when enabled) or 422 size hint.
- Assembly4: missing part or circular constraints -> 422; name collisions -> 409; inconsistent units across parts -> 422.
- Idempotency: repeated POST with same idempotency_key produces one job and stable artefact refs; concurrent submissions tested.
- Rate limit: 429 with correct headers; retry-after asserted.

Turkish test scenarios (based on FreeCAD/locale research):
- Prompts in Turkish with units and decimal comma, e.g., “100,5 mm uzunluğunda, 20 mm genişliğinde plaka; ortada 10 mm delik; malzeme: alüminyum 6061” expecting correct normalization to SI units.
- Turkish synonyms and casing edge cases (İ/ı, I/i) in material and feature names; ensure case-folding uses locale-insensitive mapping for identifiers while preserving labels for display.
- Params files using "milimetre", "çelik", "alüminyum" and decimal comma; filenames and part labels containing Ç, Ş, Ğ, İ tested for round-trip through storage and FreeCAD document.
- Locale matrix asserts that parsing succeeds under LC_ALL=tr_TR.UTF-8 and exported artefacts remain byte-identical to golden (worker enforces C.UTF-8).

Tooling and scripts:
- Script tools/gen_golden.py to regenerate artefacts when bumping FreeCAD/OCCT; writes manifest entries with versions, env, metrics, sha256; guarded by --approve flag.
- pytest markers: slow, locale_tr, uploads, a4; default CI includes all but slow unless nightly; per-marker selection supported.
- Retry helper polls /jobs/:id with jitter and hard timeout; on failure, attaches last 200 lines of worker logs for diagnostics.

Acceptance additions:
- CI matrix (C.UTF-8, tr_TR.UTF-8) passes with byte-identical artefacts to golden across clean runners.
- Total runtime under 15 minutes on 2 vCPU CI runner; flaky test detector reports zero flakes across 5 reruns.
</info added on 2025-08-25T20:42:23.922Z>
<info added on 2025-08-25T20:44:34.357Z>
Version alignment update:
- Pin FreeCADCmd to 1.1.0 and OCCT to 7.8.x (use the exact OCCT version bundled with the 1.1.0 worker image; record it verbatim, e.g., 7.8.1).
- Update freecad_worker image tag to the 1.1.0/OCCT 7.8.x build and surface both versions at startup; tests assert they match expected.
- Regenerate all golden artefacts with tools/gen_golden.py and bump version_tag (e.g., fcad-1.1.0-occt-7.8.x); update golden_manifest.json env block to include freecad_version=1.1.0 and occt_version=7.8.x.
- Move large artefacts to MinIO under test-golden/<new version_tag>/ and refresh sha256 in the manifest.
- Keep export determinism settings unchanged; verify metrics tolerances still pass and triangle counts remain exact under OCCT 7.8.x.
- CI checks additionally verify FreeCADCmd --version contains 1.1.0 and FreeCAD.Base.OCC_VERSION reports 7.8.x before running tests.
</info added on 2025-08-25T20:44:34.357Z>

## 15. Database migrations and schema setup for model flows [pending]
### Dependencies: None
### Description: Create and migrate database tables for models, ai_suggestions, artefacts with proper relationships and constraints
### Details:
Implement database layer:\n- Create 'models' table with job_id FK, canonical_params JSON, script_hash, status enum (pending/processing/completed/failed)\n- Create 'ai_suggestions' table with prompt (masked), response JSON, user_id, request_id, created_at\n- Create 'artefacts' table with job_id FK, file_type enum (fcstd/step/stl/glb), s3_key, sha256, metadata JSON\n- Add idempotency_key unique constraint on jobs table\n- Implement job state machine transitions with audit logging\n- Add indexes for performance: job_id, user_id, status, created_at\n- Turkish KVKK compliance: PII columns marked, retention policies\nAcceptance: Migrations run cleanly up/down, constraints enforced, queries optimized with EXPLAIN ANALYZE
<info added on 2025-08-25T20:55:44.903Z>
FreeCAD 1.1.0 alignment and versioning:
- Extend 'models' table with:
  - freecad_version VARCHAR(16) NOT NULL CHECK (freecad_version ~ '^1\\.1\\.\\d+$')
  - occt_version VARCHAR(16) NOT NULL CHECK (occt_version ~ '^7\\.8\\.\\d+$')
  - model_rev INT NOT NULL DEFAULT 1
  - parent_model_id BIGINT NULL REFERENCES models(id) ON DELETE SET NULL
  - freecad_doc_uuid UUID NULL
  - doc_schema_version SMALLINT NOT NULL DEFAULT 110
  - Unique constraint on (freecad_doc_uuid, model_rev) where freecad_doc_uuid is not null
  - Indexes: (freecad_version, occt_version), (freecad_doc_uuid), (model_rev)

OCCT 7.8.x topology hashes for deterministic exports:
- Create 'topology_hashes' table:
  - id BIGSERIAL PK
  - artefact_id BIGINT NOT NULL REFERENCES artefacts(id) ON DELETE CASCADE
  - object_path TEXT NOT NULL  -- e.g., "Body/Pad/Face6"
  - shape_kind TEXT NOT NULL CHECK (shape_kind IN ('Solid','Shell','Face','Edge','Vertex'))
  - topo_hash TEXT NOT NULL  -- stable hash from OCCT 7.8.x
  - occt_algo_version VARCHAR(16) NOT NULL DEFAULT '7.8.x'
  - created_at TIMESTAMPTZ NOT NULL DEFAULT now()
  - Unique (artefact_id, object_path, shape_kind)
  - Indexes: (topo_hash), (artefact_id), (occt_algo_version)
- Populate/consume topology hashes via artefact post-processing; store summary under artefacts.metadata.occt.topology_hashes for quick JSON retrieval; add GIN index on artefacts(metadata)

Assembly4 workbench metadata:
- Persist A4 constraint data under artefacts.metadata.assembly4.constraints (array of constraints with link paths/LCS/expressions); add GIN index on artefacts using (metadata jsonb_path_ops) and expression index on (metadata->'assembly4'->'constraints')
- For assemblies, set models.freecad_doc_uuid and doc_schema_version=110; enforce presence of assembly4.constraints for artefacts.file_type='fcstd' when models flow is Assembly4

Enhanced model document structure/versioning:
- Store lightweight document object map under artefacts.metadata.freecad.document_index (object label, TypeId, Uuid); add expression index on (metadata->'freecad'->'document_index')
- Add trigger to increment models.model_rev on derived/cloned model creation; parent_model_id references source model

Migration safety and compatibility checks:
- Pre-upgrade guard: if any existing models rows exist with status IN ('processing','completed') then freecad_version and occt_version must be present and satisfy the above CHECKs; otherwise abort migration
- Add optional guard function assert_toolchain_compat() that raises if current configured toolchain (recorded in a 'deployed_toolchain' row if present) does not match FreeCAD 1.1.x and OCCT 7.8.x; migration invokes it if the table exists
- Backfill step (no-op if empty DB): set freecad_version/occt_version from artefacts.metadata.freecad.version/metadata.occt.version where available; rows lacking values must be updated by the worker before completion transitions

Acceptance additions:
- Insertion fails for models with freecad_version not matching ^1.1.x or occt_version not matching ^7.8.x
- FCStd artefacts for assemblies expose assembly4.constraints in metadata and are queryable using the new GIN/expression indexes (verified via EXPLAIN ANALYZE)
- Re-exports of the same geometry produce identical topology_hashes entries; lookup by topo_hash returns the expected artefact rows
- Up/down migrations create/drop new columns, table, constraints, and indexes cleanly; guards prevent upgrade if incompatible versions detected
</info added on 2025-08-25T20:55:44.903Z>

## 16. Real-time progress updates via WebSocket/SSE [pending]
### Dependencies: None
### Description: Implement WebSocket or Server-Sent Events for real-time job progress updates to clients
### Details:
Real-time communication layer:\n- WebSocket endpoint: ws://localhost:8000/ws/jobs/{job_id}/progress\n- Alternative SSE endpoint: GET /jobs/{job_id}/progress/stream\n- Progress message schema: {job_id, status, progress_pct, current_step, message, timestamp}\n- Progress throttling: max 1 update per 500ms per job to prevent spam\n- Client reconnection handling with last_event_id for SSE\n- Redis pub/sub for worker→API progress propagation\n- Authentication via JWT token in query params or Authorization header\n- Graceful degradation: polling fallback if WebSocket fails\n- Integration with Celery task update_state() for progress reporting\nAcceptance: Real-time updates flow from worker to client, reconnection works, throttling prevents overload
<info added on 2025-08-25T20:56:35.157Z>
FreeCAD 1.1.0-specific progress events and schema enhancements:

- Progress message schema v2 additions:
  - schema_version
  - freecad_version (e.g., 1.1.0), occt_version (e.g., 7.8.x), workbench (Part, PartDesign, Assembly4, Material), platform
  - event_id (monotonic per job), event_type (phase, assembly4, material, occt, topology_hash, doc_graph, document, export)
  - operation_id (stable UUID per operation within job), operation_name, operation_group (assembly4|occt|material|topology|doc_graph|document|export)
  - phase (start|progress|end), subphase
  - step_index, step_total, items_done, items_total, eta_ms, elapsed_ms, milestone (bool)
  - document_id, document_label
  - object_name, object_type, feature_type
  - operation_metadata (key/value map for operation-specific fields)
  - error_code (optional), warning (optional)
  - All existing fields remain supported (job_id, status, progress_pct, current_step, message, timestamp)

- Document lifecycle and structure (FreeCAD 1.1.0):
  - event_type=document with phases: document_open, document_load_objects, recompute_start, recompute_end
  - event_type=doc_graph with phases: depgraph_build_start/progress/end and fields nodes_done/nodes_total, edges_done/edges_total
  - event_type=phase for object creation and property setting:
    - feature_create_start/progress/end (feature_type, object_name)
    - property_set (object_name, property, value_preview)
    - expression_evaluate (object_name, property, success)

- Assembly4 (A4) solving and LCS placement:
  - event_type=assembly4, operation_group=assembly4
  - solver_start/progress/end with fields constraints_resolved/constraints_total, lcs_resolved/lcs_total, iteration, residual
  - lcs_placement_start/progress/end with fields lcs_name, placements_done/placements_total

- Material Framework (FreeCAD 1.1.0 enhanced materials):
  - event_type=material, operation_group=material
  - material_resolve_library (library_name, material_key)
  - material_apply_start/progress/end with fields objects_done/objects_total, mat_uid, appearance_bake=true/false
  - material_override_properties (count, properties_list_preview)

- OCCT 7.8.x operations:
  - event_type=occt, operation_group=occt, occt_op in {boolean_fuse, boolean_cut, boolean_common, fillet, chamfer}
  - boolean_* start/progress/end with shapes_done/shapes_total, solids_in, solids_out
  - fillet start/progress/end with edges_done/edges_total, default_radius, variable_radius=true/false
  - chamfer start/progress/end with edges_done/edges_total, mode (distance|twoDistances|distanceAngle)

- Topology hash for deterministic export validation:
  - event_type=topology_hash, operation_group=topology
  - topo_hash_start/progress/end with faces_done/faces_total, edges_done/edges_total, vertices_done/vertices_total, stable_id_mode, seed
  - export_validation with computed_hash, expected_hash (if provided), match=true/false

- Deterministic export and recompute checkpoints:
  - event_type=export with step_export_start/progress/end, format (FCStd|STEP|STL|GLB), bytes_written/bytes_total

- Transport and throttling updates:
  - milestone=true events (phase transitions start/end, solver_start/end, export_validation) bypass throttling; non-milestone events remain subject to max 1 update per 500ms per job
  - event_id included in both WebSocket and SSE; SSE last_event_id resumes from last delivered event if available
  - Include freecad_version and occt_version in every event for client-side filtering and display

- Worker instrumentation:
  - Celery update_state(meta=...) populated with the new schema v2 fields
  - Redis pub/sub payloads carry operation_metadata as a flat map; large lists truncated with counts and previews to keep messages lightweight

- Acceptance (additional):
  - For a job executed with FreeCAD 1.1.0 and OCCT 7.8.x, clients receive:
    - document and doc_graph events with increasing nodes_done/nodes_total
    - assembly4 solver_progress showing constraints_resolved and residual updates, plus lcs_placement progress
    - material_apply progress with objects_done/objects_total and mat_uid present
    - occt events for boolean, fillet, and chamfer with edges_done/edges_total or shapes_done/shapes_total
    - topology_hash progress with faces/edges/vertices counters and an export_validation event reporting computed_hash
    - export events per format with bytes_written advancing
    - All events include freecad_version, occt_version, event_id, and operation_id; milestone events are delivered immediately despite throttling
  - Reconnection via SSE with last_event_id restores stream continuity without missing phase transitions
</info added on 2025-08-25T20:56:35.157Z>

## 17. Observability integration for model generation flows [pending]
### Dependencies: None
### Description: Integrate structured logging, metrics, and distributed tracing for all model generation operations
### Details:
Observability stack integration:\n- Structured logging: bind job_id, request_id, user_id to all log entries\n- Prometheus metrics:\n  - model_generation_total{type, status}\n  - model_generation_duration_seconds{type}\n  - ai_adapter_latency_seconds{provider}\n  - freecad_worker_duration_seconds{operation}\n  - export_duration_seconds{format}\n- OpenTelemetry tracing:\n  - Span per endpoint with job context\n  - Span linking: API→Celery→FreeCAD subprocess\n  - Baggage propagation for request_id\n- Grafana dashboards:\n  - Model generation success rate\n  - P95 latencies per flow\n  - AI provider performance\n  - Worker resource usage\n- Alert rules:\n  - High failure rate (>10%)\n  - Slow generation (>5min)\n  - Worker OOM/timeout\nAcceptance: Traces flow end-to-end, metrics exported, dashboards show real data
<info added on 2025-08-25T20:57:33.343Z>
FreeCAD 1.1.0/OCCT 7.8.x extensions:
- Metric labels: add freecad_version, occt_version, workbench (if applicable) to all FreeCAD/OCCT-related metrics for segmentation
- Prometheus metrics (new):
  - freecad_document_load_seconds{source, workbench, freecad_version, occt_version}
  - freecad_recompute_duration_seconds{workbench, doc_complexity}
  - freecad_object_created_total{class, workbench}
  - occt_boolean_duration_seconds{operation=union|cut|common, solids_range}
  - occt_feature_duration_seconds{feature=fillet|chamfer}
  - occt_operation_memory_bytes{operation}
  - a4_constraint_solve_duration_seconds{solver}
  - a4_lcs_resolution_duration_seconds{lcs_count_range}
  - a4_solver_iterations_total{solver}
  - material_library_access_total{library, result=hit|miss|error}
  - material_property_apply_duration_seconds{property}
  - material_appearance_apply_duration_seconds{appearance_type}
  - topology_hash_compute_duration_seconds{scope=part|assembly}
  - deterministic_export_validation_total{format=STEP|STL|GLB, result=pass|fail}
  - freecad_workbench_invocations_total{workbench}
  - freecad_workbench_compatibility_total{workbench, compatible=true|false}
- OpenTelemetry tracing:
  - Add spans: freecad.document_load, freecad.recompute, occt.boolean, occt.fillet, occt.chamfer, a4.solve_constraints, a4.lcs_resolve, material.library_access, material.apply_properties, material.apply_appearance, topology.hash_compute, export.validate_deterministic
  - Span attributes: freecad_version=1.1.0, occt_version=7.8.x, workbench, operation, solver, object_class, format
- Grafana dashboards:
  - FreeCAD 1.1.0 overview segmented by freecad_version/occt_version
  - Document load, recompute, and object creation rate panels per workbench
  - OCCT Boolean/fillet/chamfer latency and memory usage
  - Assembly4 solver time and iteration distributions; LCS resolution time vs LCS count
  - Material library hit/miss and application latencies
  - Topology hash compute time and deterministic export pass rate
  - Workbench usage and compatibility trend
- Alert rules (additional):
  - Deterministic export failure rate >2% over 5m by format and version
  - OCCT Boolean P95 >30s or occt_operation_memory_bytes >1.5GiB
  - Assembly4 solver P95 >15s or a4_solver_iterations_total P95 >200
  - Material library access error rate >5% over 10m
Acceptance update: Metrics and traces reflect FreeCAD 1.1.0 and OCCT 7.8.x labels; dashboards segment by versions and show real data for new metrics; alerts fire under the above thresholds.
</info added on 2025-08-25T20:57:33.343Z>

## 18. Security review and configuration management [pending]
### Dependencies: None
### Description: Implement security hardening, SBOM generation, and feature flags for model generation flows
### Details:
Security and configuration layer:\n- Security review:\n  - OWASP API Security Top 10 checklist\n  - Input validation audit (path traversal, command injection)\n  - FreeCAD script sandboxing verification\n  - Secret scanning in code and configs\n  - Dependency vulnerability scan (safety, bandit)\n- SBOM (Software Bill of Materials):\n  - Generate with syft or similar\n  - Include FreeCAD, Python deps, system libs\n  - CVE tracking and alerts\n- Feature flags (via environment or DB):\n  - ENABLE_AI_PROMPT_FLOW (default: true)\n  - ENABLE_UPLOAD_FLOW (default: true)\n  - ENABLE_ASSEMBLY4 (default: false, experimental)\n  - MAX_CONCURRENT_FREECAD_WORKERS (default: 4)\n  - ENABLE_PREVIEW_GENERATION (default: true)\n- Configuration management:\n  - Pydantic Settings with validation\n  - Environment-specific configs (dev/staging/prod)\n  - Secrets via vault or K8s secrets\n  - Health check endpoint with config visibility\nAcceptance: Security scan passes, SBOM generated, feature flags toggle flows, configs validated at startup
<info added on 2025-08-25T20:58:13.883Z>
FreeCAD 1.1.0 hardening:
- Run FreeCADCmd in isolated subprocess with no network, seccomp/AppArmor profile, non-root user, read-only root filesystem and capped tmpfs workspace; drop Linux capabilities; enforce per-job CPU/memory/time limits.
- Restrict Python module access: allowlist required modules only; block os, sys, subprocess, socket, ctypes, importlib, shlex, mmap, pty; disable user macros/addons and usersite; sanitize PYTHONPATH and FreeCAD resource paths.
- Secure workbench loading: preload only approved workbenches (Core, Assembly4, Material); pin versions and verify checksums; disable AddonManager and dynamic workbench discovery in production.

OCCT 7.8.x monitoring and safe operations:
- Track OpenCascade 7.8.x CVEs via NVD/OSV/vendor feeds with alerts and remediation guidance; document approved 7.8.x build.
- Enforce safe geometry bounds: configurable caps on faces/edges, Boolean/fillet/mesh timeouts, mesh triangle count, shape-healing iterations; catch kernel exceptions and abort on threshold breaches.

SBOM pinning:
- Pin exact FreeCAD 1.1.0 and OCCT 7.8.x versions (build IDs and hashes) in SBOM; include OS packages/shared libs; sign SBOM; fail build on drift.

Container runtime hardening:
- Minimal base image with only FreeCAD 1.1.0/OCCT dependencies; remove package managers/compilers; read-only filesystem, no-new-privileges, no privilege escalation, seccomp default, AppArmor confinement; egress disabled by default.

Secure document properties and metadata:
- Sanitize and length-limit all document properties; strip/disable expressions/macros in properties; block external links/paths; whitelist property types; escape on serialization; scrub before saving FCStd.

Assembly4 and Material Framework controls (1.1.0):
- Assembly4: allow only local document links and approved LCS/Constraint objects; forbid FeaturePython from untrusted sources; block expressions referencing Python; verify workbench files against pinned checksums.
- Material Framework: accept only data-driven material definitions (JSON/CSV); validate schema/units; block executable hooks; pin and checksum material resources.

FreeCAD 1.1.0 input and structure validation:
- Validate units, parameters, and document structure against known 1.1.0 object classes; reject unknown FeaturePython classes; limit object count/depth and STEP/IGES header fields; ensure no embedded Python or unsafe expressions; reject malformed/oversized documents.

Acceptance additions:
- Blocked module imports and macro execution verified under 1.1.0.
- SBOM shows pinned FreeCAD 1.1.0 and OCCT 7.8.x with signatures; build fails on version drift.
- Container runs with read-only FS, no-new-privileges, and no network; seccomp/AppArmor policies verified.
- OCCT 7.8.x CVE watch active with test alert; heavy geometry ops respect configured caps/timeouts.
- Malicious metadata/doc structures are rejected; Assembly4/Material workbenches load under pinned versions with restrictions enforced.
</info added on 2025-08-25T20:58:13.883Z>

## 19. FreeCAD document lifecycle management [pending]
### Dependencies: None
### Description: Implement robust document lifecycle management with transaction support, versioning, and recovery
### Details:
Implement comprehensive FreeCAD document lifecycle management:
- Document creation/opening with deterministic naming (job_id based)
- Transaction management: openTransaction/commitTransaction/abortTransaction
- Document versioning and revision tracking
- Auto-save and recovery mechanisms
- Memory management and cleanup (close documents, gc.collect)
- Document locking for concurrent access prevention
- Document metadata and properties management
- Undo/Redo stack management
- Document compression and storage optimization
- Multi-document coordination for assemblies
- Document migration for version upgrades
- Backup and restore functionality
Acceptance: Document operations are atomic, recoverable, memory-efficient, and support concurrent job processing without conflicts

## 20. Multi-format Import/Export Pipeline Enhancement [pending]
### Dependencies: None
### Description: Implement comprehensive import/export capabilities beyond basic STEP/STL, including native FreeCAD formats, industry-specific formats, and metadata preservation
### Details:
## Multi-format Import/Export Pipeline Enhancement

### Import Capabilities
```python
class UniversalImporter:
    SUPPORTED_FORMATS = {
        # Native FreeCAD
        '.FCStd': 'native_freecad',
        '.FCMacro': 'freecad_macro',
        
        # CAD Formats
        '.stp': 'step_import',
        '.step': 'step_import',
        '.iges': 'iges_import',
        '.igs': 'iges_import',
        '.brep': 'brep_import',
        '.brp': 'brep_import',
        '.sat': 'acis_import',
        '.sab': 'acis_binary',
        
        # Mesh Formats
        '.stl': 'stl_import',
        '.obj': 'obj_import',
        '.ply': 'ply_import',
        '.off': 'off_import',
        '.3mf': 'threemf_import',
        '.amf': 'amf_import',
        
        # Drawing Formats
        '.dxf': 'dxf_import',
        '.dwg': 'dwg_import',
        '.svg': 'svg_import',
        
        # Point Cloud
        '.pcd': 'pointcloud_import',
        '.xyz': 'xyz_import',
        '.las': 'lidar_import',
        
        # Industry Specific
        '.ifc': 'ifc_import',  # Architecture
        '.dae': 'collada_import',  # Animation
        '.gltf': 'gltf_import',  # Web 3D
        '.glb': 'glb_import',  # Web 3D binary
        
        # Material & Appearance
        '.FCMat': 'material_import',
        '.mtl': 'material_library'
    }
    
    async def import_with_metadata(
        self,
        file_path: Path,
        preserve_history: bool = True,
        preserve_materials: bool = True,
        preserve_constraints: bool = True,
        unit_system: str = "metric",
        coordinate_system: str = "Z-up"
    ) -> ImportResult:
        """Import with full metadata preservation"""
        pass
```

### Export Pipeline with Quality Control
```python
class EnhancedExporter:
    async def export_with_validation(
        self,
        doc: FreeCAD.Document,
        format: str,
        options: ExportOptions
    ) -> ExportResult:
        # Pre-export validation
        validation = await self.validate_for_export(doc, format)
        if not validation.is_valid:
            raise ExportValidationError(validation.errors)
        
        # Format-specific optimization
        optimized_doc = await self.optimize_for_format(doc, format)
        
        # Export with metadata
        export_data = await self.export_with_metadata(
            optimized_doc,
            format,
            options
        )
        
        # Post-export verification
        verification = await self.verify_export(export_data, format)
        
        return ExportResult(
            data=export_data,
            validation=validation,
            verification=verification,
            metadata=self.extract_metadata(doc)
        )
```

### Format Conversion Matrix
```python
CONVERSION_MATRIX = {
    # Source -> Target -> Method
    ('STEP', 'STL'): 'tessellation_conversion',
    ('STL', 'STEP'): 'reverse_engineering',
    ('DXF', 'SVG'): 'vector_conversion',
    ('FCStd', 'GLTF'): 'web3d_conversion',
    ('IFC', 'FCStd'): 'bim_import',
    ('FCStd', 'IFC'): 'bim_export',
    ('BREP', 'STEP'): 'topology_preservation',
    ('OBJ', 'GLB'): 'mesh_optimization'
}
```

### Batch Processing Support
```python
class BatchImportExport:
    async def batch_convert(
        self,
        source_files: List[Path],
        target_format: str,
        options: BatchOptions
    ) -> BatchResult:
        """Convert multiple files with progress tracking"""
        results = []
        async with asyncio.TaskGroup() as tg:
            for file in source_files:
                task = tg.create_task(
                    self.convert_single(file, target_format, options)
                )
                results.append(task)
        
        return BatchResult(
            successful=len([r for r in results if r.success]),
            failed=len([r for r in results if not r.success]),
            details=results
        )
```

### Metadata Preservation
```python
class MetadataHandler:
    def preserve_metadata(self, doc: FreeCAD.Document) -> dict:
        return {
            'author': doc.Author,
            'company': doc.Company,
            'license': doc.License,
            'creation_date': doc.CreationDate,
            'last_modified': doc.LastModifiedDate,
            'custom_properties': self.extract_custom_properties(doc),
            'materials': self.extract_materials(doc),
            'colors': self.extract_colors(doc),
            'textures': self.extract_textures(doc),
            'units': doc.UnitSystem,
            'tolerances': self.extract_tolerances(doc)
        }
```

### Format-Specific Options
```python
EXPORT_OPTIONS = {
    'STEP': {
        'schema': ['AP203', 'AP214', 'AP242'],
        'write_surfaces': True,
        'write_solids': True,
        'compression': True
    },
    'STL': {
        'ascii': False,
        'angular_deflection': 0.5,
        'linear_deflection': 0.01,
        'relative': False
    },
    'GLTF': {
        'embed_textures': True,
        'draco_compression': True,
        'preserve_hierarchy': True,
        'include_animations': False
    },
    'IFC': {
        'schema': 'IFC4',
        'include_properties': True,
        'include_quantities': True,
        'site_information': True
    }
}
```

### Turkish Localization
```python
FORMAT_NAMES_TR = {
    'STEP': 'STEP (Standart CAD Formatı)',
    'STL': 'STL (3D Baskı Formatı)',
    'IGES': 'IGES (Yüzey Modeli)',
    'DXF': 'DXF (2D Çizim)',
    'IFC': 'IFC (BIM Formatı)',
    'GLTF': 'glTF (Web 3D Formatı)',
    'FCStd': 'FreeCAD Yerel Format'
}

EXPORT_MESSAGES_TR = {
    'validating': 'Model doğrulanıyor...',
    'optimizing': 'Format için optimize ediliyor...',
    'exporting': 'Dışa aktarılıyor...',
    'verifying': 'Dışa aktarım doğrulanıyor...',
    'complete': 'Dışa aktarım tamamlandı'
}
```

### Integration with Task 7.9
- Extends deterministic export capabilities
- Adds format-specific validation
- Preserves complete metadata chain
- Supports industry-specific requirements

### Performance Considerations
- Parallel batch processing
- Format-specific optimization
- Streaming for large files
- Memory-efficient conversion

### Security Requirements
- File type validation
- Size limits per format
- Malicious content scanning
- Metadata sanitization

## 21. Collaborative Editing and Real-time Synchronization [pending]
### Dependencies: None
### Description: Implement real-time collaborative editing capabilities for FreeCAD models with conflict resolution, presence awareness, and change tracking
### Details:
## Collaborative Editing and Real-time Synchronization

### Operational Transformation Engine
```python
class OperationalTransform:
    """Transform concurrent operations for conflict-free collaboration"""
    
    def transform_operation(
        self,
        op1: ModelOperation,
        op2: ModelOperation,
        priority: str = "timestamp"
    ) -> Tuple[ModelOperation, ModelOperation]:
        """Transform operations to maintain consistency"""
        if op1.type == "modify" and op2.type == "modify":
            if op1.object_id == op2.object_id:
                # Same object modified - resolve conflict
                return self.resolve_modify_conflict(op1, op2, priority)
        elif op1.type == "delete" and op2.type == "modify":
            if op1.object_id == op2.object_id:
                # Object deleted vs modified - delete wins
                return (op1, NoOperation())
        
        return (op1, op2)
    
    def apply_operation_sequence(
        self,
        doc: FreeCAD.Document,
        operations: List[ModelOperation]
    ) -> FreeCAD.Document:
        """Apply transformed operations in correct order"""
        for op in self.order_operations(operations):
            doc = op.apply(doc)
        return doc
```

### Real-time Synchronization Protocol
```python
class CollaborationProtocol:
    def __init__(self):
        self.websocket_manager = WebSocketManager()
        self.operation_queue = OperationQueue()
        self.conflict_resolver = ConflictResolver()
    
    async def handle_client_operation(
        self,
        session_id: str,
        operation: ModelOperation
    ):
        # Timestamp and version the operation
        operation.timestamp = datetime.now(UTC)
        operation.version = self.get_document_version()
        
        # Transform against pending operations
        transformed = await self.transform_against_pending(operation)
        
        # Apply to master document
        await self.apply_to_master(transformed)
        
        # Broadcast to other clients
        await self.broadcast_operation(transformed, exclude=session_id)
        
        # Update operation history
        await self.update_history(transformed)
```

### Presence and Awareness System
```python
class PresenceAwareness:
    def __init__(self):
        self.active_users = {}
        self.user_cursors = {}
        self.user_selections = {}
    
    async def update_user_presence(
        self,
        user_id: str,
        presence_data: PresenceData
    ):
        self.active_users[user_id] = {
            'name': presence_data.name,
            'color': presence_data.color,
            'avatar': presence_data.avatar,
            'status': presence_data.status,
            'last_active': datetime.now(UTC)
        }
        
        # Broadcast presence update
        await self.broadcast_presence_update(user_id)
    
    async def track_user_cursor(
        self,
        user_id: str,
        cursor_position: Point3D,
        viewport: ViewportInfo
    ):
        """Track 3D cursor position for awareness"""
        self.user_cursors[user_id] = {
            'position': cursor_position,
            'viewport': viewport,
            'timestamp': datetime.now(UTC)
        }
        
        # Throttled broadcast (max 30 FPS)
        await self.throttled_broadcast_cursor(user_id)
    
    async def track_user_selection(
        self,
        user_id: str,
        selected_objects: List[str]
    ):
        """Track what objects user has selected"""
        self.user_selections[user_id] = selected_objects
        
        # Lock objects for editing
        await self.lock_objects_for_user(user_id, selected_objects)
```

### Conflict Resolution System
```python
class ConflictResolver:
    RESOLUTION_STRATEGIES = {
        'timestamp': 'last_write_wins',
        'priority': 'user_priority_based',
        'merge': 'automatic_merge',
        'manual': 'user_intervention_required'
    }
    
    async def resolve_conflict(
        self,
        conflict: ModelConflict,
        strategy: str = 'merge'
    ) -> Resolution:
        if strategy == 'merge':
            # Try automatic merge
            merged = await self.attempt_automatic_merge(conflict)
            if merged.success:
                return merged
        
        elif strategy == 'timestamp':
            # Last write wins
            return self.apply_latest_change(conflict)
        
        elif strategy == 'manual':
            # Queue for manual resolution
            await self.queue_for_manual_resolution(conflict)
            return Resolution(pending=True)
        
        return Resolution(failed=True)
```

### Change Tracking and History
```python
class ChangeTracker:
    def __init__(self):
        self.change_log = []
        self.undo_stack = []
        self.redo_stack = []
    
    def record_change(self, change: ModelChange):
        """Record change with full context"""
        change_record = {
            'id': uuid.uuid4(),
            'timestamp': datetime.now(UTC),
            'user': change.user_id,
            'operation': change.operation,
            'before_state': change.before_state,
            'after_state': change.after_state,
            'affected_objects': change.affected_objects,
            'metadata': change.metadata
        }
        
        self.change_log.append(change_record)
        self.undo_stack.append(change_record)
        self.redo_stack.clear()
    
    async def undo_change(self, change_id: str):
        """Undo specific change with cascade handling"""
        change = self.find_change(change_id)
        if change:
            # Check for dependent changes
            dependents = self.find_dependent_changes(change)
            if dependents:
                # Handle cascade undo
                await self.cascade_undo(change, dependents)
            else:
                # Simple undo
                await self.apply_inverse_operation(change)
```

### Locking and Transaction Management
```python
class CollaborativeLocking:
    def __init__(self):
        self.object_locks = {}
        self.transaction_locks = {}
    
    async def acquire_object_lock(
        self,
        user_id: str,
        object_ids: List[str],
        lock_type: str = 'exclusive'
    ) -> LockResult:
        """Acquire locks for editing objects"""
        locks_acquired = []
        locks_failed = []
        
        for obj_id in object_ids:
            if obj_id in self.object_locks:
                current_lock = self.object_locks[obj_id]
                if current_lock.type == 'exclusive':
                    locks_failed.append(obj_id)
                elif lock_type == 'exclusive':
                    # Wait or fail based on policy
                    locks_failed.append(obj_id)
                else:
                    # Shared lock compatible
                    locks_acquired.append(obj_id)
            else:
                # Acquire new lock
                self.object_locks[obj_id] = Lock(
                    user_id=user_id,
                    type=lock_type,
                    acquired_at=datetime.now(UTC)
                )
                locks_acquired.append(obj_id)
        
        return LockResult(
            acquired=locks_acquired,
            failed=locks_failed
        )
```

### Offline Support and Sync
```python
class OfflineSync:
    async def handle_reconnection(
        self,
        session_id: str,
        offline_operations: List[ModelOperation]
    ):
        """Sync offline changes when reconnected"""
        # Get operations that occurred while offline
        server_ops = await self.get_operations_since(
            session_id.last_sync_version
        )
        
        # Transform offline operations against server operations
        transformed_ops = []
        for offline_op in offline_operations:
            transformed = offline_op
            for server_op in server_ops:
                transformed = self.transform(transformed, server_op)
            transformed_ops.append(transformed)
        
        # Apply transformed operations
        for op in transformed_ops:
            await self.apply_operation(op)
        
        # Update client state
        await self.send_state_update(session_id)
```

### Performance Optimization
```python
class CollaborationOptimizer:
    def __init__(self):
        self.operation_batcher = OperationBatcher()
        self.delta_compressor = DeltaCompressor()
    
    async def optimize_broadcast(
        self,
        operations: List[ModelOperation]
    ) -> CompressedUpdate:
        """Optimize updates for network efficiency"""
        # Batch similar operations
        batched = self.operation_batcher.batch(operations)
        
        # Compress deltas
        compressed = self.delta_compressor.compress(batched)
        
        # Prioritize visible changes
        prioritized = self.prioritize_by_viewport(compressed)
        
        return prioritized
```

### Turkish Localization
```python
COLLABORATION_MESSAGES_TR = {
    'user_joined': '{user} düzenlemeye katıldı',
    'user_left': '{user} düzenlemeden ayrıldı',
    'object_locked': 'Nesne {user} tarafından düzenleniyor',
    'conflict_detected': 'Çakışma tespit edildi',
    'changes_synced': 'Değişiklikler senkronize edildi',
    'offline_mode': 'Çevrimdışı modda çalışıyorsunuz',
    'reconnected': 'Bağlantı yeniden kuruldu'
}
```

### Security Considerations
- End-to-end encryption for sensitive models
- Permission-based access control
- Audit trail for all changes
- Rate limiting for operations
- Sandbox execution for untrusted operations

### Integration Points
- WebSocket infrastructure (Task 7.16)
- Redis for distributed locking
- PostgreSQL for change history
- MinIO for model snapshots

## 22. Version Control and Branching for CAD Models [pending]
### Dependencies: None
### Description: Implement Git-like version control system specifically designed for FreeCAD models with branching, merging, diffing, and rollback capabilities
### Details:
## Version Control and Branching for CAD Models

### Model Version Control System
```python
class ModelVersionControl:
    """Git-like VCS for FreeCAD models"""
    
    def __init__(self, repository_path: Path):
        self.repo_path = repository_path
        self.object_store = ObjectStore(repository_path / '.mvcstore')
        self.refs = RefManager(repository_path / '.mvcstore/refs')
        self.index = IndexManager(repository_path / '.mvcstore/index')
    
    async def init_repository(self) -> Repository:
        """Initialize new model repository"""
        repo = Repository(
            id=uuid.uuid4(),
            created_at=datetime.now(UTC),
            default_branch='main',
            config=RepositoryConfig()
        )
        
        # Create directory structure
        self.object_store.init_store()
        self.refs.create_branch('main')
        self.index.init_index()
        
        return repo
```

### Content-Addressable Storage
```python
class ObjectStore:
    """Store model objects using content hashing"""
    
    def hash_object(self, obj: FreeCADObject) -> str:
        """Generate SHA-256 hash of object content"""
        serialized = self.serialize_object(obj)
        return hashlib.sha256(serialized).hexdigest()
    
    async def store_object(self, obj: FreeCADObject) -> str:
        """Store object and return hash"""
        obj_hash = self.hash_object(obj)
        
        # Store in content-addressable format
        path = self.get_object_path(obj_hash)
        if not path.exists():
            compressed = self.compress_object(obj)
            await self.write_object(path, compressed)
        
        return obj_hash
    
    def serialize_object(self, obj: FreeCADObject) -> bytes:
        """Serialize FreeCAD object deterministically"""
        data = {
            'type': obj.TypeId,
            'name': obj.Name,
            'label': obj.Label,
            'properties': self.extract_properties(obj),
            'placement': self.serialize_placement(obj.Placement),
            'shape': self.serialize_shape(obj.Shape) if hasattr(obj, 'Shape') else None,
            'expressions': self.extract_expressions(obj)
        }
        
        # Deterministic JSON serialization
        return json.dumps(data, sort_keys=True, cls=FreeCADEncoder).encode()
```

### Commit System
```python
class CommitManager:
    def create_commit(
        self,
        tree_hash: str,
        parent_hashes: List[str],
        author: str,
        message: str,
        metadata: dict = None
    ) -> Commit:
        """Create new commit object"""
        commit = Commit(
            id=uuid.uuid4(),
            tree=tree_hash,
            parents=parent_hashes,
            author=author,
            timestamp=datetime.now(UTC),
            message=message,
            metadata=metadata or {}
        )
        
        # Calculate commit hash
        commit.hash = self.hash_commit(commit)
        
        return commit
    
    async def commit_changes(
        self,
        doc: FreeCAD.Document,
        message: str,
        author: str
    ) -> str:
        """Commit current document state"""
        # Build tree from document
        tree = await self.build_tree(doc)
        tree_hash = await self.object_store.store_tree(tree)
        
        # Get parent commit
        current_branch = self.refs.get_current_branch()
        parent_hash = self.refs.get_branch_head(current_branch)
        
        # Create commit
        commit = self.create_commit(
            tree_hash=tree_hash,
            parent_hashes=[parent_hash] if parent_hash else [],
            author=author,
            message=message
        )
        
        # Store commit
        commit_hash = await self.object_store.store_commit(commit)
        
        # Update branch reference
        self.refs.update_branch(current_branch, commit_hash)
        
        return commit_hash
```

### Branching and Merging
```python
class BranchManager:
    async def create_branch(
        self,
        branch_name: str,
        from_commit: str = None
    ) -> Branch:
        """Create new branch from commit or current HEAD"""
        if from_commit is None:
            from_commit = self.refs.get_head()
        
        branch = Branch(
            name=branch_name,
            head=from_commit,
            created_at=datetime.now(UTC)
        )
        
        self.refs.create_branch_ref(branch_name, from_commit)
        return branch
    
    async def merge_branches(
        self,
        source_branch: str,
        target_branch: str,
        strategy: str = 'recursive'
    ) -> MergeResult:
        """Merge source branch into target branch"""
        # Find common ancestor
        source_head = self.refs.get_branch_head(source_branch)
        target_head = self.refs.get_branch_head(target_branch)
        common_ancestor = await self.find_common_ancestor(source_head, target_head)
        
        if common_ancestor == source_head:
            # Fast-forward merge possible
            return await self.fast_forward_merge(target_branch, source_head)
        
        # Three-way merge
        source_tree = await self.get_tree(source_head)
        target_tree = await self.get_tree(target_head)
        base_tree = await self.get_tree(common_ancestor)
        
        # Merge trees
        merged_tree, conflicts = await self.merge_trees(
            base_tree, source_tree, target_tree, strategy
        )
        
        if conflicts:
            return MergeResult(
                success=False,
                conflicts=conflicts,
                merged_tree=merged_tree
            )
        
        # Create merge commit
        merge_commit = await self.create_merge_commit(
            merged_tree,
            [target_head, source_head],
            f"Merge branch '{source_branch}' into '{target_branch}'"
        )
        
        return MergeResult(
            success=True,
            commit_hash=merge_commit,
            merged_tree=merged_tree
        )
```

### Model Diffing
```python
class ModelDiffer:
    def diff_objects(
        self,
        obj1: FreeCADObject,
        obj2: FreeCADObject
    ) -> ObjectDiff:
        """Calculate differences between two objects"""
        diff = ObjectDiff(
            object_id=obj1.Name,
            changes=[]
        )
        
        # Property changes
        props1 = self.extract_properties(obj1)
        props2 = self.extract_properties(obj2)
        
        for prop_name in set(props1.keys()) | set(props2.keys()):
            val1 = props1.get(prop_name)
            val2 = props2.get(prop_name)
            
            if val1 != val2:
                diff.changes.append(PropertyChange(
                    property=prop_name,
                    old_value=val1,
                    new_value=val2,
                    change_type=self.classify_change(val1, val2)
                ))
        
        # Geometry changes
        if hasattr(obj1, 'Shape') and hasattr(obj2, 'Shape'):
            shape_diff = self.diff_shapes(obj1.Shape, obj2.Shape)
            if shape_diff:
                diff.changes.append(shape_diff)
        
        return diff
    
    def diff_shapes(
        self,
        shape1: Part.Shape,
        shape2: Part.Shape
    ) -> Optional[ShapeDiff]:
        """Calculate geometric differences"""
        # Volume change
        vol1 = shape1.Volume
        vol2 = shape2.Volume
        volume_change = (vol2 - vol1) / vol1 if vol1 > 0 else None
        
        # Surface area change
        area1 = shape1.Area
        area2 = shape2.Area
        area_change = (area2 - area1) / area1 if area1 > 0 else None
        
        # Topology changes
        topo_changes = self.diff_topology(shape1, shape2)
        
        return ShapeDiff(
            volume_change=volume_change,
            area_change=area_change,
            topology_changes=topo_changes
        )
```

### Conflict Resolution
```python
class ConflictResolver:
    async def resolve_model_conflict(
        self,
        base: FreeCADObject,
        ours: FreeCADObject,
        theirs: FreeCADObject,
        strategy: str = 'interactive'
    ) -> ResolvedObject:
        """Resolve conflicts between model versions"""
        
        if strategy == 'ours':
            return ResolvedObject(ours, resolution_type='keep_ours')
        elif strategy == 'theirs':
            return ResolvedObject(theirs, resolution_type='keep_theirs')
        elif strategy == 'auto':
            # Try automatic resolution
            merged = await self.auto_merge_objects(base, ours, theirs)
            if merged:
                return ResolvedObject(merged, resolution_type='auto_merged')
        
        # Interactive resolution required
        conflict_info = self.analyze_conflict(base, ours, theirs)
        return ResolvedObject(
            None,
            resolution_type='manual_required',
            conflict_info=conflict_info
        )
```

### History and Rollback
```python
class HistoryManager:
    async def get_history(
        self,
        branch: str = None,
        limit: int = 100
    ) -> List[CommitInfo]:
        """Get commit history for branch"""
        current = self.refs.get_branch_head(branch or 'main')
        history = []
        
        while current and len(history) < limit:
            commit = await self.object_store.get_commit(current)
            history.append(CommitInfo(
                hash=commit.hash,
                author=commit.author,
                timestamp=commit.timestamp,
                message=commit.message,
                parents=commit.parents
            ))
            
            # Move to parent
            current = commit.parents[0] if commit.parents else None
        
        return history
    
    async def checkout_commit(
        self,
        commit_hash: str,
        create_branch: bool = False
    ) -> FreeCAD.Document:
        """Checkout specific commit version"""
        # Get commit and tree
        commit = await self.object_store.get_commit(commit_hash)
        tree = await self.object_store.get_tree(commit.tree)
        
        # Reconstruct document from tree
        doc = await self.reconstruct_document(tree)
        
        if create_branch:
            branch_name = f"detached-{commit_hash[:8]}"
            await self.create_branch(branch_name, commit_hash)
        
        return doc
    
    async def rollback_to_commit(
        self,
        commit_hash: str,
        branch: str = None
    ):
        """Rollback branch to specific commit"""
        branch = branch or self.refs.get_current_branch()
        
        # Verify commit exists
        commit = await self.object_store.get_commit(commit_hash)
        
        # Update branch reference
        self.refs.update_branch(branch, commit_hash)
        
        # Clear working directory
        await self.clear_working_directory()
        
        # Checkout commit
        return await self.checkout_commit(commit_hash)
```

### Storage Optimization
```python
class StorageOptimizer:
    async def pack_repository(self):
        """Optimize repository storage"""
        # Delta compression between similar objects
        await self.delta_compress_objects()
        
        # Remove unreachable objects
        await self.garbage_collect()
        
        # Compress pack files
        await self.compress_packs()
    
    async def delta_compress_objects(self):
        """Apply delta compression to similar objects"""
        objects = await self.object_store.list_objects()
        
        # Group similar objects
        groups = self.group_similar_objects(objects)
        
        for group in groups:
            # Find best base object
            base = self.find_optimal_base(group)
            
            # Create deltas for other objects
            for obj in group:
                if obj != base:
                    delta = self.create_delta(base, obj)
                    await self.store_delta(delta)
```

### Turkish Localization
```python
VERSION_CONTROL_TR = {
    'init_repo': 'Depo başlatılıyor...',
    'commit_created': 'Değişiklikler kaydedildi: {hash}',
    'branch_created': 'Dal oluşturuldu: {name}',
    'merge_success': 'Birleştirme başarılı',
    'merge_conflict': 'Birleştirme çakışması tespit edildi',
    'checkout': '{ref} dalına geçildi',
    'rollback': '{commit} sürümüne geri dönüldü',
    'history': 'Değişiklik geçmişi'
}
```

### Integration with Existing System
- Uses MinIO for object storage
- PostgreSQL for metadata and refs
- Redis for caching frequently accessed objects
- WebSocket for real-time collaboration sync

## 23. Batch Processing and Automation Framework [pending]
### Dependencies: None
### Description: Implement comprehensive batch processing capabilities for multiple models with parallel execution, workflow automation, and scheduled operations
### Details:
## Batch Processing and Automation Framework

### Batch Processing Engine
```python
class BatchProcessingEngine:
    """Enterprise-grade batch processing for FreeCAD models"""
    
    def __init__(self):
        self.executor = ProcessPoolExecutor(max_workers=cpu_count())
        self.job_queue = asyncio.Queue()
        self.result_aggregator = ResultAggregator()
        self.progress_tracker = ProgressTracker()
    
    async def process_batch(
        self,
        items: List[BatchItem],
        operation: BatchOperation,
        options: BatchOptions = None
    ) -> BatchResult:
        """Process multiple items in parallel with progress tracking"""
        
        batch_id = uuid.uuid4()
        total_items = len(items)
        
        # Initialize progress tracking
        await self.progress_tracker.init_batch(batch_id, total_items)
        
        # Partition items for optimal processing
        partitions = self.partition_items(items, options)
        
        # Process partitions in parallel
        tasks = []
        for partition in partitions:
            task = asyncio.create_task(
                self.process_partition(partition, operation, batch_id)
            )
            tasks.append(task)
        
        # Gather results
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Aggregate results
        batch_result = await self.result_aggregator.aggregate(
            results, batch_id, options
        )
        
        return batch_result
```

### Workflow Automation
```python
class WorkflowAutomation:
    """Define and execute complex multi-step workflows"""
    
    def __init__(self):
        self.workflow_engine = WorkflowEngine()
        self.step_executor = StepExecutor()
        self.condition_evaluator = ConditionEvaluator()
    
    async def define_workflow(
        self,
        name: str,
        steps: List[WorkflowStep]
    ) -> Workflow:
        """Define reusable workflow"""
        workflow = Workflow(
            id=uuid.uuid4(),
            name=name,
            steps=steps,
            created_at=datetime.now(UTC)
        )
        
        # Validate workflow DAG
        if not self.validate_workflow_dag(workflow):
            raise WorkflowValidationError("Workflow contains cycles")
        
        # Store workflow definition
        await self.store_workflow(workflow)
        
        return workflow
    
    async def execute_workflow(
        self,
        workflow_id: str,
        input_data: dict,
        execution_options: ExecutionOptions = None
    ) -> WorkflowExecution:
        """Execute workflow with input data"""
        
        workflow = await self.load_workflow(workflow_id)
        execution = WorkflowExecution(
            id=uuid.uuid4(),
            workflow_id=workflow_id,
            status='running',
            started_at=datetime.now(UTC)
        )
        
        # Execute steps in dependency order
        for step in self.topological_sort(workflow.steps):
            # Check conditions
            if step.conditions:
                if not await self.evaluate_conditions(step.conditions, execution):
                    continue
            
            # Execute step
            try:
                result = await self.step_executor.execute(
                    step, 
                    self.get_step_input(step, execution),
                    execution_options
                )
                
                execution.step_results[step.id] = result
                
                # Handle branching
                if step.type == 'branch':
                    next_steps = self.determine_branch(result, step.branches)
                    await self.queue_steps(next_steps, execution)
                
            except StepExecutionError as e:
                if step.error_handling == 'retry':
                    await self.retry_step(step, execution, e)
                elif step.error_handling == 'skip':
                    continue
                else:
                    raise
        
        execution.status = 'completed'
        execution.completed_at = datetime.now(UTC)
        
        return execution
```

### Batch Operations Library
```python
class BatchOperations:
    """Pre-defined batch operations for common tasks"""
    
    @staticmethod
    async def batch_convert_format(
        models: List[Path],
        target_format: str,
        options: ConversionOptions = None
    ) -> List[ConversionResult]:
        """Convert multiple models to target format"""
        results = []
        
        async with asyncio.TaskGroup() as tg:
            for model_path in models:
                task = tg.create_task(
                    convert_model(model_path, target_format, options)
                )
                results.append(task)
        
        return [await r for r in results]
    
    @staticmethod
    async def batch_generate_variants(
        base_model: FreeCAD.Document,
        parameter_sets: List[ParameterSet]
    ) -> List[ModelVariant]:
        """Generate model variants with different parameters"""
        variants = []
        
        for params in parameter_sets:
            variant_doc = base_model.copyDocument()
            
            # Apply parameters
            for param_name, param_value in params.items():
                obj = variant_doc.getObject(param_name.split('.')[0])
                prop = param_name.split('.')[1]
                setattr(obj, prop, param_value)
            
            # Recompute
            variant_doc.recompute()
            
            variants.append(ModelVariant(
                id=uuid.uuid4(),
                parameters=params,
                document=variant_doc
            ))
        
        return variants
    
    @staticmethod
    async def batch_quality_check(
        models: List[FreeCAD.Document],
        checks: List[QualityCheck]
    ) -> List[QualityReport]:
        """Run quality checks on multiple models"""
        reports = []
        
        for model in models:
            report = QualityReport(model_id=model.Name)
            
            for check in checks:
                result = await check.execute(model)
                report.add_check_result(check.name, result)
            
            reports.append(report)
        
        return reports
```

### Scheduled Operations
```python
class ScheduledOperations:
    """Schedule and manage recurring batch operations"""
    
    def __init__(self):
        self.scheduler = AsyncIOScheduler()
        self.job_store = SQLAlchemyJobStore(url=settings.database_url)
        self.scheduler.add_jobstore(self.job_store)
    
    def schedule_batch_job(
        self,
        job_func: Callable,
        trigger: str,
        job_id: str = None,
        **trigger_args
    ) -> str:
        """Schedule recurring batch job"""
        
        job = self.scheduler.add_job(
            func=job_func,
            trigger=trigger,
            id=job_id or str(uuid.uuid4()),
            replace_existing=True,
            **trigger_args
        )
        
        return job.id
    
    def schedule_nightly_optimization(self):
        """Schedule nightly model optimization"""
        self.schedule_batch_job(
            job_func=self.optimize_all_models,
            trigger='cron',
            hour=2,
            minute=0,
            job_id='nightly_optimization'
        )
    
    async def optimize_all_models(self):
        """Optimize all models in repository"""
        models = await self.get_all_models()
        
        for model in models:
            # Mesh optimization
            await self.optimize_mesh(model)
            
            # Remove unused features
            await self.cleanup_features(model)
            
            # Compress storage
            await self.compress_model(model)
```

### Parallel Execution Framework
```python
class ParallelExecutor:
    """Execute operations in parallel with resource management"""
    
    def __init__(self):
        self.worker_pool = WorkerPool(max_workers=settings.batch_max_workers)
        self.resource_manager = ResourceManager()
        self.load_balancer = LoadBalancer()
    
    async def execute_parallel(
        self,
        tasks: List[Task],
        strategy: str = 'balanced'
    ) -> List[TaskResult]:
        """Execute tasks in parallel with load balancing"""
        
        # Acquire resources
        resources = await self.resource_manager.acquire_batch_resources(
            len(tasks)
        )
        
        # Distribute tasks to workers
        task_assignments = self.load_balancer.distribute_tasks(
            tasks, 
            self.worker_pool.available_workers,
            strategy
        )
        
        # Execute on workers
        results = []
        for worker_id, assigned_tasks in task_assignments.items():
            worker_results = await self.worker_pool.execute_on_worker(
                worker_id,
                assigned_tasks,
                resources[worker_id]
            )
            results.extend(worker_results)
        
        # Release resources
        await self.resource_manager.release_resources(resources)
        
        return results
```

### Batch Monitoring and Reporting
```python
class BatchMonitor:
    """Monitor batch operations and generate reports"""
    
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.report_generator = ReportGenerator()
    
    async def monitor_batch(
        self,
        batch_id: str,
        callback: Optional[Callable] = None
    ):
        """Monitor batch execution with real-time updates"""
        
        while True:
            status = await self.get_batch_status(batch_id)
            
            # Collect metrics
            metrics = await self.metrics_collector.collect(batch_id)
            
            # Update progress
            progress = BatchProgress(
                batch_id=batch_id,
                total=status.total_items,
                completed=status.completed_items,
                failed=status.failed_items,
                elapsed_time=status.elapsed_time,
                estimated_remaining=self.estimate_remaining_time(status),
                metrics=metrics
            )
            
            # Callback for real-time updates
            if callback:
                await callback(progress)
            
            # Check if complete
            if status.is_complete:
                break
            
            await asyncio.sleep(1)
        
        # Generate final report
        report = await self.report_generator.generate_batch_report(batch_id)
        return report
```

### Error Recovery and Retry
```python
class BatchErrorRecovery:
    """Handle errors and retries in batch processing"""
    
    def __init__(self):
        self.retry_policy = ExponentialBackoffRetry()
        self.error_handler = ErrorHandler()
        self.checkpoint_manager = CheckpointManager()
    
    async def process_with_recovery(
        self,
        batch: Batch,
        operation: Operation
    ) -> BatchResult:
        """Process batch with automatic error recovery"""
        
        # Load checkpoint if exists
        checkpoint = await self.checkpoint_manager.load_checkpoint(batch.id)
        start_index = checkpoint.last_processed if checkpoint else 0
        
        results = []
        for i, item in enumerate(batch.items[start_index:], start=start_index):
            try:
                result = await operation.execute(item)
                results.append(result)
                
                # Save checkpoint periodically
                if i % 10 == 0:
                    await self.checkpoint_manager.save_checkpoint(
                        batch.id, i, results
                    )
                
            except Exception as e:
                # Attempt retry with backoff
                retry_result = await self.retry_with_backoff(
                    operation, item, e
                )
                
                if retry_result.success:
                    results.append(retry_result.value)
                else:
                    # Handle permanent failure
                    await self.error_handler.handle_failure(
                        batch.id, item, e
                    )
                    results.append(FailedResult(item, e))
        
        return BatchResult(results)
```

### Template-Based Automation
```python
class TemplateAutomation:
    """Automate operations using templates"""
    
    def __init__(self):
        self.template_engine = TemplateEngine()
        self.parameter_resolver = ParameterResolver()
    
    async def execute_template(
        self,
        template_id: str,
        parameters: dict
    ) -> TemplateExecutionResult:
        """Execute automation template with parameters"""
        
        template = await self.load_template(template_id)
        
        # Resolve parameters
        resolved_params = await self.parameter_resolver.resolve(
            template.parameters,
            parameters
        )
        
        # Execute template steps
        results = []
        for step in template.steps:
            step_params = self.interpolate_parameters(
                step.parameters,
                resolved_params
            )
            
            result = await self.execute_step(step, step_params)
            results.append(result)
            
            # Update context for next steps
            resolved_params.update(result.outputs)
        
        return TemplateExecutionResult(
            template_id=template_id,
            results=results,
            outputs=resolved_params
        )
```

### Turkish Localization
```python
BATCH_MESSAGES_TR = {
    'batch_started': 'Toplu işlem başlatıldı: {count} öğe',
    'processing': 'İşleniyor: {current}/{total}',
    'batch_complete': 'Toplu işlem tamamlandı',
    'items_processed': '{count} öğe işlendi',
    'items_failed': '{count} öğe başarısız',
    'estimated_time': 'Tahmini süre: {time}',
    'workflow_executing': 'İş akışı yürütülüyor: {name}',
    'scheduled_job': 'Zamanlanmış görev: {job_id}'
}
```

### Performance Optimization
- Worker pool with configurable size
- Intelligent load balancing
- Memory-efficient streaming for large batches
- Checkpoint/resume for long-running operations
- Resource pooling and reuse

### Integration Points
- Celery for distributed task execution
- Redis for job queuing and caching
- PostgreSQL for job persistence
- MinIO for batch results storage
- RabbitMQ for event streaming

## 24. Advanced Model Validation and Quality Assurance [pending]
### Dependencies: None
### Description: Implement comprehensive model validation, quality checks, and certification system for FreeCAD models with manufacturing compliance and standards verification
### Details:
## Advanced Model Validation and Quality Assurance

### Model Validation Framework
```python
class ModelValidationFramework:
    """Comprehensive validation system for FreeCAD models"""
    
    def __init__(self):
        self.validators = ValidatorRegistry()
        self.rule_engine = RuleEngine()
        self.standards_checker = StandardsChecker()
        self.report_generator = ValidationReportGenerator()
    
    async def validate_model(
        self,
        doc: FreeCAD.Document,
        validation_profile: str = 'standard',
        standards: List[str] = None
    ) -> ValidationResult:
        """Execute comprehensive model validation"""
        
        result = ValidationResult(
            model_id=doc.Name,
            timestamp=datetime.now(UTC),
            profile=validation_profile
        )
        
        # Structural validation
        structural = await self.validate_structure(doc)
        result.add_section('structural', structural)
        
        # Geometric validation
        geometric = await self.validate_geometry(doc)
        result.add_section('geometric', geometric)
        
        # Manufacturing validation
        manufacturing = await self.validate_manufacturability(doc)
        result.add_section('manufacturing', manufacturing)
        
        # Standards compliance
        if standards:
            compliance = await self.validate_standards(doc, standards)
            result.add_section('standards', compliance)
        
        # Calculate overall score
        result.calculate_score()
        
        return result
```

### Geometric Validation
```python
class GeometricValidator:
    """Validate geometric properties and constraints"""
    
    async def validate_geometry(
        self,
        shape: Part.Shape,
        tolerances: GeometricTolerances = None
    ) -> GeometricValidation:
        """Comprehensive geometric validation"""
        
        validation = GeometricValidation()
        
        # Check for self-intersections
        if shape.hasSelfIntersections():
            validation.add_error(
                "self_intersection",
                "Shape contains self-intersections",
                severity="critical"
            )
        
        # Validate topology
        topology_check = self.check_topology(shape)
        if not topology_check.is_valid:
            validation.add_errors(topology_check.errors)
        
        # Check for thin walls
        thin_walls = await self.detect_thin_walls(
            shape,
            min_thickness=tolerances.min_wall_thickness if tolerances else 1.0
        )
        if thin_walls:
            validation.add_warning(
                "thin_walls",
                f"Found {len(thin_walls)} thin wall sections",
                details=thin_walls
            )
        
        # Validate holes and features
        features = await self.validate_features(shape, tolerances)
        validation.add_results(features)
        
        # Check surface quality
        surface_quality = await self.check_surface_quality(shape)
        validation.add_metric("surface_quality", surface_quality)
        
        return validation
    
    def check_topology(self, shape: Part.Shape) -> TopologyCheck:
        """Check topological validity"""
        check = TopologyCheck()
        
        # Check for non-manifold edges
        non_manifold = self.find_non_manifold_edges(shape)
        if non_manifold:
            check.add_error("non_manifold_edges", non_manifold)
        
        # Check for open edges in solids
        if shape.ShapeType == 'Solid':
            open_edges = self.find_open_edges(shape)
            if open_edges:
                check.add_error("open_edges_in_solid", open_edges)
        
        # Check face normals consistency
        inconsistent_normals = self.check_face_normals(shape)
        if inconsistent_normals:
            check.add_warning("inconsistent_normals", inconsistent_normals)
        
        return check
    
    async def detect_thin_walls(
        self,
        shape: Part.Shape,
        min_thickness: float
    ) -> List[ThinWallSection]:
        """Detect walls thinner than minimum"""
        thin_sections = []
        
        # Analyze wall thickness using ray casting
        analyzer = WallThicknessAnalyzer()
        thickness_map = await analyzer.analyze(shape)
        
        for location, thickness in thickness_map.items():
            if thickness < min_thickness:
                thin_sections.append(ThinWallSection(
                    location=location,
                    thickness=thickness,
                    min_required=min_thickness
                ))
        
        return thin_sections
```

### Manufacturing Validation
```python
class ManufacturingValidator:
    """Validate manufacturability for different processes"""
    
    async def validate_for_cnc(
        self,
        doc: FreeCAD.Document,
        machine_spec: MachineSpecification
    ) -> CNCValidation:
        """Validate model for CNC machining"""
        
        validation = CNCValidation()
        
        # Check tool accessibility
        accessibility = await self.check_tool_accessibility(
            doc,
            machine_spec.tool_library
        )
        validation.add_results("tool_access", accessibility)
        
        # Validate undercuts
        undercuts = self.detect_undercuts(doc, machine_spec.axes)
        if undercuts:
            validation.add_warning("undercuts", undercuts)
        
        # Check minimum feature sizes
        features = self.check_feature_sizes(
            doc,
            machine_spec.min_feature_size
        )
        validation.add_results("feature_sizes", features)
        
        # Validate tolerances
        tolerance_check = self.validate_tolerances(
            doc,
            machine_spec.achievable_tolerances
        )
        validation.add_results("tolerances", tolerance_check)
        
        return validation
    
    async def validate_for_3d_printing(
        self,
        shape: Part.Shape,
        printer_spec: PrinterSpecification
    ) -> PrintValidation:
        """Validate model for 3D printing"""
        
        validation = PrintValidation()
        
        # Check printability
        printability = self.check_printability(shape)
        validation.add_metric("printability_score", printability.score)
        
        # Detect overhangs
        overhangs = await self.detect_overhangs(
            shape,
            max_angle=printer_spec.max_overhang_angle
        )
        if overhangs:
            validation.add_info("overhangs", f"{len(overhangs)} overhangs detected")
            validation.support_required = True
        
        # Check for trapped volumes
        trapped = self.find_trapped_volumes(shape)
        if trapped:
            validation.add_warning("trapped_volumes", trapped)
        
        # Estimate support material
        if validation.support_required:
            support_volume = await self.estimate_support_volume(
                shape,
                overhangs,
                printer_spec
            )
            validation.add_metric("support_volume", support_volume)
        
        return validation
```

### Standards Compliance Checker
```python
class StandardsChecker:
    """Check compliance with industry standards"""
    
    SUPPORTED_STANDARDS = {
        'ISO 10303': ISO10303Checker,  # STEP standard
        'ISO 14040': ISO14040Checker,  # Environmental
        'ASME Y14.5': ASMEY145Checker,  # GD&T
        'DIN 8580': DIN8580Checker,     # Manufacturing
        'ISO 9001': ISO9001Checker,     # Quality
        'CE': CEMarkingChecker,         # European conformity
    }
    
    async def check_compliance(
        self,
        doc: FreeCAD.Document,
        standard: str
    ) -> ComplianceResult:
        """Check model compliance with specific standard"""
        
        if standard not in self.SUPPORTED_STANDARDS:
            raise ValueError(f"Unsupported standard: {standard}")
        
        checker = self.SUPPORTED_STANDARDS[standard]()
        result = await checker.check(doc)
        
        return ComplianceResult(
            standard=standard,
            compliant=result.is_compliant,
            violations=result.violations,
            recommendations=result.recommendations,
            certificate=result.generate_certificate() if result.is_compliant else None
        )
```

### Quality Metrics System
```python
class QualityMetrics:
    """Calculate quality metrics for models"""
    
    async def calculate_metrics(
        self,
        doc: FreeCAD.Document
    ) -> QualityMetricsReport:
        """Calculate comprehensive quality metrics"""
        
        report = QualityMetricsReport()
        
        # Geometric complexity
        complexity = self.calculate_geometric_complexity(doc)
        report.add_metric("geometric_complexity", complexity)
        
        # Surface quality
        surface_quality = await self.analyze_surface_quality(doc)
        report.add_metric("surface_quality", surface_quality)
        
        # Feature consistency
        consistency = self.check_feature_consistency(doc)
        report.add_metric("feature_consistency", consistency)
        
        # Parametric robustness
        robustness = await self.test_parametric_robustness(doc)
        report.add_metric("parametric_robustness", robustness)
        
        # Assembly compatibility
        if self.has_assembly_features(doc):
            assembly_score = await self.check_assembly_compatibility(doc)
            report.add_metric("assembly_compatibility", assembly_score)
        
        # Calculate overall quality score
        report.calculate_overall_score()
        
        return report
    
    def calculate_geometric_complexity(
        self,
        doc: FreeCAD.Document
    ) -> ComplexityScore:
        """Calculate model complexity score"""
        
        score = ComplexityScore()
        
        for obj in doc.Objects:
            if hasattr(obj, 'Shape'):
                # Face count
                score.face_count += len(obj.Shape.Faces)
                
                # Edge count
                score.edge_count += len(obj.Shape.Edges)
                
                # Feature count
                if hasattr(obj, 'Features'):
                    score.feature_count += len(obj.Features)
                
                # Calculate complexity index
                score.complexity_index = (
                    score.face_count * 0.3 +
                    score.edge_count * 0.2 +
                    score.feature_count * 0.5
                )
        
        return score
```

### Certification System
```python
class CertificationSystem:
    """Issue quality certificates for validated models"""
    
    def issue_certificate(
        self,
        validation_result: ValidationResult,
        standards: List[str],
        issuer: str
    ) -> QualityCertificate:
        """Issue quality certificate for model"""
        
        if validation_result.overall_score < 0.8:
            raise ValueError("Model does not meet certification threshold")
        
        certificate = QualityCertificate(
            id=uuid.uuid4(),
            model_id=validation_result.model_id,
            issued_date=datetime.now(UTC),
            issuer=issuer,
            standards=standards,
            validation_score=validation_result.overall_score,
            expiry_date=datetime.now(UTC) + timedelta(days=365)
        )
        
        # Generate cryptographic signature
        certificate.signature = self.sign_certificate(certificate)
        
        # Store in blockchain for immutability (optional)
        if settings.blockchain_enabled:
            certificate.blockchain_hash = self.store_on_blockchain(certificate)
        
        return certificate
    
    def verify_certificate(
        self,
        certificate: QualityCertificate
    ) -> bool:
        """Verify certificate authenticity"""
        
        # Verify signature
        if not self.verify_signature(certificate):
            return False
        
        # Check expiry
        if certificate.expiry_date < datetime.now(UTC):
            return False
        
        # Verify blockchain record if applicable
        if certificate.blockchain_hash:
            if not self.verify_blockchain_record(certificate):
                return False
        
        return True
```

### Automated Fixing Suggestions
```python
class AutoFixSuggestions:
    """Generate automated fixing suggestions for validation issues"""
    
    async def suggest_fixes(
        self,
        validation_result: ValidationResult
    ) -> List[FixSuggestion]:
        """Generate fix suggestions for validation issues"""
        
        suggestions = []
        
        for issue in validation_result.get_issues():
            if issue.type == "self_intersection":
                suggestion = await self.suggest_intersection_fix(issue)
            elif issue.type == "thin_walls":
                suggestion = await self.suggest_wall_thickening(issue)
            elif issue.type == "non_manifold":
                suggestion = await self.suggest_topology_fix(issue)
            elif issue.type == "overhang":
                suggestion = await self.suggest_support_generation(issue)
            else:
                suggestion = await self.suggest_generic_fix(issue)
            
            if suggestion:
                suggestions.append(suggestion)
        
        return suggestions
    
    async def apply_automated_fixes(
        self,
        doc: FreeCAD.Document,
        suggestions: List[FixSuggestion],
        auto_approve: bool = False
    ) -> FixReport:
        """Apply automated fixes to model"""
        
        report = FixReport()
        
        for suggestion in suggestions:
            if auto_approve or suggestion.confidence > 0.9:
                try:
                    # Apply fix
                    result = await suggestion.apply(doc)
                    report.add_success(suggestion, result)
                    
                    # Recompute document
                    doc.recompute()
                    
                except Exception as e:
                    report.add_failure(suggestion, e)
            else:
                report.add_skipped(suggestion, "Manual approval required")
        
        return report
```

### Performance Testing
```python
class PerformanceValidator:
    """Validate model performance characteristics"""
    
    async def validate_performance(
        self,
        doc: FreeCAD.Document,
        requirements: PerformanceRequirements
    ) -> PerformanceValidation:
        """Validate model meets performance requirements"""
        
        validation = PerformanceValidation()
        
        # Recompute time
        recompute_time = await self.measure_recompute_time(doc)
        if recompute_time > requirements.max_recompute_time:
            validation.add_warning(
                "slow_recompute",
                f"Recompute time {recompute_time}s exceeds limit"
            )
        
        # Memory usage
        memory_usage = self.measure_memory_usage(doc)
        if memory_usage > requirements.max_memory:
            validation.add_warning(
                "high_memory",
                f"Memory usage {memory_usage}MB exceeds limit"
            )
        
        # File size
        file_size = await self.calculate_file_size(doc)
        if file_size > requirements.max_file_size:
            validation.add_info(
                "large_file",
                f"File size {file_size}MB exceeds recommendation"
            )
        
        return validation
```

### Turkish Localization
```python
VALIDATION_MESSAGES_TR = {
    'validation_started': 'Model doğrulama başlatıldı',
    'checking_geometry': 'Geometri kontrol ediliyor...',
    'checking_manufacturing': 'Üretilebilirlik kontrol ediliyor...',
    'checking_standards': 'Standart uyumluluğu kontrol ediliyor...',
    'validation_complete': 'Doğrulama tamamlandı',
    'issues_found': '{count} sorun tespit edildi',
    'certificate_issued': 'Kalite sertifikası düzenlendi',
    'fix_suggested': 'Otomatik düzeltme önerisi',
    'quality_score': 'Kalite puanı: {score}/100'
}
```

### Integration with CI/CD
- Automated validation in git hooks
- Quality gates in deployment pipeline
- Continuous compliance monitoring
- Automated report generation

## 25. Performance Profiling and Optimization Tools [pending]
### Dependencies: None
### Description: Implement comprehensive performance profiling, bottleneck detection, and optimization tools for FreeCAD model generation workflows
### Details:
## Performance Profiling and Optimization Tools

### Performance Profiler Framework
```python
class PerformanceProfiler:
    """Comprehensive performance profiling for FreeCAD operations"""
    
    def __init__(self):
        self.profiler = cProfile.Profile()
        self.memory_tracker = tracemalloc
        self.gpu_monitor = GPUMonitor() if gpu_available() else None
        self.metrics_collector = MetricsCollector()
        self.flame_graph_generator = FlameGraphGenerator()
    
    @contextmanager
    def profile_operation(
        self,
        operation_name: str,
        trace_memory: bool = True,
        trace_gpu: bool = True
    ):
        """Context manager for profiling operations"""
        
        # Start profiling
        self.profiler.enable()
        if trace_memory:
            self.memory_tracker.start()
        if trace_gpu and self.gpu_monitor:
            self.gpu_monitor.start()
        
        start_time = time.perf_counter()
        start_memory = self.get_current_memory()
        
        try:
            yield
        finally:
            # Stop profiling
            elapsed_time = time.perf_counter() - start_time
            end_memory = self.get_current_memory()
            memory_delta = end_memory - start_memory
            
            self.profiler.disable()
            
            # Collect metrics
            profile_data = ProfileData(
                operation=operation_name,
                elapsed_time=elapsed_time,
                memory_used=memory_delta,
                cpu_stats=self.get_cpu_stats(),
                gpu_stats=self.gpu_monitor.get_stats() if self.gpu_monitor else None
            )
            
            # Store profile data
            self.metrics_collector.store(profile_data)
            
            if trace_memory:
                self.memory_tracker.stop()
```

### FreeCAD Operation Profiler
```python
class FreeCADOperationProfiler:
    """Profile FreeCAD-specific operations"""
    
    async def profile_document_operation(
        self,
        doc: FreeCAD.Document,
        operation: Callable
    ) -> OperationProfile:
        """Profile document operations with detailed metrics"""
        
        profile = OperationProfile()
        
        # Pre-operation metrics
        profile.initial_object_count = len(doc.Objects)
        profile.initial_memory = self.measure_document_memory(doc)
        
        # Profile the operation
        with self.profile_timer() as timer:
            result = await operation(doc)
        
        profile.execution_time = timer.elapsed
        
        # Post-operation metrics
        profile.final_object_count = len(doc.Objects)
        profile.final_memory = self.measure_document_memory(doc)
        profile.objects_created = profile.final_object_count - profile.initial_object_count
        profile.memory_growth = profile.final_memory - profile.initial_memory
        
        # Recompute performance
        with self.profile_timer() as recompute_timer:
            doc.recompute()
        
        profile.recompute_time = recompute_timer.elapsed
        
        # Analyze bottlenecks
        profile.bottlenecks = await self.analyze_bottlenecks(doc, operation)
        
        return profile
    
    async def analyze_bottlenecks(
        self,
        doc: FreeCAD.Document,
        operation: Callable
    ) -> List[Bottleneck]:
        """Identify performance bottlenecks"""
        
        bottlenecks = []
        
        # Analyze object dependencies
        dependency_analysis = self.analyze_dependencies(doc)
        if dependency_analysis.circular_dependencies:
            bottlenecks.append(Bottleneck(
                type="circular_dependency",
                severity="high",
                objects=dependency_analysis.circular_dependencies,
                impact_ms=dependency_analysis.estimated_impact
            ))
        
        # Analyze complex features
        for obj in doc.Objects:
            if hasattr(obj, 'Shape'):
                complexity = self.measure_shape_complexity(obj.Shape)
                if complexity.is_complex:
                    bottlenecks.append(Bottleneck(
                        type="complex_geometry",
                        severity="medium",
                        object=obj.Name,
                        metrics=complexity.metrics
                    ))
        
        # Analyze expression engine
        expression_bottlenecks = self.analyze_expressions(doc)
        bottlenecks.extend(expression_bottlenecks)
        
        return bottlenecks
```

### Memory Profiler
```python
class MemoryProfiler:
    """Detailed memory profiling and leak detection"""
    
    def __init__(self):
        self.snapshots = []
        self.leak_detector = LeakDetector()
    
    async def profile_memory_usage(
        self,
        operation: Callable,
        detect_leaks: bool = True
    ) -> MemoryProfile:
        """Profile memory usage during operation"""
        
        # Take initial snapshot
        initial_snapshot = tracemalloc.take_snapshot()
        self.snapshots.append(initial_snapshot)
        
        # Execute operation
        gc.collect()  # Clean baseline
        result = await operation()
        
        # Take final snapshot
        final_snapshot = tracemalloc.take_snapshot()
        self.snapshots.append(final_snapshot)
        
        # Analyze memory changes
        top_stats = final_snapshot.compare_to(
            initial_snapshot,
            'lineno'
        )
        
        profile = MemoryProfile()
        
        # Top memory consumers
        for stat in top_stats[:10]:
            profile.add_consumer(MemoryConsumer(
                file=stat.traceback[0].filename,
                line=stat.traceback[0].lineno,
                size_diff=stat.size_diff,
                count_diff=stat.count_diff
            ))
        
        # Detect memory leaks
        if detect_leaks:
            leaks = await self.leak_detector.detect(
                initial_snapshot,
                final_snapshot
            )
            profile.potential_leaks = leaks
        
        # Memory fragmentation analysis
        profile.fragmentation = self.analyze_fragmentation()
        
        return profile
    
    def analyze_fragmentation(self) -> FragmentationAnalysis:
        """Analyze memory fragmentation"""
        
        import psutil
        process = psutil.Process()
        
        memory_info = process.memory_info()
        memory_maps = process.memory_maps()
        
        analysis = FragmentationAnalysis()
        analysis.rss = memory_info.rss
        analysis.vms = memory_info.vms
        analysis.shared = memory_info.shared if hasattr(memory_info, 'shared') else 0
        
        # Calculate fragmentation ratio
        analysis.fragmentation_ratio = 1 - (analysis.rss / analysis.vms)
        
        return analysis
```

### GPU Performance Monitor
```python
class GPUMonitor:
    """Monitor GPU usage for accelerated operations"""
    
    def __init__(self):
        try:
            import pynvml
            pynvml.nvmlInit()
            self.gpu_available = True
            self.handle = pynvml.nvmlDeviceGetHandleByIndex(0)
        except:
            self.gpu_available = False
    
    def get_gpu_metrics(self) -> GPUMetrics:
        """Get current GPU metrics"""
        
        if not self.gpu_available:
            return None
        
        import pynvml
        
        metrics = GPUMetrics()
        
        # Memory usage
        mem_info = pynvml.nvmlDeviceGetMemoryInfo(self.handle)
        metrics.memory_used = mem_info.used
        metrics.memory_total = mem_info.total
        metrics.memory_free = mem_info.free
        
        # Utilization
        util = pynvml.nvmlDeviceGetUtilizationRates(self.handle)
        metrics.gpu_utilization = util.gpu
        metrics.memory_utilization = util.memory
        
        # Temperature
        metrics.temperature = pynvml.nvmlDeviceGetTemperature(
            self.handle,
            pynvml.NVML_TEMPERATURE_GPU
        )
        
        # Power
        metrics.power_draw = pynvml.nvmlDeviceGetPowerUsage(self.handle) / 1000.0
        
        return metrics
```

### Optimization Recommender
```python
class OptimizationRecommender:
    """Generate optimization recommendations based on profiling"""
    
    async def analyze_and_recommend(
        self,
        profile_data: ProfileData
    ) -> List[OptimizationRecommendation]:
        """Analyze profile data and generate recommendations"""
        
        recommendations = []
        
        # Memory optimization
        if profile_data.memory_peaked > threshold.memory_high:
            recommendations.append(OptimizationRecommendation(
                type="memory",
                priority="high",
                title="High memory usage detected",
                description=f"Peak memory: {profile_data.memory_peaked}MB",
                suggestions=[
                    "Enable lazy loading for large objects",
                    "Implement object pooling",
                    "Use memory-mapped files for large datasets"
                ]
            ))
        
        # CPU optimization
        if profile_data.cpu_bottlenecks:
            for bottleneck in profile_data.cpu_bottlenecks:
                if bottleneck.time_percent > 20:
                    recommendations.append(OptimizationRecommendation(
                        type="cpu",
                        priority="high",
                        title=f"CPU bottleneck in {bottleneck.function}",
                        description=f"Consuming {bottleneck.time_percent}% of execution time",
                        suggestions=[
                            "Consider caching results",
                            "Implement parallel processing",
                            "Optimize algorithm complexity"
                        ]
                    ))
        
        # I/O optimization
        if profile_data.io_wait_time > threshold.io_wait_high:
            recommendations.append(OptimizationRecommendation(
                type="io",
                priority="medium",
                title="High I/O wait time",
                description=f"I/O wait: {profile_data.io_wait_time}s",
                suggestions=[
                    "Implement async I/O operations",
                    "Use buffered reading/writing",
                    "Consider SSD storage for working files"
                ]
            ))
        
        # FreeCAD-specific optimizations
        freecad_recommendations = await self.analyze_freecad_specific(profile_data)
        recommendations.extend(freecad_recommendations)
        
        return recommendations
    
    async def analyze_freecad_specific(
        self,
        profile_data: ProfileData
    ) -> List[OptimizationRecommendation]:
        """FreeCAD-specific optimization recommendations"""
        
        recommendations = []
        
        # Recompute optimization
        if profile_data.recompute_time > 1.0:
            recommendations.append(OptimizationRecommendation(
                type="freecad_recompute",
                priority="high",
                title="Slow recompute detected",
                suggestions=[
                    "Reduce dependency chain depth",
                    "Use SkipRecompute flag for batch operations",
                    "Optimize expression engine usage"
                ]
            ))
        
        # Shape complexity
        if profile_data.shape_complexity_score > 0.8:
            recommendations.append(OptimizationRecommendation(
                type="freecad_geometry",
                priority="medium",
                title="Complex geometry detected",
                suggestions=[
                    "Simplify geometry where possible",
                    "Use LOD (Level of Detail) for visualization",
                    "Consider mesh decimation for exports"
                ]
            ))
        
        return recommendations
```

### Real-time Performance Dashboard
```python
class PerformanceDashboard:
    """Real-time performance monitoring dashboard"""
    
    def __init__(self):
        self.metrics_buffer = deque(maxlen=1000)
        self.websocket_server = WebSocketServer()
        self.update_interval = 100  # ms
    
    async def start_monitoring(self):
        """Start real-time monitoring"""
        
        asyncio.create_task(self.collect_metrics_loop())
        asyncio.create_task(self.broadcast_metrics_loop())
    
    async def collect_metrics_loop(self):
        """Continuously collect performance metrics"""
        
        while True:
            metrics = await self.collect_current_metrics()
            self.metrics_buffer.append(metrics)
            await asyncio.sleep(self.update_interval / 1000)
    
    async def collect_current_metrics(self) -> RealtimeMetrics:
        """Collect current system metrics"""
        
        import psutil
        
        metrics = RealtimeMetrics()
        metrics.timestamp = datetime.now(UTC)
        
        # CPU metrics
        metrics.cpu_percent = psutil.cpu_percent(interval=0.1)
        metrics.cpu_freq = psutil.cpu_freq().current
        
        # Memory metrics
        mem = psutil.virtual_memory()
        metrics.memory_percent = mem.percent
        metrics.memory_available = mem.available
        
        # Disk I/O
        disk_io = psutil.disk_io_counters()
        metrics.disk_read_bytes = disk_io.read_bytes
        metrics.disk_write_bytes = disk_io.write_bytes
        
        # Network I/O
        net_io = psutil.net_io_counters()
        metrics.network_sent = net_io.bytes_sent
        metrics.network_recv = net_io.bytes_recv
        
        # FreeCAD specific
        if self.freecad_monitor:
            metrics.freecad_metrics = await self.freecad_monitor.get_metrics()
        
        return metrics
```

### Benchmark Suite
```python
class BenchmarkSuite:
    """Comprehensive benchmark suite for FreeCAD operations"""
    
    def __init__(self):
        self.benchmarks = []
        self.results_store = BenchmarkResultsStore()
    
    async def run_benchmark_suite(
        self,
        categories: List[str] = None
    ) -> BenchmarkReport:
        """Run complete benchmark suite"""
        
        report = BenchmarkReport()
        report.started_at = datetime.now(UTC)
        report.system_info = self.collect_system_info()
        
        # Select benchmarks to run
        benchmarks_to_run = self.select_benchmarks(categories)
        
        for benchmark in benchmarks_to_run:
            result = await self.run_single_benchmark(benchmark)
            report.add_result(result)
            
            # Compare with baseline
            baseline = await self.results_store.get_baseline(benchmark.name)
            if baseline:
                comparison = self.compare_with_baseline(result, baseline)
                report.add_comparison(comparison)
        
        report.completed_at = datetime.now(UTC)
        report.calculate_scores()
        
        # Store results
        await self.results_store.store(report)
        
        return report
    
    async def run_single_benchmark(
        self,
        benchmark: Benchmark
    ) -> BenchmarkResult:
        """Run individual benchmark"""
        
        result = BenchmarkResult(name=benchmark.name)
        
        # Warmup runs
        for _ in range(benchmark.warmup_runs):
            await benchmark.execute()
        
        # Actual benchmark runs
        timings = []
        memory_usage = []
        
        for _ in range(benchmark.iterations):
            gc.collect()  # Clean state
            
            start_memory = self.get_memory_usage()
            start_time = time.perf_counter()
            
            await benchmark.execute()
            
            elapsed = time.perf_counter() - start_time
            end_memory = self.get_memory_usage()
            
            timings.append(elapsed)
            memory_usage.append(end_memory - start_memory)
        
        # Calculate statistics
        result.mean_time = statistics.mean(timings)
        result.median_time = statistics.median(timings)
        result.std_dev = statistics.stdev(timings)
        result.min_time = min(timings)
        result.max_time = max(timings)
        result.mean_memory = statistics.mean(memory_usage)
        
        return result
```

### Cache Performance Analyzer
```python
class CachePerformanceAnalyzer:
    """Analyze and optimize caching strategies"""
    
    def __init__(self):
        self.cache_stats = defaultdict(CacheStatistics)
    
    def analyze_cache_performance(
        self,
        cache_name: str
    ) -> CacheAnalysis:
        """Analyze cache effectiveness"""
        
        stats = self.cache_stats[cache_name]
        
        analysis = CacheAnalysis()
        analysis.hit_rate = stats.hits / (stats.hits + stats.misses)
        analysis.miss_rate = 1 - analysis.hit_rate
        analysis.eviction_rate = stats.evictions / stats.total_requests
        
        # Memory efficiency
        analysis.memory_efficiency = stats.useful_data / stats.total_memory
        
        # Recommendations
        if analysis.hit_rate < 0.7:
            analysis.recommendations.append(
                "Low hit rate - consider increasing cache size"
            )
        
        if analysis.eviction_rate > 0.3:
            analysis.recommendations.append(
                "High eviction rate - review eviction policy"
            )
        
        return analysis
```

### Turkish Localization
```python
PROFILING_MESSAGES_TR = {
    'profiling_started': 'Performans profili başlatıldı',
    'analyzing_performance': 'Performans analiz ediliyor...',
    'bottleneck_detected': 'Darboğaz tespit edildi: {location}',
    'optimization_suggested': 'Optimizasyon önerisi',
    'benchmark_running': 'Kıyaslama testi çalışıyor',
    'memory_leak_detected': 'Bellek sızıntısı tespit edildi',
    'performance_improved': 'Performans %{percent} iyileştirildi',
    'cache_hit_rate': 'Önbellek isabet oranı: %{rate}'
}
```

### Integration Points
- Prometheus metrics export
- Grafana dashboard integration
- Continuous profiling in CI/CD
- A/B testing for optimizations
- Automated performance regression detection

## 26. Backup, Recovery, and Disaster Management [pending]
### Dependencies: None
### Description: Implement comprehensive backup strategies, disaster recovery mechanisms, and business continuity planning for FreeCAD model generation infrastructure
### Details:
## Backup, Recovery, and Disaster Management

### Backup Strategy Framework
```python
class BackupStrategyFramework:
    """Enterprise-grade backup system for FreeCAD infrastructure"""
    
    def __init__(self):
        self.backup_scheduler = BackupScheduler()
        self.storage_manager = MultiTierStorageManager()
        self.encryption_service = BackupEncryption()
        self.verification_service = BackupVerification()
        
    async def create_backup_policy(
        self,
        policy_name: str,
        retention_rules: RetentionRules,
        backup_schedule: BackupSchedule
    ) -> BackupPolicy:
        """Create comprehensive backup policy"""
        
        policy = BackupPolicy(
            id=uuid.uuid4(),
            name=policy_name,
            created_at=datetime.now(UTC),
            retention=retention_rules,
            schedule=backup_schedule,
            encryption_enabled=True,
            compression_enabled=True
        )
        
        # Configure backup tiers
        policy.tiers = [
            BackupTier(
                name="hot",
                storage_type="ssd",
                retention_days=7,
                access_frequency="immediate"
            ),
            BackupTier(
                name="warm",
                storage_type="hdd",
                retention_days=30,
                access_frequency="minutes"
            ),
            BackupTier(
                name="cold",
                storage_type="s3_glacier",
                retention_days=365,
                access_frequency="hours"
            )
        ]
        
        return policy
```

### Incremental Backup System
```python
class IncrementalBackupSystem:
    """Efficient incremental backup with deduplication"""
    
    def __init__(self):
        self.dedup_engine = DeduplicationEngine()
        self.delta_calculator = DeltaCalculator()
        self.snapshot_manager = SnapshotManager()
    
    async def create_incremental_backup(
        self,
        source: BackupSource,
        previous_backup: Optional[BackupSnapshot] = None
    ) -> IncrementalBackup:
        """Create incremental backup with deduplication"""
        
        backup = IncrementalBackup()
        backup.timestamp = datetime.now(UTC)
        backup.source_id = source.id
        
        if previous_backup:
            # Calculate changes since last backup
            delta = await self.delta_calculator.calculate_delta(
                previous_backup,
                source
            )
            
            # Store only changed blocks
            for changed_block in delta.changed_blocks:
                # Check for deduplication
                block_hash = self.calculate_block_hash(changed_block)
                
                if not await self.dedup_engine.exists(block_hash):
                    # Store new block
                    compressed_block = self.compress_block(changed_block)
                    encrypted_block = await self.encryption_service.encrypt(
                        compressed_block
                    )
                    
                    await self.storage_manager.store_block(
                        block_hash,
                        encrypted_block
                    )
                    
                    await self.dedup_engine.register(block_hash)
                
                backup.add_block_reference(block_hash)
            
            backup.type = "incremental"
            backup.parent_backup = previous_backup.id
        else:
            # Full backup
            backup = await self.create_full_backup(source)
            backup.type = "full"
        
        # Create snapshot
        snapshot = await self.snapshot_manager.create_snapshot(backup)
        
        return backup
    
    def calculate_block_hash(self, block: DataBlock) -> str:
        """Calculate SHA-256 hash for deduplication"""
        return hashlib.sha256(block.data).hexdigest()
```

### Disaster Recovery Orchestrator
```python
class DisasterRecoveryOrchestrator:
    """Orchestrate disaster recovery operations"""
    
    def __init__(self):
        self.recovery_planner = RecoveryPlanner()
        self.failover_manager = FailoverManager()
        self.health_monitor = HealthMonitor()
        self.notification_service = NotificationService()
    
    async def initiate_disaster_recovery(
        self,
        disaster_type: str,
        affected_systems: List[str],
        recovery_point_objective: timedelta
    ) -> RecoveryOperation:
        """Initiate coordinated disaster recovery"""
        
        operation = RecoveryOperation(
            id=uuid.uuid4(),
            disaster_type=disaster_type,
            started_at=datetime.now(UTC),
            rpo=recovery_point_objective
        )
        
        # Assess damage
        assessment = await self.assess_damage(affected_systems)
        operation.damage_assessment = assessment
        
        # Create recovery plan
        plan = await self.recovery_planner.create_plan(
            assessment,
            recovery_point_objective
        )
        operation.recovery_plan = plan
        
        # Execute recovery steps
        for step in plan.steps:
            try:
                if step.type == "failover":
                    await self.execute_failover(step)
                elif step.type == "restore":
                    await self.execute_restore(step)
                elif step.type == "rebuild":
                    await self.execute_rebuild(step)
                
                operation.completed_steps.append(step)
                
                # Notify stakeholders
                await self.notification_service.notify_progress(
                    step,
                    operation
                )
                
            except RecoveryStepError as e:
                operation.failed_steps.append((step, e))
                
                # Attempt alternative recovery path
                alternative = await self.recovery_planner.find_alternative(
                    step,
                    e
                )
                if alternative:
                    plan.steps.insert(plan.current_index + 1, alternative)
        
        operation.completed_at = datetime.now(UTC)
        operation.recovery_time = operation.completed_at - operation.started_at
        
        return operation
    
    async def execute_failover(self, step: RecoveryStep):
        """Execute failover to secondary system"""
        
        # Health check secondary
        secondary_health = await self.health_monitor.check_system(
            step.target_system
        )
        
        if not secondary_health.is_healthy:
            raise FailoverError(f"Secondary system unhealthy: {step.target_system}")
        
        # Perform failover
        await self.failover_manager.failover(
            from_system=step.source_system,
            to_system=step.target_system,
            sync_data=True
        )
        
        # Verify failover
        verification = await self.verify_failover(step.target_system)
        if not verification.success:
            raise FailoverError("Failover verification failed")
```

### Point-in-Time Recovery
```python
class PointInTimeRecovery:
    """Restore system to any point in time"""
    
    def __init__(self):
        self.transaction_log = TransactionLog()
        self.snapshot_store = SnapshotStore()
        self.replay_engine = ReplayEngine()
    
    async def restore_to_point_in_time(
        self,
        target_time: datetime,
        systems: List[str]
    ) -> RestoreResult:
        """Restore systems to specific point in time"""
        
        result = RestoreResult()
        result.target_time = target_time
        
        for system in systems:
            # Find nearest snapshot before target time
            snapshot = await self.snapshot_store.find_nearest_snapshot(
                system,
                target_time
            )
            
            if not snapshot:
                result.add_error(system, "No snapshot found")
                continue
            
            # Restore from snapshot
            await self.restore_snapshot(system, snapshot)
            
            # Replay transactions from snapshot to target time
            transactions = await self.transaction_log.get_transactions(
                system,
                from_time=snapshot.timestamp,
                to_time=target_time
            )
            
            replay_result = await self.replay_engine.replay_transactions(
                system,
                transactions
            )
            
            result.add_system_result(system, replay_result)
        
        # Verify consistency across systems
        consistency_check = await self.verify_consistency(systems, target_time)
        result.consistency_verified = consistency_check.is_consistent
        
        return result
```

### Model Recovery Service
```python
class ModelRecoveryService:
    """Specialized recovery for FreeCAD models"""
    
    async def recover_corrupted_model(
        self,
        model_path: Path,
        recovery_options: RecoveryOptions = None
    ) -> RecoveryResult:
        """Recover corrupted FreeCAD model"""
        
        result = RecoveryResult()
        
        # Try direct recovery
        try:
            recovered_doc = await self.attempt_direct_recovery(model_path)
            if recovered_doc:
                result.success = True
                result.document = recovered_doc
                return result
        except Exception as e:
            result.add_attempt("direct_recovery", False, str(e))
        
        # Try from backup
        backup = await self.find_latest_backup(model_path)
        if backup:
            try:
                recovered_doc = await self.restore_from_backup(backup)
                result.success = True
                result.document = recovered_doc
                result.data_loss = self.calculate_data_loss(backup)
                return result
            except Exception as e:
                result.add_attempt("backup_recovery", False, str(e))
        
        # Try partial recovery
        try:
            partial_doc = await self.attempt_partial_recovery(model_path)
            if partial_doc:
                result.success = True
                result.partial = True
                result.document = partial_doc
                result.recovered_objects = self.list_recovered_objects(partial_doc)
                return result
        except Exception as e:
            result.add_attempt("partial_recovery", False, str(e))
        
        # Rebuild from history
        if recovery_options and recovery_options.allow_rebuild:
            try:
                rebuilt_doc = await self.rebuild_from_history(model_path)
                result.success = True
                result.rebuilt = True
                result.document = rebuilt_doc
                return result
            except Exception as e:
                result.add_attempt("history_rebuild", False, str(e))
        
        result.success = False
        return result
    
    async def attempt_partial_recovery(
        self,
        model_path: Path
    ) -> Optional[FreeCAD.Document]:
        """Recover salvageable parts of corrupted model"""
        
        doc = FreeCAD.newDocument()
        recovered_count = 0
        
        # Parse raw file structure
        raw_data = await self.parse_raw_fcstd(model_path)
        
        for object_data in raw_data.objects:
            try:
                # Attempt to recreate object
                obj = self.recreate_object(object_data)
                if obj:
                    doc.addObject(obj)
                    recovered_count += 1
            except Exception:
                continue  # Skip corrupted objects
        
        if recovered_count > 0:
            return doc
        
        return None
```

### Continuous Data Protection
```python
class ContinuousDataProtection:
    """Real-time continuous data protection"""
    
    def __init__(self):
        self.change_tracker = ChangeDataCapture()
        self.replication_manager = ReplicationManager()
        self.journal_writer = JournalWriter()
    
    async def enable_cdp(
        self,
        source: DataSource,
        targets: List[ReplicationTarget]
    ):
        """Enable continuous data protection"""
        
        # Start change data capture
        await self.change_tracker.start_capture(source)
        
        # Configure replication targets
        for target in targets:
            await self.replication_manager.add_target(
                source,
                target,
                ReplicationMode.SYNCHRONOUS if target.is_local else ReplicationMode.ASYNCHRONOUS
            )
        
        # Start journaling
        await self.journal_writer.start_journaling(source)
        
        # Monitor and replicate changes
        async for change in self.change_tracker.get_changes():
            # Write to journal
            await self.journal_writer.write(change)
            
            # Replicate to targets
            replication_tasks = []
            for target in targets:
                task = asyncio.create_task(
                    self.replication_manager.replicate(change, target)
                )
                replication_tasks.append(task)
            
            # Wait for critical replications
            critical_tasks = [
                t for t, target in zip(replication_tasks, targets)
                if target.is_critical
            ]
            
            if critical_tasks:
                await asyncio.gather(*critical_tasks)
```

### Business Continuity Manager
```python
class BusinessContinuityManager:
    """Ensure business continuity during disasters"""
    
    def __init__(self):
        self.rto_monitor = RTOMonitor()  # Recovery Time Objective
        self.rpo_monitor = RPOMonitor()  # Recovery Point Objective
        self.drill_scheduler = DrillScheduler()
        self.compliance_checker = ComplianceChecker()
    
    async def validate_continuity_plan(
        self,
        plan: ContinuityPlan
    ) -> ValidationResult:
        """Validate business continuity plan"""
        
        validation = ValidationResult()
        
        # Check RTO compliance
        rto_analysis = await self.rto_monitor.analyze_plan(plan)
        if rto_analysis.exceeds_objective:
            validation.add_issue(
                "RTO exceeded",
                f"Plan RTO: {rto_analysis.estimated_rto}, Required: {plan.rto_requirement}"
            )
        
        # Check RPO compliance
        rpo_analysis = await self.rpo_monitor.analyze_plan(plan)
        if rpo_analysis.data_loss_risk > plan.acceptable_data_loss:
            validation.add_issue(
                "RPO risk",
                f"Potential data loss: {rpo_analysis.data_loss_risk}"
            )
        
        # Validate redundancy
        redundancy_check = self.check_redundancy(plan)
        validation.add_results("redundancy", redundancy_check)
        
        # Check compliance
        compliance = await self.compliance_checker.check(plan)
        validation.add_results("compliance", compliance)
        
        return validation
    
    async def execute_disaster_drill(
        self,
        drill_scenario: DrillScenario
    ) -> DrillReport:
        """Execute disaster recovery drill"""
        
        report = DrillReport()
        report.scenario = drill_scenario
        report.started_at = datetime.now(UTC)
        
        # Create isolated environment
        drill_env = await self.create_drill_environment()
        
        # Simulate disaster
        await drill_env.simulate_disaster(drill_scenario.disaster_type)
        
        # Execute recovery
        recovery_start = datetime.now(UTC)
        recovery_result = await drill_env.execute_recovery(
            drill_scenario.recovery_plan
        )
        recovery_time = datetime.now(UTC) - recovery_start
        
        # Validate recovery
        validation = await drill_env.validate_recovery()
        
        report.recovery_time = recovery_time
        report.recovery_successful = validation.success
        report.issues_found = validation.issues
        report.recommendations = self.generate_recommendations(
            drill_scenario,
            recovery_result,
            validation
        )
        
        # Cleanup drill environment
        await drill_env.cleanup()
        
        report.completed_at = datetime.now(UTC)
        
        return report
```

### Geo-Redundant Backup
```python
class GeoRedundantBackup:
    """Geographically distributed backup system"""
    
    def __init__(self):
        self.region_manager = RegionManager()
        self.sync_coordinator = SyncCoordinator()
        self.latency_optimizer = LatencyOptimizer()
    
    async def setup_geo_redundancy(
        self,
        primary_region: str,
        replica_regions: List[str],
        consistency_level: str = "eventual"
    ):
        """Setup geographically redundant backups"""
        
        # Configure primary region
        primary = await self.region_manager.configure_primary(primary_region)
        
        # Setup replica regions
        replicas = []
        for region in replica_regions:
            replica = await self.region_manager.configure_replica(
                region,
                primary,
                consistency_level
            )
            replicas.append(replica)
        
        # Optimize replication topology
        topology = await self.latency_optimizer.optimize_topology(
            primary,
            replicas
        )
        
        # Start synchronization
        await self.sync_coordinator.start_sync(topology)
        
        return GeoRedundancyConfig(
            primary=primary,
            replicas=replicas,
            topology=topology,
            consistency=consistency_level
        )
```

### Compliance and Audit
```python
class BackupComplianceAuditor:
    """Ensure backup compliance with regulations"""
    
    def __init__(self):
        self.regulations = {
            'GDPR': GDPRCompliance(),
            'KVKK': KVKKCompliance(),  # Turkish data protection
            'ISO27001': ISO27001Compliance(),
            'SOC2': SOC2Compliance()
        }
    
    async def audit_backup_compliance(
        self,
        backup_system: BackupSystem
    ) -> ComplianceAuditReport:
        """Audit backup system compliance"""
        
        report = ComplianceAuditReport()
        
        for regulation_name, checker in self.regulations.items():
            result = await checker.audit(backup_system)
            report.add_regulation_result(regulation_name, result)
            
            if not result.compliant:
                # Generate remediation plan
                remediation = await checker.generate_remediation(result.violations)
                report.add_remediation(regulation_name, remediation)
        
        # Data retention compliance
        retention_audit = await self.audit_retention_policies(backup_system)
        report.retention_compliance = retention_audit
        
        # Encryption compliance
        encryption_audit = await self.audit_encryption(backup_system)
        report.encryption_compliance = encryption_audit
        
        # Access control audit
        access_audit = await self.audit_access_controls(backup_system)
        report.access_compliance = access_audit
        
        report.overall_compliance = report.calculate_overall_compliance()
        
        return report
```

### Turkish Localization
```python
BACKUP_MESSAGES_TR = {
    'backup_started': 'Yedekleme başlatıldı',
    'backup_completed': 'Yedekleme tamamlandı',
    'recovery_initiated': 'Kurtarma işlemi başlatıldı',
    'recovery_successful': 'Kurtarma başarılı',
    'disaster_detected': 'Felaket durumu tespit edildi',
    'failover_executing': 'Yedek sisteme geçiliyor',
    'data_loss_warning': 'Veri kaybı uyarısı: {amount}',
    'compliance_check': 'Uyumluluk denetimi',
    'drill_scheduled': 'Tatbikat planlandı: {date}'
}
```

### Integration Points
- Integration with MinIO for object storage
- PostgreSQL continuous archiving
- Redis persistence and AOF
- Kubernetes backup operators
- Cloud provider backup services (AWS Backup, Azure Backup)
- Monitoring integration with Prometheus/Grafana

