#!/usr/bin/env python3
"""
S3/MinIO Functionality Smoke Test

Tests basic functionality of the S3 service including:
- Bucket connectivity
- File upload/download operations
- Presigned URL generation
- Object listing and metadata retrieval
"""

import os
import sys
import tempfile
from pathlib import Path
from datetime import timedelta

# Add the app directory to Python path
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.s3 import S3Service
import structlog

logger = structlog.get_logger(__name__)


def test_s3_connectivity():
    """Test basic S3 connectivity and bucket access."""
    print("🔗 Testing S3 connectivity...")

    try:
        s3 = S3Service()

        # Test bucket existence for all required buckets
        buckets = ["artefacts", "logs", "reports", "invoices"]

        for bucket in buckets:
            exists = s3._ensure_bucket_exists(bucket)
            status = "✅" if exists else "❌"
            print(f"  {status} Bucket '{bucket}': {'exists' if exists else 'missing'}")

        print("✅ S3 connectivity test completed")
        return True

    except Exception as e:
        print(f"❌ S3 connectivity test failed: {e}")
        return False


def test_file_upload_download():
    """Test file upload and download operations."""
    print("\n📤 Testing file upload/download...")

    try:
        s3 = S3Service()

        # Create a test file
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as f:
            test_content = (
                "This is a test file for S3 functionality verification.\nGenerated by smoke test."
            )
            f.write(test_content)
            test_file_path = Path(f.name)

        try:
            # Upload the test file
            bucket = "artefacts"
            object_key = "tests/smoke_test_file.txt"

            print(f"  📤 Uploading test file to {bucket}/{object_key}")
            s3.upload_file(
                local_path=test_file_path,
                bucket=bucket,
                object_key=object_key,
                content_type="text/plain",
                metadata={"test": "smoke_test", "purpose": "verification"},
            )
            print("  ✅ File uploaded successfully")

            # Download the file to verify
            with tempfile.NamedTemporaryFile(mode="r", suffix=".txt", delete=False) as f:
                download_path = Path(f.name)

            print(f"  📥 Downloading file to verify content")
            s3.download_file(bucket, object_key, download_path)

            # Verify content
            downloaded_content = download_path.read_text()
            if downloaded_content == test_content:
                print("  ✅ File content verified successfully")
            else:
                print("  ❌ File content mismatch")
                return False

            # Get object info
            print("  📋 Retrieving object metadata")
            info = s3.get_object_info(bucket, object_key)
            print(f"      Size: {info['size']} bytes")
            print(f"      Content-Type: {info['content_type']}")
            print(f"      Last Modified: {info['last_modified']}")
            print(f"      Metadata: {info['metadata']}")

            # Clean up test object
            print("  🧹 Cleaning up test file")
            s3.delete_object(bucket, object_key)
            print("  ✅ Test file deleted")

        finally:
            # Clean up local files
            test_file_path.unlink(missing_ok=True)
            download_path.unlink(missing_ok=True)

        print("✅ File upload/download test completed")
        return True

    except Exception as e:
        print(f"❌ File upload/download test failed: {e}")
        return False


def test_presigned_urls():
    """Test presigned URL generation for uploads and downloads."""
    print("\n🔗 Testing presigned URL generation...")

    try:
        s3 = S3Service()

        # Create a test file for presigned URL testing
        with tempfile.NamedTemporaryFile(mode="w", suffix=".json", delete=False) as f:
            test_content = '{"test": "presigned_url", "timestamp": "2024-01-01T00:00:00Z"}'
            f.write(test_content)
            test_file_path = Path(f.name)

        try:
            bucket = "artefacts"
            object_key = "tests/presigned_test.json"

            # Upload file first
            s3.upload_file(test_file_path, bucket, object_key, content_type="application/json")
            print("  📤 Test file uploaded for presigned URL testing")

            # Generate presigned upload URL
            print("  🔗 Generating presigned upload URL")
            upload_url = s3.generate_presigned_upload_url(
                bucket=bucket,
                object_key="tests/presigned_upload_test.json",
                expiry=timedelta(minutes=15),
                content_type="application/json",
            )
            print(f"      Upload URL generated (length: {len(upload_url)} chars)")

            # Generate presigned download URL
            print("  🔗 Generating presigned download URL")
            download_url = s3.generate_presigned_download_url(
                bucket=bucket, object_key=object_key, expiry=timedelta(minutes=15)
            )
            print(f"      Download URL generated (length: {len(download_url)} chars)")

            # Test custom download URL with filename
            print("  🔗 Generating custom download URL with filename")
            custom_download_url = s3.create_temp_download_url(
                bucket=bucket,
                object_key=object_key,
                filename="custom_test_file.json",
                expiry_minutes=10,
            )
            print(f"      Custom download URL generated (length: {len(custom_download_url)} chars)")

            # Clean up
            s3.delete_object(bucket, object_key)
            print("  🧹 Test file deleted")

        finally:
            test_file_path.unlink(missing_ok=True)

        print("✅ Presigned URL test completed")
        return True

    except Exception as e:
        print(f"❌ Presigned URL test failed: {e}")
        return False


def test_object_listing():
    """Test object listing functionality."""
    print("\n📋 Testing object listing...")

    try:
        s3 = S3Service()
        bucket = "artefacts"

        # Create test files
        test_files = []
        for i in range(3):
            with tempfile.NamedTemporaryFile(mode="w", suffix=f"_{i}.txt", delete=False) as f:
                f.write(f"Test file {i} for listing test")
                test_file = Path(f.name)

                object_key = f"tests/listing/file_{i}.txt"
                s3.upload_file(test_file, bucket, object_key)
                test_files.append((test_file, object_key))
                test_file.unlink()  # Clean up local file

        print(f"  📤 Uploaded {len(test_files)} test files")

        # List objects with prefix
        print("  📋 Listing objects with prefix 'tests/listing/'")
        objects = s3.list_objects(bucket, prefix="tests/listing/")

        print(f"      Found {len(objects)} objects:")
        for obj in objects:
            print(f"        - {obj['key']} ({obj['size']} bytes, {obj['last_modified']})")

        if len(objects) != len(test_files):
            print(f"  ❌ Expected {len(test_files)} objects, found {len(objects)}")
            return False

        # Clean up test files
        print("  🧹 Cleaning up test files")
        for _, object_key in test_files:
            s3.delete_object(bucket, object_key)

        print("✅ Object listing test completed")
        return True

    except Exception as e:
        print(f"❌ Object listing test failed: {e}")
        return False


def test_copy_operations():
    """Test object copy functionality."""
    print("\n📋 Testing object copy operations...")

    try:
        s3 = S3Service()

        # Create source file
        with tempfile.NamedTemporaryFile(mode="w", suffix=".txt", delete=False) as f:
            test_content = "This file will be copied to test copy functionality"
            f.write(test_content)
            source_file = Path(f.name)

        try:
            # Upload source file
            source_bucket = "artefacts"
            source_key = "tests/copy_source.txt"
            dest_bucket = "logs"
            dest_key = "tests/copy_destination.txt"

            s3.upload_file(source_file, source_bucket, source_key)
            print(f"  📤 Uploaded source file to {source_bucket}/{source_key}")

            # Copy the file
            print(f"  📋 Copying to {dest_bucket}/{dest_key}")
            copied_key = s3.copy_object(
                source_bucket=source_bucket,
                source_key=source_key,
                dest_bucket=dest_bucket,
                dest_key=dest_key,
                metadata={"copied": "true", "test": "copy_operation"},
            )
            print(f"  ✅ File copied successfully: {copied_key}")

            # Verify both files exist
            source_info = s3.get_object_info(source_bucket, source_key)
            dest_info = s3.get_object_info(dest_bucket, dest_key)

            if source_info["size"] == dest_info["size"]:
                print("  ✅ File sizes match after copy")
            else:
                print("  ❌ File sizes don't match after copy")
                return False

            # Clean up
            s3.delete_object(source_bucket, source_key)
            s3.delete_object(dest_bucket, dest_key)
            print("  🧹 Test files deleted")

        finally:
            source_file.unlink(missing_ok=True)

        print("✅ Object copy test completed")
        return True

    except Exception as e:
        print(f"❌ Object copy test failed: {e}")
        return False


def main():
    """Run all S3 functionality tests."""
    print("🚀 Starting S3/MinIO functionality smoke tests...\n")

    # Configure structured logging for tests
    structlog.configure(
        processors=[structlog.dev.ConsoleRenderer()],
        wrapper_class=structlog.make_filtering_bound_logger(20),  # INFO level
    )

    tests = [
        ("S3 Connectivity", test_s3_connectivity),
        ("File Upload/Download", test_file_upload_download),
        ("Presigned URLs", test_presigned_urls),
        ("Object Listing", test_object_listing),
        ("Copy Operations", test_copy_operations),
    ]

    passed = 0
    failed = 0

    for test_name, test_func in tests:
        try:
            if test_func():
                passed += 1
            else:
                failed += 1
        except Exception as e:
            print(f"❌ {test_name} test crashed: {e}")
            failed += 1

    print(f"\n📊 Test Results:")
    print(f"  ✅ Passed: {passed}")
    print(f"  ❌ Failed: {failed}")
    print(f"  📋 Total: {len(tests)}")

    if failed == 0:
        print("\n🎉 All S3 functionality tests passed!")
        return 0
    else:
        print(f"\n💥 {failed} test(s) failed. Please check your MinIO configuration.")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
